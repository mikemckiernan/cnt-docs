<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Install Kubernetes &mdash; NVIDIA Cloud Native Technologies  documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="../_static/tabs.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />
    <link rel="shortcut icon" href="../_static/nvidia.ico"/>
    <link rel="canonical" href="https://docs.nvidia.com/datacenter/cloud-native/kubernetes/install-k8s.html"/>
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/sphinx_highlight.js"></script>
        <script src="../_static/clipboard.min.js"></script>
        <script src="../_static/copybutton.js"></script>
        <script src="../_static/tabs.js"></script>
        <script src="../_static/js/google-analytics/google-analytics-tracker.js"></script>
        <script src="../_static/js/google-analytics/google-analytics-write.js"></script>
        <script src="//assets.adobedtm.com/b92787824f2e0e9b68dc2e993f9bd995339fe417/satelliteLib-7ba51e58dc61bcb0e9311aadd02a0108ab24cc6c.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="MIG Support in Kubernetes" href="mig-k8s.html" />
    <link rel="prev" title="Appendix" href="../gpu-operator/archive/1.8/appendix.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" > 
            <a href="../contents.html">
            <img src="../_static/NVLogo_H_B&W.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

  <style>
    /* Sidebar header (and topbar for mobile) */
    .wy-side-nav-search, .wy-nav-top {
      background: #76b900;
    }

    .wy-side-nav-search a:link, .wy-nav-top a:link {
      color: #fff;
    }
    .wy-side-nav-search a:visited, .wy-nav-top a:visited {
      color: #fff;
    }
    .wy-side-nav-search a:hover, .wy-nav-top a:hover {
      color: #fff;
    }

    .wy-menu-vertical a:link, .wy-menu-vertical a:visited {
      color: #d9d9d9
    }

    .wy-menu-vertical a:active {
      background-color: #76b900
    }

    .wy-side-nav-search>div.version {
      color: rgba(0, 0, 0, 0.3)
    }

    .wy-nav-content {
      max-width: 1000px;
    }
  </style>
  
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">NVIDIA Container Toolkit:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../container-toolkit/overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../container-toolkit/concepts.html">Concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="../container-toolkit/arch-overview.html">Architecture Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../container-toolkit/install-guide.html">Installation Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../container-toolkit/troubleshooting.html">Troubleshooting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../container-toolkit/user-guide.html">User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../container-toolkit/release-notes.html">Release Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../container-toolkit/archive.html">Archive</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">NVIDIA GPU Operator:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/getting-started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/platform-support.html">Platform Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/release-notes.html">Release Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/gpu-driver-upgrades.html">GPU Driver Upgrades</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/install-gpu-operator-vgpu.html">NVIDIA vGPU</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/install-gpu-operator-nvaie.html">NVIDIA AI Enterprise</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/openshift/contents.html">GPU Operator on OpenShift</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/gpu-operator-mig.html">GPU Operator with MIG</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/gpu-sharing.html">Time-Slicing GPUs in Kubernetes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/gpu-operator-rdma.html">GPUDirect RDMA and GPUDirect Storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/gpu-operator-kubevirt.html">GPU Operator with KubeVirt</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/appendix.html">Appendix</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/archive.html">Archive</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Kubernetes with GPUs:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Install Kubernetes</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#introduction">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="#option-1-installing-kubernetes-using-deepops">Option 1: Installing Kubernetes Using DeepOps</a></li>
<li class="toctree-l2"><a class="reference internal" href="#option-2-installing-kubernetes-using-kubeadm">Option 2: Installing Kubernetes Using Kubeadm</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="mig-k8s.html">MIG Support in Kubernetes</a></li>
<li class="toctree-l1"><a class="reference internal" href="anthos-guide.html">NVIDIA GPUs with Google Cloud’s Anthos</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">GPU Telemetry:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../gpu-telemetry/dcgm-exporter.html">DCGM-Exporter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-telemetry/dcgm-exporter.html#integrating-gpu-telemetry-into-kubernetes">Integrating GPU Telemetry into Kubernetes</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Multi-Instance GPU:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../mig/mig.html">Multi-Instance GPU</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mig/mig-k8s.html">MIG Support in Kubernetes</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Driver Containers:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../driver-containers/overview.html">Overview</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Playground:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../playground/dind.html">Docker-in-Docker</a></li>
<li class="toctree-l1"><a class="reference internal" href="../playground/x-arch.html">Running Cross-Architecture Containers</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../contents.html">NVIDIA Cloud Native Technologies</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../contents.html" class="icon icon-home"></a> &raquo;</li>
      <li>Install Kubernetes</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="install-kubernetes">
<span id="install-k8s"></span><h1>Install Kubernetes<a class="headerlink" href="#install-kubernetes" title="Permalink to this heading"></a></h1>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this heading"></a></h2>
<p>Kubernetes is an open-source platform for automating deployment, scaling and managing containerized applications. Kubernetes includes support
for GPUs and enhancements to Kubernetes so users can easily configure and use GPU resources for accelerating AI and HPC workloads.</p>
<p>There are many ways to install upstream Kubernetes with NVIDIA supported components, such as drivers, plugins and runtime. This document
describes a few methods for getting started with Kubernetes. Click on the links below to map out the options that you would like to follow:</p>
<ol class="arabic simple">
<li><p>Option 1: Using <a class="reference external" href="https://github.com/NVIDIA/deepops">DeepOps</a></p></li>
<li><p>Option 2: Using <a class="reference external" href="https://kubernetes.io/docs/reference/setup-tools/kubeadm/">Kubeadm</a> to install Kubernetes</p>
<ul class="simple">
<li><p>Option 2-a: Use the <a class="reference internal" href="#gpu-operator"><span class="std std-ref">NVIDIA GPU Operator</span></a> to automate/manage the deployment of the NVIDIA software components</p></li>
<li><p>Option 2-b: Set up the NVIDIA software components as <a class="reference internal" href="#nvdp"><span class="std std-ref">pre-requisites</span></a> before running applications</p></li>
</ul>
</li>
</ol>
<div class="align-default"><img height="280" src="../_images/blockdiag-407fa48522c23a1901e2491ab6d861e86b4717f4.png" width="640" /></div>
</section>
<section id="option-1-installing-kubernetes-using-deepops">
<h2>Option 1: Installing Kubernetes Using DeepOps<a class="headerlink" href="#option-1-installing-kubernetes-using-deepops" title="Permalink to this heading"></a></h2>
<p>Use DeepOps to automate deployment, especially for a cluster of many worker nodes. DeepOps is a modular collection
of ansible scripts which automate the deployment of Kubernetes, Slurm, or a hybrid combination of the two across
your nodes. It also installs the necessary GPU drivers, NVIDIA Container Toolkit for Docker (<code class="docutils literal notranslate"><span class="pre">nvidia-docker2</span></code>),
and various other dependencies for GPU-accelerated work. Encapsulating best practices for NVIDIA GPUs, it can be
customized or run as individual components, as needed.</p>
<p>Use the following procedure to install Kubernetes using DeepOps:</p>
<ol class="arabic">
<li><p>Pick a provisioning node to deploy from.
This is where the DeepOps Ansible scripts run from and is often a development laptop that has a connection to the target cluster. On this provisioning node,
clone the DeepOps repository with the following command:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/NVIDIA/deepops.git
</pre></div>
</div>
</li>
<li><p>Optionally, check out a recent release tag with the following command:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span><span class="nb">cd</span><span class="w"> </span>deepops<span class="w"> </span><span class="se">\</span>
<span class="w">   </span><span class="o">&amp;&amp;</span><span class="w"> </span>git<span class="w"> </span>checkout<span class="w"> </span>tags/20.10
</pre></div>
</div>
<p>If you do not explicitly use a release tag, then the latest development code is used, and not an official release.</p>
</li>
<li><p>Follow the instructions in the <a class="reference external" href="https://github.com/NVIDIA/deepops/blob/master/docs/k8s-cluster">DeepOps Kubernetes Deployment Guide</a> to install Kubernetes.</p></li>
</ol>
</section>
<section id="option-2-installing-kubernetes-using-kubeadm">
<h2>Option 2: Installing Kubernetes Using Kubeadm<a class="headerlink" href="#option-2-installing-kubernetes-using-kubeadm" title="Permalink to this heading"></a></h2>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The method described in this section is an alternative to using DeepOps. If you have deployed using DeepOps, then skip this section.</p>
</div>
<p>For a less scripted approach, especially for smaller clusters or where there is a desire to learn the components that make up a Kubernetes cluster, use Kubeadm.</p>
<p>A Kubernetes cluster is composed of master nodes and worker nodes. The master nodes run the control plane components of Kubernetes which allows your
cluster to function properly. These components include the API Server (front-end to the <code class="docutils literal notranslate"><span class="pre">kubectl</span></code> CLI), <strong>etcd</strong> (stores the cluster state) and others.</p>
<p>Use CPU-only (GPU-free) master nodes, which run the control plane components: Scheduler, API-server, and Controller Manager. Control plane components can
have some impact on your CPU intensive tasks and conversely, CPU or HDD/SSD intensive components can have an impact on your control plane components.</p>
<p>With <code class="docutils literal notranslate"><span class="pre">kubeadm</span></code>, this document will walk through the steps for installing a single node Kubernetes cluster (where we untaint the control plane
so it can run GPU pods), but the cluster can be scaled easily with additional nodes.</p>
<section id="step-0-before-you-begin">
<h3>Step 0: Before You Begin<a class="headerlink" href="#step-0-before-you-begin" title="Permalink to this heading"></a></h3>
<p>Before proceeding to install the components, check that all Kubernetes <a class="reference external" href="https://kubernetes.io/docs/setup/independent/install-kubeadm/#before-you-begin">prerequisites</a>
have been satisfied. These prerequisites include:</p>
<ul class="simple">
<li><p>Check network adapters and required ports</p></li>
<li><p>Disable swap on the nodes so that kubelet can work correctly</p></li>
<li><p>Install a supported container runtime such as Docker, containerd or CRI-O</p></li>
</ul>
<p>Depending on your Linux distribution, refer to the steps below:</p>
<ul class="simple">
<li><p><a class="reference internal" href="k8s-containerd.html#ubuntu-k8s"><span class="std std-ref">Ubuntu LTS</span></a></p></li>
<li><p><a class="reference internal" href="k8s-containerd.html#centos-k8s"><span class="std std-ref">CentOS</span></a></p></li>
</ul>
</section>
<section id="ubuntu-lts">
<span id="ubuntu-k8s"></span><h3>Ubuntu LTS<a class="headerlink" href="#ubuntu-lts" title="Permalink to this heading"></a></h3>
<p>This section provides steps for setting up K8s on Ubuntu 18.04 and 20.04 LTS distributions.</p>
<section id="step-1-install-a-container-engine">
<h4>Step 1: Install a Container Engine<a class="headerlink" href="#step-1-install-a-container-engine" title="Permalink to this heading"></a></h4>
<p>NVIDIA supports running GPU containers with Docker and other CRI compliant runtimes such as <cite>containerd</cite> or CRI-O.</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-0-0-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-0-0-0" name="0-0" role="tab" tabindex="0">Docker</button><button aria-controls="panel-0-0-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-0-0-1" name="0-1" role="tab" tabindex="-1">containerd</button></div><div aria-labelledby="tab-0-0-0" class="sphinx-tabs-panel" id="panel-0-0-0" name="0-0" role="tabpanel" tabindex="0"><p>Follow the steps in this <a class="reference external" href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html#installing-on-ubuntu-and-debian">guide</a>
to install Docker.</p>
</div><div aria-labelledby="tab-0-0-1" class="sphinx-tabs-panel" hidden="true" id="panel-0-0-1" name="0-1" role="tabpanel" tabindex="0"><p>First, install some pre-requisites for <code class="docutils literal notranslate"><span class="pre">containerd</span></code>:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>sudo<span class="w"> </span>apt-get<span class="w"> </span>update<span class="w"> </span><span class="se">\</span>
<span class="w">   </span><span class="o">&amp;&amp;</span><span class="w"> </span>sudo<span class="w"> </span>apt-get<span class="w"> </span>install<span class="w"> </span>-y<span class="w"> </span>apt-transport-https<span class="w"> </span><span class="se">\</span>
<span class="w">      </span>ca-certificates<span class="w"> </span>curl<span class="w"> </span>software-properties-common
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">overlay</span></code> and <code class="docutils literal notranslate"><span class="pre">br_netfilter</span></code> modules are required to be loaded:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>cat<span class="w"> </span>&lt;&lt;EOF<span class="w"> </span><span class="p">|</span><span class="w"> </span>sudo<span class="w"> </span>tee<span class="w"> </span>/etc/modules-load.d/containerd.conf
<span class="go">overlay</span>
<span class="go">br_netfilter</span>
<span class="go">EOF</span>
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>sudo<span class="w"> </span>modprobe<span class="w"> </span>overlay<span class="w"> </span><span class="se">\</span>
<span class="w">   </span><span class="o">&amp;&amp;</span><span class="w"> </span>sudo<span class="w"> </span>modprobe<span class="w"> </span>br_netfilter
</pre></div>
</div>
<p>Setup the required <code class="docutils literal notranslate"><span class="pre">sysctl</span></code> parameters and make them persistent:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>cat<span class="w"> </span>&lt;&lt;EOF<span class="w"> </span><span class="p">|</span><span class="w"> </span>sudo<span class="w"> </span>tee<span class="w"> </span>/etc/sysctl.d/99-kubernetes-cri.conf
<span class="go">net.bridge.bridge-nf-call-iptables  = 1</span>
<span class="go">net.ipv4.ip_forward                 = 1</span>
<span class="go">net.bridge.bridge-nf-call-ip6tables = 1</span>
<span class="go">EOF</span>
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>sudo<span class="w"> </span>sysctl<span class="w"> </span>--system
</pre></div>
</div>
<p>Now proceed to setup the Docker repository:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>curl<span class="w"> </span>-fsSL<span class="w"> </span>https://download.docker.com/linux/ubuntu/gpg<span class="w"> </span><span class="p">|</span><span class="w"> </span>sudo<span class="w"> </span>apt-key<span class="w"> </span>--keyring<span class="w"> </span>/etc/apt/trusted.gpg.d/docker.gpg<span class="w"> </span>add<span class="w"> </span>-
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>sudo<span class="w"> </span>add-apt-repository<span class="w"> </span><span class="s2">&quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu \</span>
<span class="gp">   $</span><span class="s2">(lsb_release -cs) \</span>
<span class="s2">   stable&quot;</span>
</pre></div>
</div>
<p>Install <code class="docutils literal notranslate"><span class="pre">containerd</span></code>:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>sudo<span class="w"> </span>apt-get<span class="w"> </span>update<span class="w"> </span><span class="se">\</span>
<span class="w">   </span><span class="o">&amp;&amp;</span><span class="w"> </span>sudo<span class="w"> </span>apt-get<span class="w"> </span>install<span class="w"> </span>-y<span class="w"> </span>containerd.io
</pre></div>
</div>
<p>Create a default <code class="docutils literal notranslate"><span class="pre">config.toml</span></code>:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>sudo<span class="w"> </span>mkdir<span class="w"> </span>-p<span class="w"> </span>/etc/containerd<span class="w"> </span><span class="se">\</span>
<span class="w">   </span><span class="o">&amp;&amp;</span><span class="w"> </span>sudo<span class="w"> </span>containerd<span class="w"> </span>config<span class="w"> </span>default<span class="w"> </span><span class="p">|</span><span class="w"> </span>sudo<span class="w"> </span>tee<span class="w"> </span>/etc/containerd/config.toml
</pre></div>
</div>
<p>Configure <code class="docutils literal notranslate"><span class="pre">containerd</span></code> to use the <code class="docutils literal notranslate"><span class="pre">systemd</span></code> cgroup driver with <code class="docutils literal notranslate"><span class="pre">runc</span></code> by editing the configuration file and adding this line:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">[plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.runtimes.runc.options]</span>
<span class="go">   SystemdCgroup = true</span>
</pre></div>
</div>
<p>Now restart the daemon:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>sudo<span class="w"> </span>systemctl<span class="w"> </span>restart<span class="w"> </span>containerd
</pre></div>
</div>
</div></div>
</section>
<section id="step-2-install-kubernetes-components">
<h4>Step 2: Install Kubernetes Components<a class="headerlink" href="#step-2-install-kubernetes-components" title="Permalink to this heading"></a></h4>
<p>First, install some dependencies:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>sudo<span class="w"> </span>apt-get<span class="w"> </span>update<span class="w"> </span><span class="se">\</span>
<span class="w">   </span><span class="o">&amp;&amp;</span><span class="w"> </span>sudo<span class="w"> </span>apt-get<span class="w"> </span>install<span class="w"> </span>-y<span class="w"> </span>apt-transport-https<span class="w"> </span>curl
</pre></div>
</div>
<p>Add the package repository keys:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>curl<span class="w"> </span>-s<span class="w"> </span>https://packages.cloud.google.com/apt/doc/apt-key.gpg<span class="w"> </span><span class="p">|</span><span class="w"> </span>sudo<span class="w"> </span>apt-key<span class="w"> </span>add<span class="w"> </span>-
</pre></div>
</div>
<p>And the repository:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>cat<span class="w"> </span>&lt;&lt;EOF<span class="w"> </span><span class="p">|</span><span class="w"> </span>sudo<span class="w"> </span>tee<span class="w"> </span>/etc/apt/sources.list.d/kubernetes.list
<span class="go">deb https://apt.kubernetes.io/ kubernetes-xenial main</span>
<span class="go">EOF</span>
</pre></div>
</div>
<p>Update the package listing and install <cite>kubelet</cite>:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>sudo<span class="w"> </span>apt-get<span class="w"> </span>update<span class="w"> </span><span class="se">\</span>
<span class="w">   </span><span class="o">&amp;&amp;</span><span class="w"> </span>sudo<span class="w"> </span>apt-get<span class="w"> </span>install<span class="w"> </span>-y<span class="w"> </span>-q<span class="w"> </span>kubelet<span class="w"> </span>kubectl<span class="w"> </span>kubeadm
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If you’re using <code class="docutils literal notranslate"><span class="pre">containerd</span></code> as the CRI runtime, then follow these steps:</p>
<ol class="arabic">
<li><p>Configure the cgroup driver for <code class="docutils literal notranslate"><span class="pre">kubelet</span></code>:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>sudo<span class="w"> </span>mkdir<span class="w"> </span>-p<span class="w">  </span>/etc/systemd/system/kubelet.service.d/
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>sudo<span class="w"> </span>cat<span class="w"> </span>&lt;&lt;<span class="w"> </span>EOF<span class="w"> </span><span class="p">|</span><span class="w"> </span>sudo<span class="w"> </span>tee<span class="w">  </span>/etc/systemd/system/kubelet.service.d/0-containerd.conf
<span class="go">[Service]</span>
<span class="go">Environment=&quot;KUBELET_EXTRA_ARGS=--container-runtime=remote --runtime-request-timeout=15m --container-runtime-endpoint=unix:///run/containerd/containerd.sock --cgroup-driver=&#39;systemd&#39;&quot;</span>
<span class="go">EOF</span>
</pre></div>
</div>
</li>
<li><p>Restart kubelet:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>sudo<span class="w"> </span>systemctl<span class="w"> </span>daemon-reload<span class="w"> </span><span class="se">\</span>
<span class="w">   </span><span class="o">&amp;&amp;</span><span class="w"> </span>sudo<span class="w"> </span>systemctl<span class="w"> </span>restart<span class="w"> </span>kubelet
</pre></div>
</div>
</li>
</ol>
</div>
<p>Disable swap</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>sudo<span class="w"> </span>swapoff<span class="w"> </span>-a
</pre></div>
</div>
<p>And <code class="docutils literal notranslate"><span class="pre">init</span></code> using <code class="docutils literal notranslate"><span class="pre">kubeadm</span></code>:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>sudo<span class="w"> </span>kubeadm<span class="w"> </span>init<span class="w"> </span>--pod-network-cidr<span class="o">=</span><span class="m">192</span>.168.0.0/16
</pre></div>
</div>
<p>Finish the configuration setup with Kubeadm:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>mkdir<span class="w"> </span>-p<span class="w"> </span><span class="nv">$HOME</span>/.kube<span class="w"> </span><span class="se">\</span>
<span class="w">   </span><span class="o">&amp;&amp;</span><span class="w"> </span>sudo<span class="w"> </span>cp<span class="w"> </span>-i<span class="w"> </span>/etc/kubernetes/admin.conf<span class="w"> </span><span class="nv">$HOME</span>/.kube/config<span class="w"> </span><span class="se">\</span>
<span class="w">   </span><span class="o">&amp;&amp;</span><span class="w"> </span>sudo<span class="w"> </span>chown<span class="w"> </span><span class="k">$(</span>id<span class="w"> </span>-u<span class="k">)</span>:<span class="k">$(</span>id<span class="w"> </span>-g<span class="k">)</span><span class="w"> </span><span class="nv">$HOME</span>/.kube/config
</pre></div>
</div>
</section>
<section id="step-3-configure-networking">
<h4>Step 3: Configure Networking<a class="headerlink" href="#step-3-configure-networking" title="Permalink to this heading"></a></h4>
<p>Now, setup networking with Calico:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl<span class="w"> </span>apply<span class="w"> </span>-f<span class="w"> </span>https://docs.projectcalico.org/manifests/calico.yaml
</pre></div>
</div>
<p>Untaint the control plane, so it can be used to schedule GPU pods in our simplistic single-node cluster:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl<span class="w"> </span>taint<span class="w"> </span>nodes<span class="w"> </span>--all<span class="w"> </span>node-role.kubernetes.io/master-
</pre></div>
</div>
<p>Your cluster should now be ready to schedule containerized applications.</p>
</section>
</section>
<section id="centos">
<span id="centos-k8s"></span><h3>CentOS<a class="headerlink" href="#centos" title="Permalink to this heading"></a></h3>
<p>Follow the steps in this section for setting up K8s on CentOS 7/8.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If you’re using CentOS 7/8 on a cloud IaaS platform such as EC2, then you may need to do some additional setup as listed here:</p>
<ol class="arabic">
<li><p>Choose an official CentOS image for your EC2 region: <a class="reference external" href="https://wiki.centos.org/Cloud/AWS">https://wiki.centos.org/Cloud/AWS</a></p></li>
<li><p>Install some of the prerequisites:</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-1-1-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-1-1-0" name="1-0" role="tab" tabindex="0">CentOS 8</button><button aria-controls="panel-1-1-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-1-1-1" name="1-1" role="tab" tabindex="-1">CentOS 7</button></div><div aria-labelledby="tab-1-1-0" class="sphinx-tabs-panel" id="panel-1-1-0" name="1-0" role="tabpanel" tabindex="0"><div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>sudo<span class="w"> </span>dnf<span class="w"> </span>install<span class="w"> </span>-y<span class="w"> </span>tar<span class="w"> </span>bzip2<span class="w"> </span>make<span class="w"> </span>automake<span class="w"> </span>gcc<span class="w"> </span>gcc-c++<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>pciutils<span class="w"> </span>elfutils-libelf-devel<span class="w"> </span>libglvnd-devel<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>iptables<span class="w"> </span>firewalld<span class="w"> </span>bind-utils<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>vim<span class="w"> </span>wget
</pre></div>
</div>
</div><div aria-labelledby="tab-1-1-1" class="sphinx-tabs-panel" hidden="true" id="panel-1-1-1" name="1-1" role="tabpanel" tabindex="0"><div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>sudo<span class="w"> </span>yum<span class="w"> </span>install<span class="w"> </span>-y<span class="w"> </span>tar<span class="w"> </span>bzip2<span class="w"> </span>make<span class="w"> </span>automake<span class="w"> </span>gcc<span class="w"> </span>gcc-c++<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>pciutils<span class="w"> </span>elfutils-libelf-devel<span class="w"> </span>libglvnd-devel<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>iptables<span class="w"> </span>firewalld<span class="w"> </span>bind-utils<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>vim<span class="w"> </span>wget
</pre></div>
</div>
</div></div>
</li>
<li><p>Update the running kernel to ensure you’re running the latest updates</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-2-2-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-2-2-0" name="2-0" role="tab" tabindex="0">CentOS 8</button><button aria-controls="panel-2-2-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-2-2-1" name="2-1" role="tab" tabindex="-1">CentOS 7</button></div><div aria-labelledby="tab-2-2-0" class="sphinx-tabs-panel" id="panel-2-2-0" name="2-0" role="tabpanel" tabindex="0"><div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>sudo<span class="w"> </span>dnf<span class="w"> </span>update<span class="w"> </span>-y
</pre></div>
</div>
</div><div aria-labelledby="tab-2-2-1" class="sphinx-tabs-panel" hidden="true" id="panel-2-2-1" name="2-1" role="tabpanel" tabindex="0"><div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>sudo<span class="w"> </span>yum<span class="w"> </span>update<span class="w"> </span>-y
</pre></div>
</div>
</div></div>
</li>
<li><p>Reboot your VM</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>sudo<span class="w"> </span>reboot
</pre></div>
</div>
</li>
</ol>
</div>
<section id="step-0-configuring-the-system">
<h4>Step 0: Configuring the System<a class="headerlink" href="#step-0-configuring-the-system" title="Permalink to this heading"></a></h4>
<section id="disable-nouveau">
<h5>Disable Nouveau<a class="headerlink" href="#disable-nouveau" title="Permalink to this heading"></a></h5>
<p>For a successful install of the NVIDIA driver, the Nouveau drivers must first be disabled.</p>
<p>Determine if the <code class="docutils literal notranslate"><span class="pre">nouveau</span></code> driver is loaded:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>lsmod<span class="w"> </span><span class="p">|</span><span class="w"> </span>grep<span class="w"> </span>-i<span class="w"> </span>nouveau
</pre></div>
</div>
<p>Create a file at <code class="docutils literal notranslate"><span class="pre">/etc/modprobe.d/blacklist-nouveau.conf</span></code> with the following contents:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">blacklist nouveau</span>
<span class="go">options nouveau modeset=0</span>
</pre></div>
</div>
<p>Regenerate the kernel initramfs:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>sudo<span class="w"> </span>dracut<span class="w"> </span>--force
</pre></div>
</div>
<p>Reboot the system before proceeding with the next step.</p>
<p>For the remaining part of this section, we will follow the general steps for using <a class="reference external" href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/">kubeadm</a>.
Also, for convenience, let’s enter into an interactive <code class="docutils literal notranslate"><span class="pre">sudo</span></code> session since most of the remaining commands require root privileges:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>sudo<span class="w"> </span>-i
</pre></div>
</div>
</section>
<section id="disable-selinux">
<h5>Disable SELinux<a class="headerlink" href="#disable-selinux" title="Permalink to this heading"></a></h5>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>setenforce<span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span><span class="o">&amp;&amp;</span><span class="w"> </span>sed<span class="w"> </span>-i<span class="w"> </span>--follow-symlinks<span class="w"> </span><span class="s1">&#39;s/SELINUX=enforcing/SELINUX=disabled/g&#39;</span><span class="w"> </span>/etc/sysconfig/selinux
</pre></div>
</div>
</section>
<section id="bridged-traffic-and-iptables">
<h5>Bridged traffic and iptables<a class="headerlink" href="#bridged-traffic-and-iptables" title="Permalink to this heading"></a></h5>
<p>As mentioned in the <code class="docutils literal notranslate"><span class="pre">kubedadm</span></code> documentation, ensure that the <code class="docutils literal notranslate"><span class="pre">br_netfilter</span></code> module is loaded:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>modprobe<span class="w"> </span>br_netfilter
</pre></div>
</div>
<p>Ensure <code class="docutils literal notranslate"><span class="pre">net.bridge.bridge-nf-call-iptables</span></code> is configured correctly:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>cat<span class="w"> </span>&lt;&lt;EOF<span class="w"> </span>&gt;<span class="w"> </span>/etc/sysctl.d/k8s.conf
<span class="go">net.bridge.bridge-nf-call-ip6tables = 1</span>
<span class="go">net.bridge.bridge-nf-call-iptables = 1</span>
<span class="go">EOF</span>
</pre></div>
</div>
<p>and restart the <code class="docutils literal notranslate"><span class="pre">sysctl</span></code> config:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>sysctl<span class="w"> </span>--system
</pre></div>
</div>
</section>
<section id="firewall-and-required-ports">
<h5>Firewall and required ports<a class="headerlink" href="#firewall-and-required-ports" title="Permalink to this heading"></a></h5>
<p>The network plugin requires certain ports to be open on the control plane and worker nodes. See this
<a class="reference external" href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/#check-required-ports">table</a> for more information on
the purpose of these port numbers.</p>
<p>Ensure that <code class="docutils literal notranslate"><span class="pre">firewalld</span></code> is running:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>systemctl<span class="w"> </span>status<span class="w"> </span>firewalld
</pre></div>
</div>
<p>and if required, start <code class="docutils literal notranslate"><span class="pre">firewalld</span></code>:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>systemctl<span class="w"> </span>--now<span class="w"> </span><span class="nb">enable</span><span class="w"> </span>firewalld
</pre></div>
</div>
<p>Now open the ports:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>firewall-cmd<span class="w"> </span>--permanent<span class="w"> </span>--add-port<span class="o">=</span><span class="m">6443</span>/tcp<span class="w"> </span><span class="se">\</span>
<span class="w">   </span><span class="o">&amp;&amp;</span><span class="w"> </span>firewall-cmd<span class="w"> </span>--permanent<span class="w"> </span>--add-port<span class="o">=</span><span class="m">2379</span>-2380/tcp<span class="w"> </span><span class="se">\</span>
<span class="w">   </span><span class="o">&amp;&amp;</span><span class="w"> </span>firewall-cmd<span class="w"> </span>--permanent<span class="w"> </span>--add-port<span class="o">=</span><span class="m">10250</span>/tcp<span class="w"> </span><span class="se">\</span>
<span class="w">   </span><span class="o">&amp;&amp;</span><span class="w"> </span>firewall-cmd<span class="w"> </span>--permanent<span class="w"> </span>--add-port<span class="o">=</span><span class="m">10251</span>/tcp<span class="w"> </span><span class="se">\</span>
<span class="w">   </span><span class="o">&amp;&amp;</span><span class="w"> </span>firewall-cmd<span class="w"> </span>--permanent<span class="w"> </span>--add-port<span class="o">=</span><span class="m">10252</span>/tcp<span class="w"> </span><span class="se">\</span>
<span class="w">   </span><span class="o">&amp;&amp;</span><span class="w"> </span>firewall-cmd<span class="w"> </span>--permanent<span class="w"> </span>--add-port<span class="o">=</span><span class="m">10255</span>/tcp
</pre></div>
</div>
<p>Its also required to add the <code class="docutils literal notranslate"><span class="pre">docker0</span></code> interface to the public zone and allow for <code class="docutils literal notranslate"><span class="pre">docker0</span></code> ingress and egress:</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-3-3-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-3-3-0" name="3-0" role="tab" tabindex="0">CentOS 8</button><button aria-controls="panel-3-3-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-3-3-1" name="3-1" role="tab" tabindex="-1">CentOS 7</button></div><div aria-labelledby="tab-3-3-0" class="sphinx-tabs-panel" id="panel-3-3-0" name="3-0" role="tabpanel" tabindex="0"><div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>nmcli<span class="w"> </span>connection<span class="w"> </span>modify<span class="w"> </span>docker0<span class="w"> </span>connection.zone<span class="w"> </span>public<span class="w"> </span><span class="se">\</span>
<span class="w">   </span><span class="o">&amp;&amp;</span><span class="w"> </span>firewall-cmd<span class="w"> </span>--zone<span class="o">=</span>public<span class="w"> </span>--add-masquerade<span class="w"> </span>--permanent<span class="w"> </span><span class="se">\</span>
<span class="w">   </span><span class="o">&amp;&amp;</span><span class="w"> </span>firewall-cmd<span class="w"> </span>--zone<span class="o">=</span>public<span class="w"> </span>--add-port<span class="o">=</span><span class="m">443</span>/tcp
</pre></div>
</div>
</div><div aria-labelledby="tab-3-3-1" class="sphinx-tabs-panel" hidden="true" id="panel-3-3-1" name="3-1" role="tabpanel" tabindex="0"><div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>firewall-cmd<span class="w"> </span>--zone<span class="o">=</span>public<span class="w"> </span>--add-masquerade<span class="w"> </span>--permanent<span class="w"> </span><span class="se">\</span>
<span class="w">   </span><span class="o">&amp;&amp;</span><span class="w"> </span>firewall-cmd<span class="w"> </span>--zone<span class="o">=</span>public<span class="w"> </span>--add-port<span class="o">=</span><span class="m">443</span>/tcp
</pre></div>
</div>
</div></div>
<p>Reload the <code class="docutils literal notranslate"><span class="pre">firewalld</span></code> configuration and <code class="docutils literal notranslate"><span class="pre">dockerd</span></code> for the settings to take effect:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>firewall-cmd<span class="w"> </span>--reload<span class="w"> </span><span class="se">\</span>
<span class="w">   </span><span class="o">&amp;&amp;</span><span class="w"> </span>systemctl<span class="w"> </span>restart<span class="w"> </span>docker
</pre></div>
</div>
<p>Optionally, before we install the Kubernetes control plane, test your container networking using a simple <code class="docutils literal notranslate"><span class="pre">ping</span></code> command:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>docker<span class="w"> </span>run<span class="w"> </span>busybox<span class="w"> </span>ping<span class="w"> </span>google.com
</pre></div>
</div>
</section>
<section id="disable-swap">
<h5>Disable swap<a class="headerlink" href="#disable-swap" title="Permalink to this heading"></a></h5>
<p>For performance, disable swap on your system:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>swapoff<span class="w"> </span>-a
</pre></div>
</div>
</section>
</section>
<section id="step-1-install-docker">
<h4>Step 1: Install Docker<a class="headerlink" href="#step-1-install-docker" title="Permalink to this heading"></a></h4>
<p>Follow the steps in this <a class="reference external" href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html#setting-up-docker-on-centos-7-8">guide</a> to install Docker on CentOS 7/8.</p>
</section>
<section id="id3">
<h4>Step 2: Install Kubernetes Components<a class="headerlink" href="#id3" title="Permalink to this heading"></a></h4>
<p>Add the network repository listing to the package manager configuration:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>cat<span class="w"> </span>&lt;&lt;EOF<span class="w"> </span>&gt;<span class="w"> </span>/etc/yum.repos.d/kubernetes.repo
<span class="go">[kubernetes]</span>
<span class="go">name=Kubernetes</span>
<span class="go">baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64</span>
<span class="go">enabled=1</span>
<span class="go">gpgcheck=1</span>
<span class="go">repo_gpgcheck=1</span>
<span class="go">gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg</span>
<span class="go">EOF</span>
</pre></div>
</div>
<p>Install the components:</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-4-4-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-4-4-0" name="4-0" role="tab" tabindex="0">CentOS 8</button><button aria-controls="panel-4-4-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-4-4-1" name="4-1" role="tab" tabindex="-1">CentOS 7</button></div><div aria-labelledby="tab-4-4-0" class="sphinx-tabs-panel" id="panel-4-4-0" name="4-0" role="tabpanel" tabindex="0"><div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>dnf<span class="w"> </span>install<span class="w"> </span>-y<span class="w"> </span>kubelet<span class="w"> </span>kubectl<span class="w"> </span>kubeadm
</pre></div>
</div>
</div><div aria-labelledby="tab-4-4-1" class="sphinx-tabs-panel" hidden="true" id="panel-4-4-1" name="4-1" role="tabpanel" tabindex="0"><div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>yum<span class="w"> </span>install<span class="w"> </span>-y<span class="w"> </span>kubelet<span class="w"> </span>kubectl<span class="w"> </span>kubeadm
</pre></div>
</div>
</div></div>
<p>Ensure that <code class="docutils literal notranslate"><span class="pre">kubelet</span></code> is started across system reboots:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>systemctl<span class="w"> </span>--now<span class="w"> </span><span class="nb">enable</span><span class="w"> </span>kubelet
</pre></div>
</div>
<p>Now use <code class="docutils literal notranslate"><span class="pre">kubeadm</span></code> to initialize the control plane:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubeadm<span class="w"> </span>init<span class="w"> </span>--pod-network-cidr<span class="o">=</span><span class="m">192</span>.168.0.0/16
</pre></div>
</div>
<p>At this point, feel free to exit from the interactive <code class="docutils literal notranslate"><span class="pre">sudo</span></code> session that we started with.</p>
<section id="configure-directories">
<h5>Configure Directories<a class="headerlink" href="#configure-directories" title="Permalink to this heading"></a></h5>
<p>To start using the cluster, run the following as a regular user:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>mkdir<span class="w"> </span>-p<span class="w"> </span><span class="nv">$HOME</span>/.kube<span class="w"> </span><span class="se">\</span>
<span class="w">   </span><span class="o">&amp;&amp;</span><span class="w"> </span>sudo<span class="w"> </span>cp<span class="w"> </span>-i<span class="w"> </span>/etc/kubernetes/admin.conf<span class="w"> </span><span class="nv">$HOME</span>/.kube/config<span class="w"> </span><span class="se">\</span>
<span class="w">   </span><span class="o">&amp;&amp;</span><span class="w"> </span>sudo<span class="w"> </span>chown<span class="w"> </span><span class="k">$(</span>id<span class="w"> </span>-u<span class="k">)</span>:<span class="k">$(</span>id<span class="w"> </span>-g<span class="k">)</span><span class="w"> </span><span class="nv">$HOME</span>/.kube/config
</pre></div>
</div>
<p>If you’re using a simplistic cluster (or just testing), you can untaint the control plane node so that it can also run containers:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl<span class="w"> </span>taint<span class="w"> </span>nodes<span class="w"> </span>--all<span class="w"> </span>node-role.kubernetes.io/master-
</pre></div>
</div>
<p>At this point, your cluster would look like below:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl<span class="w"> </span>get<span class="w"> </span>pods<span class="w"> </span>-A
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">NAMESPACE     NAME                                                    READY   STATUS    RESTARTS   AGE</span>
<span class="go">kube-system   coredns-f9fd979d6-46hmf                                 0/1     Pending   0          23s</span>
<span class="go">kube-system   coredns-f9fd979d6-v7v4d                                 0/1     Pending   0          23s</span>
<span class="go">kube-system   etcd-ip-172-31-54-109.ec2.internal                      0/1     Running   0          38s</span>
<span class="go">kube-system   kube-apiserver-ip-172-31-54-109.ec2.internal            1/1     Running   0          38s</span>
<span class="go">kube-system   kube-controller-manager-ip-172-31-54-109.ec2.internal   0/1     Running   0          37s</span>
<span class="go">kube-system   kube-proxy-xd5zg                                        1/1     Running   0          23s</span>
<span class="go">kube-system   kube-scheduler-ip-172-31-54-109.ec2.internal            0/1     Running   0          37s</span>
</pre></div>
</div>
</section>
</section>
<section id="id4">
<h4>Step 3: Configure Networking<a class="headerlink" href="#id4" title="Permalink to this heading"></a></h4>
<p>For the purposes of this document, we will use Calico as a network plugin to configure networking in our Kubernetes cluster. Due to an
<a class="reference external" href="https://github.com/projectcalico/calico/issues/2322">issue</a> with Calico and iptables on CentOS, let’s modify the configuration before deploying the plugin.</p>
<p>Download the <code class="docutils literal notranslate"><span class="pre">calico</span></code> configuration:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>curl<span class="w"> </span>-fOSsL<span class="w"> </span>https://docs.projectcalico.org/manifests/calico.yaml
</pre></div>
</div>
<p>And add the following configuration options to the environment section:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">- name: FELIX_IPTABLESBACKEND</span>
<span class="go">  value: &quot;NFT&quot;</span>
</pre></div>
</div>
<p>Save the modified file and then deploy the plugin:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl<span class="w"> </span>apply<span class="w"> </span>-f<span class="w"> </span>./calico.yaml
</pre></div>
</div>
<p>After a few minutes, you can see that the networking has been configured:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">NAMESPACE     NAME                                                    READY   STATUS    RESTARTS   AGE</span>
<span class="go">kube-system   calico-kube-controllers-5c6f6b67db-wmts9                1/1     Running   0          99s</span>
<span class="go">kube-system   calico-node-fktnf                                       1/1     Running   0          100s</span>
<span class="go">kube-system   coredns-f9fd979d6-46hmf                                 1/1     Running   0          3m22s</span>
<span class="go">kube-system   coredns-f9fd979d6-v7v4d                                 1/1     Running   0          3m22s</span>
<span class="go">kube-system   etcd-ip-172-31-54-109.ec2.internal                      1/1     Running   0          3m37s</span>
<span class="go">kube-system   kube-apiserver-ip-172-31-54-109.ec2.internal            1/1     Running   0          3m37s</span>
<span class="go">kube-system   kube-controller-manager-ip-172-31-54-109.ec2.internal   1/1     Running   0          3m36s</span>
<span class="go">kube-system   kube-proxy-xd5zg                                        1/1     Running   0          3m22s</span>
<span class="go">kube-system   kube-scheduler-ip-172-31-54-109.ec2.internal            1/1     Running   0          3m36s</span>
</pre></div>
</div>
<p>To verify that networking has been setup successfully, let’s use the <code class="docutils literal notranslate"><span class="pre">multitool</span></code> container:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl<span class="w"> </span>run<span class="w"> </span>multitool<span class="w"> </span>--image<span class="o">=</span>praqma/network-multitool<span class="w"> </span>--restart<span class="w"> </span>Never
</pre></div>
</div>
<p>and then run a simple <code class="docutils literal notranslate"><span class="pre">ping</span></code> command to ensure that the DNS servers can be detected correctly:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl<span class="w"> </span><span class="nb">exec</span><span class="w"> </span>multitool<span class="w"> </span>--<span class="w"> </span>sh<span class="w"> </span>-c<span class="w"> </span><span class="s1">&#39;ping google.com&#39;</span>
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">PING google.com (172.217.9.206) 56(84) bytes of data.</span>
<span class="go">64 bytes from iad30s14-in-f14.1e100.net (172.217.9.206): icmp_seq=1 ttl=53 time=0.569 ms</span>
<span class="go">64 bytes from iad30s14-in-f14.1e100.net (172.217.9.206): icmp_seq=2 ttl=53 time=0.548 ms</span>
</pre></div>
</div>
</section>
</section>
<section id="step-4-setup-nvidia-software">
<h3>Step 4: Setup NVIDIA Software<a class="headerlink" href="#step-4-setup-nvidia-software" title="Permalink to this heading"></a></h3>
<p>At this point in our journey, you should have a working Kubernetes control plane and worker nodes attached to your cluster.
We can proceed to configure the NVIDIA software on the worker nodes. As described at the beginning of the document, there are
two options:</p>
<section id="nvidia-gpu-operator">
<span id="gpu-operator"></span><h4>NVIDIA GPU Operator<a class="headerlink" href="#nvidia-gpu-operator" title="Permalink to this heading"></a></h4>
<p>Use the <a class="reference external" href="https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/getting-started.html#install-nvidia-gpu-operator">NVIDIA GPU Operator</a>
to automatically setup and manage the NVIDIA software components on the worker nodes.</p>
<p>This is the preferred way as it provides a 1-click install experience.</p>
</section>
<section id="install-nvidia-dependencies">
<span id="nvdp"></span><h4>Install NVIDIA Dependencies<a class="headerlink" href="#install-nvidia-dependencies" title="Permalink to this heading"></a></h4>
<p>The GPU worker nodes in the Kubernetes cluster need to be enabled with the following components:</p>
<ol class="arabic simple">
<li><p>NVIDIA drivers</p></li>
<li><p>NVIDIA Container Toolkit</p></li>
<li><p>NVIDIA Kubernetes Device Plugin (and optionally GPU Feature Discovery plugin)</p></li>
<li><p>(Optional) DCGM-Exporter to gather GPU telemetry and integrate into a monitoring stack such as Prometheus</p></li>
</ol>
<p>Let’s walk through these steps.</p>
<section id="install-nvidia-drivers">
<h5>Install NVIDIA Drivers<a class="headerlink" href="#install-nvidia-drivers" title="Permalink to this heading"></a></h5>
<p>This section provides a summary of the steps for installing the driver using the <code class="docutils literal notranslate"><span class="pre">apt</span></code> package manager on Ubuntu LTS.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For complete instructions on setting up NVIDIA drivers, visit the quickstart guide at <a class="reference external" href="https://docs.nvidia.com/datacenter/tesla/tesla-installation-notes/index.html">https://docs.nvidia.com/datacenter/tesla/tesla-installation-notes/index.html</a>.
The guide covers a number of pre-installation requirements and steps on supported Linux distributions for a successful install of the driver.</p>
</div>
<p>Install the kernel headers and development packages for the currently running kernel:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>sudo<span class="w"> </span>apt-get<span class="w"> </span>install<span class="w"> </span>linux-headers-<span class="k">$(</span>uname<span class="w"> </span>-r<span class="k">)</span>
</pre></div>
</div>
<p>Setup the CUDA network repository and ensure packages on the CUDA network repository have priority over the Canonical repository:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span><span class="nv">distribution</span><span class="o">=</span><span class="k">$(</span>.<span class="w"> </span>/etc/os-release<span class="p">;</span><span class="nb">echo</span><span class="w"> </span><span class="nv">$ID$VERSION_ID</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>sed<span class="w"> </span>-e<span class="w"> </span><span class="s1">&#39;s/\.//g&#39;</span><span class="k">)</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span><span class="o">&amp;&amp;</span><span class="w"> </span>wget<span class="w"> </span>https://developer.download.nvidia.com/compute/cuda/repos/<span class="nv">$distribution</span>/x86_64/cuda-<span class="nv">$distribution</span>.pin<span class="w"> </span><span class="se">\</span>
<span class="w">   </span><span class="o">&amp;&amp;</span><span class="w"> </span>sudo<span class="w"> </span>mv<span class="w"> </span>cuda-<span class="nv">$distribution</span>.pin<span class="w"> </span>/etc/apt/preferences.d/cuda-repository-pin-600
</pre></div>
</div>
<p>Install the CUDA repository GPG key:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>sudo<span class="w"> </span>apt-key<span class="w"> </span>adv<span class="w"> </span>--fetch-keys<span class="w"> </span>https://developer.download.nvidia.com/compute/cuda/repos/<span class="nv">$distribution</span>/x86_64/7fa2af80.pub<span class="w"> </span><span class="se">\</span>
<span class="w">   </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;deb http://developer.download.nvidia.com/compute/cuda/repos/</span><span class="nv">$distribution</span><span class="s2">/x86_64 /&quot;</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>sudo<span class="w"> </span>tee<span class="w"> </span>/etc/apt/sources.list.d/cuda.list
</pre></div>
</div>
<p>Update the <code class="docutils literal notranslate"><span class="pre">apt</span></code> repository cache and install the driver using the <code class="docutils literal notranslate"><span class="pre">cuda-drivers</span></code> or <code class="docutils literal notranslate"><span class="pre">cuda-drivers-&lt;branch-number&gt;</span></code> meta-package.
Use the <code class="docutils literal notranslate"><span class="pre">--no-install-recommends</span></code> option for a lean driver install without any dependencies on X packages. This is particularly useful
for headless installations on cloud instances:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>sudo<span class="w"> </span>apt-get<span class="w"> </span>update<span class="w"> </span><span class="se">\</span>
<span class="w">   </span><span class="o">&amp;&amp;</span><span class="w"> </span>sudo<span class="w"> </span>apt-get<span class="w"> </span>-y<span class="w"> </span>install<span class="w"> </span>cuda-drivers
</pre></div>
</div>
</section>
<section id="install-nvidia-container-toolkit-nvidia-docker2">
<h5>Install NVIDIA Container Toolkit (<code class="docutils literal notranslate"><span class="pre">nvidia-docker2</span></code>)<a class="headerlink" href="#install-nvidia-container-toolkit-nvidia-docker2" title="Permalink to this heading"></a></h5>
<p>First, setup the <code class="docutils literal notranslate"><span class="pre">stable</span></code> repository for the NVIDIA runtime and the GPG key:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span><span class="nv">distribution</span><span class="o">=</span><span class="k">$(</span>.<span class="w"> </span>/etc/os-release<span class="p">;</span><span class="nb">echo</span><span class="w"> </span><span class="nv">$ID$VERSION_ID</span><span class="k">)</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span><span class="o">&amp;&amp;</span><span class="w"> </span>curl<span class="w"> </span>-s<span class="w"> </span>-L<span class="w"> </span>https://nvidia.github.io/nvidia-docker/gpgkey<span class="w"> </span><span class="p">|</span><span class="w"> </span>sudo<span class="w"> </span>apt-key<span class="w"> </span>add<span class="w"> </span>-<span class="w"> </span><span class="se">\</span>
<span class="w">   </span><span class="o">&amp;&amp;</span><span class="w"> </span>curl<span class="w"> </span>-s<span class="w"> </span>-L<span class="w"> </span>https://nvidia.github.io/nvidia-docker/<span class="nv">$distribution</span>/nvidia-docker.list<span class="w"> </span><span class="p">|</span><span class="w"> </span>sudo<span class="w"> </span>tee<span class="w"> </span>/etc/apt/sources.list.d/nvidia-docker.list
</pre></div>
</div>
<p>Depending on the container engine, you would need to use different packages.</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-5-5-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-5-5-0" name="5-0" role="tab" tabindex="0">Docker</button><button aria-controls="panel-5-5-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-5-5-1" name="5-1" role="tab" tabindex="-1">containerd</button></div><div aria-labelledby="tab-5-5-0" class="sphinx-tabs-panel" id="panel-5-5-0" name="5-0" role="tabpanel" tabindex="0"><p>Install the <code class="docutils literal notranslate"><span class="pre">nvidia-docker2</span></code> package (and its dependencies) after updating the package listing:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>sudo<span class="w"> </span>apt-get<span class="w"> </span>update<span class="w"> </span><span class="se">\</span>
<span class="w">   </span><span class="o">&amp;&amp;</span><span class="w"> </span>sudo<span class="w"> </span>apt-get<span class="w"> </span>install<span class="w"> </span>-y<span class="w"> </span>nvidia-docker2
</pre></div>
</div>
<p>Since Kubernetes does not support the <code class="docutils literal notranslate"><span class="pre">--gpus</span></code> option with Docker yet, the <code class="docutils literal notranslate"><span class="pre">nvidia</span></code> runtime should be setup as the
default container runtime for Docker on the GPU node. This can be done by adding the <code class="docutils literal notranslate"><span class="pre">default-runtime</span></code> line into the Docker daemon
config file, which is usually located on the system at <code class="docutils literal notranslate"><span class="pre">/etc/docker/daemon.json</span></code>:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">{</span>
<span class="go">   &quot;default-runtime&quot;: &quot;nvidia&quot;,</span>
<span class="go">   &quot;runtimes&quot;: {</span>
<span class="go">      &quot;nvidia&quot;: {</span>
<span class="go">            &quot;path&quot;: &quot;/usr/bin/nvidia-container-runtime&quot;,</span>
<span class="go">            &quot;runtimeArgs&quot;: []</span>
<span class="go">      }</span>
<span class="go">   }</span>
<span class="go">}</span>
</pre></div>
</div>
<p>Restart the Docker daemon to complete the installation after setting the default runtime:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>sudo<span class="w"> </span>systemctl<span class="w"> </span>restart<span class="w"> </span>docker
</pre></div>
</div>
<p>At this point, a working setup can be tested by running a base CUDA container:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>sudo<span class="w"> </span>docker<span class="w"> </span>run<span class="w"> </span>--rm<span class="w"> </span>--gpus<span class="w"> </span>all<span class="w"> </span>nvidia/cuda:11.0-base<span class="w"> </span>nvidia-smi
</pre></div>
</div>
<p>You should observe an output as shown below:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">+-----------------------------------------------------------------------------+</span>
<span class="go">| NVIDIA-SMI 450.51.06    Driver Version: 450.51.06    CUDA Version: 11.0     |</span>
<span class="go">|-------------------------------+----------------------+----------------------+</span>
<span class="go">| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |</span>
<span class="go">| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |</span>
<span class="go">|                               |                      |               MIG M. |</span>
<span class="go">|===============================+======================+======================|</span>
<span class="go">|   0  Tesla T4            On   | 00000000:00:1E.0 Off |                    0 |</span>
<span class="go">| N/A   34C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |</span>
<span class="go">|                               |                      |                  N/A |</span>
<span class="go">+-------------------------------+----------------------+----------------------+</span>

<span class="go">+-----------------------------------------------------------------------------+</span>
<span class="go">| Processes:                                                                  |</span>
<span class="go">|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |</span>
<span class="go">|        ID   ID                                                   Usage      |</span>
<span class="go">|=============================================================================|</span>
<span class="go">|  No running processes found                                                 |</span>
<span class="go">+-----------------------------------------------------------------------------+</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-5-5-1" class="sphinx-tabs-panel" hidden="true" id="panel-5-5-1" name="5-1" role="tabpanel" tabindex="0"><p>Install the <code class="docutils literal notranslate"><span class="pre">nvidia-container-runtime</span></code> package (and its dependencies) after updating the package listing:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>sudo<span class="w"> </span>apt-get<span class="w"> </span>update<span class="w"> </span><span class="se">\</span>
<span class="w">   </span><span class="o">&amp;&amp;</span><span class="w"> </span>sudo<span class="w"> </span>apt-get<span class="w"> </span>install<span class="w"> </span>-y<span class="w"> </span>nvidia-container-runtime
</pre></div>
</div>
<p>Next, <code class="docutils literal notranslate"><span class="pre">containerd</span></code>’s configuration file (<code class="docutils literal notranslate"><span class="pre">config.toml</span></code>) needs to be updated to set the default runtime to <em>nvidia</em>.
The new configuration changes are shown in the patch below:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>---<span class="w"> </span>config.toml<span class="w"> </span><span class="m">2020</span>-12-17<span class="w"> </span><span class="m">19</span>:13:03.242630735<span class="w"> </span>+0000
+++<span class="w"> </span>/etc/containerd/config.toml<span class="w"> </span><span class="m">2020</span>-12-17<span class="w"> </span><span class="m">19</span>:27:02.019027793<span class="w"> </span>+0000
@@<span class="w"> </span>-70,7<span class="w"> </span>+70,7<span class="w"> </span>@@
<span class="w">   </span><span class="nv">ignore_image_defined_volumes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">false</span>
<span class="w">   </span><span class="o">[</span>plugins.<span class="s2">&quot;io.containerd.grpc.v1.cri&quot;</span>.containerd<span class="o">]</span>
<span class="w">      </span><span class="nv">snapshotter</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;overlayfs&quot;</span>
-<span class="w">      </span><span class="nv">default_runtime_name</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;runc&quot;</span>
+<span class="w">      </span><span class="nv">default_runtime_name</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;nvidia&quot;</span>
<span class="w">      </span><span class="nv">no_pivot</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">false</span>
<span class="w">      </span><span class="nv">disable_snapshot_annotations</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">true</span>
<span class="w">      </span><span class="nv">discard_unpacked_layers</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">false</span>
@@<span class="w"> </span>-94,6<span class="w"> </span>+94,15<span class="w"> </span>@@
<span class="w">         </span><span class="nv">privileged_without_host_devices</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">false</span>
<span class="w">         </span><span class="nv">base_runtime_spec</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;&quot;</span>
<span class="w">         </span><span class="o">[</span>plugins.<span class="s2">&quot;io.containerd.grpc.v1.cri&quot;</span>.containerd.runtimes.runc.options<span class="o">]</span>
+<span class="w">            </span><span class="nv">SystemdCgroup</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">true</span>
+<span class="w">       </span><span class="o">[</span>plugins.<span class="s2">&quot;io.containerd.grpc.v1.cri&quot;</span>.containerd.runtimes.nvidia<span class="o">]</span>
+<span class="w">          </span><span class="nv">privileged_without_host_devices</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">false</span>
+<span class="w">          </span><span class="nv">runtime_engine</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;&quot;</span>
+<span class="w">          </span><span class="nv">runtime_root</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;&quot;</span>
+<span class="w">          </span><span class="nv">runtime_type</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;io.containerd.runc.v1&quot;</span>
+<span class="w">          </span><span class="o">[</span>plugins.<span class="s2">&quot;io.containerd.grpc.v1.cri&quot;</span>.containerd.runtimes.nvidia.options<span class="o">]</span>
+<span class="w">            </span><span class="nv">BinaryName</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;/usr/bin/nvidia-container-runtime&quot;</span>
+<span class="w">            </span><span class="nv">SystemdCgroup</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">true</span>
<span class="w">   </span><span class="o">[</span>plugins.<span class="s2">&quot;io.containerd.grpc.v1.cri&quot;</span>.cni<span class="o">]</span>
<span class="w">      </span><span class="nv">bin_dir</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;/opt/cni/bin&quot;</span>
<span class="w">      </span><span class="nv">conf_dir</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;/etc/cni/net.d&quot;</span>
</pre></div>
</div>
<p>Finally, restart <code class="docutils literal notranslate"><span class="pre">containerd</span></code>:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>sudo<span class="w"> </span>systemctl<span class="w"> </span>restart<span class="w"> </span>containerd
</pre></div>
</div>
</div></div>
</section>
<section id="install-nvidia-device-plugin">
<h5>Install NVIDIA Device Plugin<a class="headerlink" href="#install-nvidia-device-plugin" title="Permalink to this heading"></a></h5>
<p>To use GPUs in Kubernetes, the <a class="reference external" href="https://github.com/NVIDIA/k8s-device-plugin/">NVIDIA Device Plugin</a> is required.
The NVIDIA Device Plugin is a daemonset that automatically enumerates the number of GPUs on each node of the cluster
and allows pods to be run on GPUs.</p>
<p>The preferred method to deploy the device plugin is as a daemonset using <code class="docutils literal notranslate"><span class="pre">helm</span></code>. First, install Helm:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>curl<span class="w"> </span>-fsSL<span class="w"> </span>-o<span class="w"> </span>get_helm.sh<span class="w"> </span>https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3<span class="w"> </span><span class="se">\</span>
<span class="w">   </span><span class="o">&amp;&amp;</span><span class="w"> </span>chmod<span class="w"> </span><span class="m">700</span><span class="w"> </span>get_helm.sh<span class="w"> </span><span class="se">\</span>
<span class="w">   </span><span class="o">&amp;&amp;</span><span class="w"> </span>./get_helm.sh
</pre></div>
</div>
<p>Add the <code class="docutils literal notranslate"><span class="pre">nvidia-device-plugin</span></code> <code class="docutils literal notranslate"><span class="pre">helm</span></code> repository:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>helm<span class="w"> </span>repo<span class="w"> </span>add<span class="w"> </span>nvdp<span class="w"> </span>https://nvidia.github.io/k8s-device-plugin<span class="w"> </span><span class="se">\</span>
<span class="w">   </span><span class="o">&amp;&amp;</span><span class="w"> </span>helm<span class="w"> </span>repo<span class="w"> </span>update
</pre></div>
</div>
<p>Deploy the device plugin:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>helm<span class="w"> </span>install<span class="w"> </span>--generate-name<span class="w"> </span>nvdp/nvidia-device-plugin
</pre></div>
</div>
<p>For more user configurable options while deploying the daemonset, refer to the <a class="reference external" href="https://github.com/NVIDIA/k8s-device-plugin/#deployment-via-helm">documentation</a></p>
<p>At this point, all the pods should be deployed:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl<span class="w"> </span>get<span class="w"> </span>pods<span class="w"> </span>-A
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">NAMESPACE     NAME                                       READY   STATUS      RESTARTS   AGE</span>
<span class="go">kube-system   calico-kube-controllers-5fbfc9dfb6-2ttkk   1/1     Running     3          9d</span>
<span class="go">kube-system   calico-node-5vfcb                          1/1     Running     3          9d</span>
<span class="go">kube-system   coredns-66bff467f8-jzblc                   1/1     Running     4          9d</span>
<span class="go">kube-system   coredns-66bff467f8-l85sz                   1/1     Running     3          9d</span>
<span class="go">kube-system   etcd-ip-172-31-81-185                      1/1     Running     4          9d</span>
<span class="go">kube-system   kube-apiserver-ip-172-31-81-185            1/1     Running     3          9d</span>
<span class="go">kube-system   kube-controller-manager-ip-172-31-81-185   1/1     Running     3          9d</span>
<span class="go">kube-system   kube-proxy-86vlr                           1/1     Running     3          9d</span>
<span class="go">kube-system   kube-scheduler-ip-172-31-81-185            1/1     Running     4          9d</span>
<span class="go">kube-system   nvidia-device-plugin-1595448322-42vgf      1/1     Running     2          9d</span>
</pre></div>
</div>
<p>To test whether CUDA jobs can be deployed, run a sample CUDA <code class="docutils literal notranslate"><span class="pre">vectorAdd</span></code> application:</p>
<p>The pod spec is shown for reference below, which requests 1 GPU:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Pod</span>
<span class="nt">metadata</span><span class="p">:</span>
<span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">gpu-operator-test</span>
<span class="nt">spec</span><span class="p">:</span>
<span class="w">  </span><span class="nt">restartPolicy</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">OnFailure</span>
<span class="w">  </span><span class="nt">containers</span><span class="p">:</span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">cuda-vector-add</span>
<span class="w">    </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;nvidia/samples:vectoradd-cuda10.2&quot;</span>
<span class="w">    </span><span class="nt">resources</span><span class="p">:</span>
<span class="w">      </span><span class="nt">limits</span><span class="p">:</span>
<span class="w">         </span><span class="nt">nvidia.com/gpu</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
</pre></div>
</div>
<p>Save this podspec as <code class="docutils literal notranslate"><span class="pre">gpu-pod.yaml</span></code>. Now, deploy the application:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl<span class="w"> </span>apply<span class="w"> </span>-f<span class="w"> </span>gpu-pod.yaml
</pre></div>
</div>
<p>Check the logs to ensure the app completed successfully:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl<span class="w"> </span>get<span class="w"> </span>pods<span class="w"> </span>gpu-operator-test
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">NAME                READY   STATUS      RESTARTS   AGE</span>
<span class="go">gpu-operator-test   0/1     Completed   0          9d</span>
</pre></div>
</div>
<p>And check the logs of the <code class="docutils literal notranslate"><span class="pre">gpu-operator-test</span></code> pod:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl<span class="w"> </span>logs<span class="w"> </span>gpu-operator-test
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">[Vector addition of 50000 elements]</span>
<span class="go">Copy input data from the host memory to the CUDA device</span>
<span class="go">CUDA kernel launch with 196 blocks of 256 threads</span>
<span class="go">Copy output data from the CUDA device to the host memory</span>
<span class="go">Test PASSED</span>
<span class="go">Done</span>
</pre></div>
</div>
</section>
<section id="gpu-telemetry">
<h5>GPU Telemetry<a class="headerlink" href="#gpu-telemetry" title="Permalink to this heading"></a></h5>
<p>Refer to the <a class="reference external" href="https://docs.nvidia.com/datacenter/cloud-native/gpu-telemetry/dcgm-exporter.html#integrating-gpu-telemetry-into-kubernetes.html">DCGM-Exporter</a> documentation
to get started with integrating GPU metrics into a Prometheus monitoring system.</p>
</section>
</section>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../gpu-operator/archive/1.8/appendix.html" class="btn btn-neutral float-left" title="Appendix" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="mig-k8s.html" class="btn btn-neutral float-right" title="MIG Support in Kubernetes" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2018-2023, NVIDIA Corporation.
      <span class="lastupdated">Last updated on 2023-02-22.
      </span></p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>  

  <style>
  a:link, a:visited {
    color: #76b900;
  }

  a:hover {
    color: #8c0;
  }

  .rst-content dl:not(.docutils) dt {
    background: rgba(118, 185, 0, 0.1);
    color: rgba(59,93,0,1);
    border-top: solid 3px rgba(59,93,0,1);
  }
  </style>
  

</body>
</html>