<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Install NVIDIA GPU Operator &mdash; NVIDIA Cloud Native Technologies  documentation</title>
      <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/tabs.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/custom.css" type="text/css" />
    <link rel="shortcut icon" href="../../../_static/nvidia.ico"/>
    <link rel="canonical" href="https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/archive/1.11.1/install-gpu-operator.html"/>
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script src="../../../_static/sphinx_highlight.js"></script>
        <script src="../../../_static/clipboard.min.js"></script>
        <script src="../../../_static/copybutton.js"></script>
        <script src="../../../_static/js/google-analytics/google-analytics-tracker.js"></script>
        <script src="../../../_static/js/google-analytics/google-analytics-write.js"></script>
        <script src="//assets.adobedtm.com/b92787824f2e0e9b68dc2e993f9bd995339fe417/satelliteLib-7ba51e58dc61bcb0e9311aadd02a0108ab24cc6c.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" > 
            <a href="../../../contents.html">
            <img src="../../../_static/NVLogo_H_B&W.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

  <style>
    /* Sidebar header (and topbar for mobile) */
    .wy-side-nav-search, .wy-nav-top {
      background: #76b900;
    }

    .wy-side-nav-search a:link, .wy-nav-top a:link {
      color: #fff;
    }
    .wy-side-nav-search a:visited, .wy-nav-top a:visited {
      color: #fff;
    }
    .wy-side-nav-search a:hover, .wy-nav-top a:hover {
      color: #fff;
    }

    .wy-menu-vertical a:link, .wy-menu-vertical a:visited {
      color: #d9d9d9
    }

    .wy-menu-vertical a:active {
      background-color: #76b900
    }

    .wy-side-nav-search>div.version {
      color: rgba(0, 0, 0, 0.3)
    }

    .wy-nav-content {
      max-width: 1000px;
    }
  </style>
  
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">NVIDIA Container Toolkit</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../container-toolkit/overview.html">Overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../container-toolkit/overview.html#architecture">Architecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../container-toolkit/overview.html#installation-guide">Installation Guide</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../container-toolkit/overview.html#troubleshooting-guide">Troubleshooting Guide</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../container-toolkit/overview.html#user-guide">User Guide</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../container-toolkit/overview.html#license">License</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../container-toolkit/concepts.html">Concepts</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../container-toolkit/concepts.html#what-is-docker">What is Docker?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../container-toolkit/concepts.html#motivation">Motivation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../container-toolkit/arch-overview.html">Architecture Overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../container-toolkit/arch-overview.html#components-and-packages">Components and Packages</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../container-toolkit/arch-overview.html#which-package-should-i-use-then">Which package should I use then?</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../container-toolkit/install-guide.html">Installation Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../container-toolkit/install-guide.html#supported-platforms">Supported Platforms</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../container-toolkit/install-guide.html#pre-requisites">Pre-Requisites</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../container-toolkit/install-guide.html#container-device-interface-cdi-support">Container Device Interface (CDI) Support</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../container-toolkit/install-guide.html#docker">Docker</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../container-toolkit/install-guide.html#id6">containerd</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../container-toolkit/install-guide.html#id9">podman</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../container-toolkit/troubleshooting.html">Troubleshooting</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../container-toolkit/troubleshooting.html#conflicting-values-set-for-option-signed-by-error-when-running-apt-update">Conflicting values set for option Signed-By error when running <code class="docutils literal notranslate"><span class="pre">apt</span> <span class="pre">update</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../container-toolkit/troubleshooting.html#permission-denied-error-when-running-the-nvidia-docker-wrapper-under-selinux">Permission denied error when running the <code class="docutils literal notranslate"><span class="pre">nvidia-docker</span></code> wrapper under SELinux</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../container-toolkit/user-guide.html">User Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../container-toolkit/user-guide.html#id2">Docker</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../container-toolkit/release-notes.html">Release Notes</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../container-toolkit/release-notes.html#nvidia-container-toolkit-1-12-0">NVIDIA Container Toolkit 1.12.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../container-toolkit/release-notes.html#nvidia-container-toolkit-1-11-0">NVIDIA Container Toolkit 1.11.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../container-toolkit/release-notes.html#nvidia-container-toolkit-1-10-0">NVIDIA Container Toolkit 1.10.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../container-toolkit/release-notes.html#nvidia-container-toolkit-1-9-0">NVIDIA Container Toolkit 1.9.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../container-toolkit/release-notes.html#nvidia-container-toolkit-1-8-1">NVIDIA Container Toolkit 1.8.1</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../container-toolkit/release-notes.html#nvidia-container-toolkit-1-8-0">NVIDIA Container Toolkit 1.8.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../container-toolkit/release-notes.html#nvidia-container-toolkit-1-7-0">NVIDIA Container Toolkit 1.7.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../container-toolkit/release-notes.html#nvidia-container-toolkit-1-6-0">NVIDIA Container Toolkit 1.6.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../container-toolkit/release-notes.html#toolkit-container-1-7-0">Toolkit Container 1.7.0</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../container-toolkit/archive.html">Archive</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../container-toolkit/archive.html#id1">1.11.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../container-toolkit/archive.html#id2">1.10.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../container-toolkit/archive.html#id3">1.9.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../container-toolkit/archive.html#id4">1.8.1</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../container-toolkit/archive.html#id5">1.8.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../container-toolkit/archive.html#id6">1.7.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../container-toolkit/archive.html#id7">1.6.0</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">NVIDIA GPU Operator</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../about.html">About the Operator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../platform-support.html">Platform Support</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../platform-support.html#nvidia-gpu-operator-versioning">NVIDIA GPU Operator Versioning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../platform-support.html#nvidia-gpu-operator-life-cycle">NVIDIA GPU Operator Life Cycle</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../platform-support.html#gpu-operator-component-matrix">GPU Operator Component Matrix</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../platform-support.html#supported-nvidia-gpus-and-systems">Supported NVIDIA GPUs and Systems</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../platform-support.html#supported-arm-based-platforms">Supported ARM Based Platforms</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../platform-support.html#supported-deployment-options-hypervisors-and-nvidia-vgpu-based-products">Supported Deployment Options, Hypervisors, and NVIDIA vGPU Based Products</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../platform-support.html#supported-operating-systems-and-kubernetes-platforms">Supported Operating Systems and Kubernetes Platforms</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../platform-support.html#supported-container-runtimes">Supported Container Runtimes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../platform-support.html#nvidia-ai-enterprise-support-matrix">NVIDIA AI Enterprise Support Matrix</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../platform-support.html#support-for-kubevirt">Support for KubeVirt</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../platform-support.html#support-for-gpudirect-rdma">Support for GPUDirect RDMA</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../platform-support.html#support-for-gpudirect-storage">Support for GPUDirect Storage</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../platform-support.html#additional-supported-container-management-tools">Additional Supported Container Management Tools</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../platform-support.html#previous-gpu-operator-releases">Previous GPU Operator Releases</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../release-notes.html">Release Notes</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../release-notes.html#id1">22.9.2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../release-notes.html#id2">22.9.1</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../release-notes.html#id9">22.9.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../release-notes.html#id19">1.11.1</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../release-notes.html#id24">1.11.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../release-notes.html#id29">1.10.1</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../release-notes.html#id34">1.10.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../release-notes.html#id41">1.9.1</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../release-notes.html#id44">1.9.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../release-notes.html#id49">1.8.2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../release-notes.html#id53">1.8.1</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../release-notes.html#id55">1.8.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../release-notes.html#id60">1.7.1</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../release-notes.html#id62">1.7.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../release-notes.html#id67">1.6.2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../release-notes.html#id69">1.6.1</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../release-notes.html#id71">1.6.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../release-notes.html#id76">1.5.2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../release-notes.html#id79">1.5.1</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../release-notes.html#id82">1.5.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../release-notes.html#id87">1.4.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../release-notes.html#id92">1.3.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../release-notes.html#id97">1.2.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../release-notes.html#id102">1.1.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../release-notes.html#id106">1.0.0</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../installation.html">Installation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../installation.html#prerequisites">Prerequisites</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../installation.html#install-nvidia-gpu-operator">Install NVIDIA GPU Operator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../installation.html#running-sample-gpu-applications">Running Sample GPU Applications</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../getting-started.html">Getting Started</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../getting-started.html#red-hat-openshift-4">Red Hat OpenShift 4</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../getting-started.html#vmware-vsphere-with-tanzu">VMware vSphere with Tanzu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../getting-started.html#google-cloud-anthos">Google Cloud Anthos</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../getting-started.html#prerequisites">Prerequisites</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../getting-started.html#install-kubernetes">Install Kubernetes</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../getting-started.html#install-nvidia-gpu-operator">Install NVIDIA GPU Operator</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../getting-started.html#install-helm">Install Helm</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../getting-started.html#install-the-gpu-operator">Install the GPU Operator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../getting-started.html#common-deployment-scenarios">Common Deployment Scenarios</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../getting-started.html#running-sample-gpu-applications">Running Sample GPU Applications</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../getting-started.html#demo">Demo</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../getting-started.html#gpu-telemetry">GPU Telemetry</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../getting-started.html#upgrade">Upgrade</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../getting-started.html#uninstall">Uninstall</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../gpu-driver-upgrades.html">GPU Driver Upgrades</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../gpu-driver-upgrades.html#introduction">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../gpu-driver-upgrades.html#upgrades-with-the-upgrade-controller">Upgrades with the Upgrade Controller</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../gpu-driver-upgrades.html#upgrades-without-the-upgrade-controller">Upgrades without the Upgrade Controller</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../advanced-configurations.html">Advanced Configurations</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../install-gpu-operator-vgpu.html">NVIDIA vGPU</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../gpu-operator-rdma.html">GPUDirect RDMA and GPUDirect Storage</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../install-gpu-operator-nvaie.html">NVIDIA AI Enterprise</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../gpu-operator-mig.html">GPU Operator with MIG</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../gpu-sharing.html">Time-Slicing GPUs in Kubernetes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../gpu-operator-kubevirt.html">GPU Operator with KubeVirt</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../openshift/contents.html">GPU Operator on OpenShift</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../openshift/introduction.html">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../openshift/prerequisites.html">Prerequisites</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../openshift/steps-overview.html">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../openshift/install-nfd.html">Installing the Node Feature Discovery (NFD) Operator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../openshift/install-gpu-ocp.html">Installing the NVIDIA GPU Operator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../openshift/nvaie-with-ocp.html">NVIDIA AI Enterprise with OpenShift</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../openshift/mig-ocp.html">MIG Support in OpenShift Container Platform</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../openshift/clean-up.html">Cleanup</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../openshift/mirror-gpu-ocp-disconnected.html">Deploy GPU Operators in a disconnected or airgapped environment</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../openshift/enable-gpu-op-dashboard.html">Enable the GPU Operator Dashboard</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../openshift/time-slicing-gpus-in-openshift.html">Time-slicing NVIDIA GPUs in OpenShift</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../openshift/openshift-virtualization.html">NVIDIA GPU Operator with OpenShift Virtualization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../openshift/troubleshooting-gpu-ocp.html">Troubleshooting</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../openshift/appendix-ocp.html">Appendix</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../appendix.html">Appendix</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../appendix.html#install-gpu-operator-in-proxy-environments">Install GPU Operator in Proxy Environments</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../appendix.html#install-gpu-operator-in-air-gapped-environments">Install GPU Operator in Air-gapped Environments</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../appendix.html#considerations-when-installing-with-outdated-kernels-in-cluster">Considerations when Installing with Outdated Kernels in Cluster</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../appendix.html#customizing-nvidia-gpu-driver-parameters-during-installation">Customizing NVIDIA GPU Driver Parameters during Installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../appendix.html#installing-precompiled-and-canonical-signed-drivers-on-ubuntu-20-04-and-22-04">Installing Precompiled and Canonical Signed Drivers on Ubuntu 20.04 and 22.04</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../license.html">Licenses and Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../archive.html">Archive</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../archive.html#id1">22.9.1</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../archive.html#id2">22.9.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../archive.html#id3">1.11.1</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../archive.html#id4">1.11.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../archive.html#id5">1.10.1</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../archive.html#id6">1.9.1</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../archive.html#id7">1.9.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../archive.html#id8">1.8</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Kubernetes with GPUs</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../kubernetes/install-k8s.html">Install Kubernetes</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../kubernetes/install-k8s.html#introduction">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../kubernetes/install-k8s.html#option-1-installing-kubernetes-using-deepops">Option 1: Installing Kubernetes Using DeepOps</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../kubernetes/install-k8s.html#option-2-installing-kubernetes-using-kubeadm">Option 2: Installing Kubernetes Using Kubeadm</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../kubernetes/mig-k8s.html">MIG Support in Kubernetes</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../kubernetes/mig-k8s.html#mig-strategies">MIG Strategies</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../kubernetes/mig-k8s.html#using-mig-strategies-in-kubernetes">Using MIG Strategies in Kubernetes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../kubernetes/mig-k8s.html#testing-with-different-strategies">Testing with Different Strategies</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../kubernetes/anthos-guide.html">NVIDIA GPUs with Google Cloud’s Anthos</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../kubernetes/anthos-guide.html#changelog">Changelog</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../kubernetes/anthos-guide.html#introduction">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../kubernetes/anthos-guide.html#deployment-configurations">Deployment Configurations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../kubernetes/anthos-guide.html#supported-platforms">Supported Platforms</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../kubernetes/anthos-guide.html#getting-support">Getting Support</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../kubernetes/anthos-guide.html#anthos-clusters-on-bare-metal-with-nvidia-dgx-systems-and-gpu-accelerated-servers">Anthos Clusters on Bare Metal with NVIDIA DGX Systems and GPU-Accelerated Servers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../kubernetes/anthos-guide.html#anthos-clusters-with-vmware-and-nvidia-gpu-accelerated-servers">Anthos Clusters with VMware and NVIDIA GPU Accelerated Servers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../kubernetes/anthos-guide.html#install-nvidia-gpu-operator">Install NVIDIA GPU Operator</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">GPU Telemetry</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../gpu-telemetry/dcgm-exporter.html">DCGM-Exporter</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../gpu-telemetry/dcgm-exporter.html#introduction">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../gpu-telemetry/dcgm-exporter.html#getting-started">Getting Started</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../gpu-telemetry/dcgm-exporter.html#multi-instance-gpu-mig-support">Multi-Instance GPU (MIG) Support</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../gpu-telemetry/dcgm-exporter.html#integrating-gpu-telemetry-into-kubernetes">Integrating GPU Telemetry into Kubernetes</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../gpu-telemetry/dcgm-exporter.html#nvidia-drivers">NVIDIA Drivers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../gpu-telemetry/dcgm-exporter.html#install-docker">Install Docker</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../gpu-telemetry/dcgm-exporter.html#install-nvidia-container-toolkit-previously-nvidia-docker2">Install NVIDIA Container Toolkit (previously <code class="docutils literal notranslate"><span class="pre">nvidia-docker2</span></code>)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../gpu-telemetry/dcgm-exporter.html#install-kubernetes">Install Kubernetes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../gpu-telemetry/dcgm-exporter.html#install-nvidia-device-plugin">Install NVIDIA Device Plugin</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../gpu-telemetry/dcgm-exporter.html#gpu-telemetry">GPU Telemetry</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Multi-Instance GPU</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../mig/mig.html">Multi-Instance GPU</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../mig/mig.html#introduction">Introduction</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../mig/mig-k8s.html">MIG Support in Kubernetes</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../mig/mig-k8s.html#software-pre-requisites">Software Pre-requisites</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../mig/mig-k8s.html#getting-started">Getting Started</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Driver Containers</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../driver-containers/overview.html">Overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../driver-containers/overview.html#pre-requisites">Pre-requisites</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../driver-containers/overview.html#configuration">Configuration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../driver-containers/overview.html#quickstart">Quickstart</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../driver-containers/overview.html#container-images">Container Images</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../driver-containers/overview.html#licenses-and-contributing">Licenses and Contributing</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Playground</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../playground/dind.html">Docker-in-Docker</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../playground/x-arch.html">Running Cross-Architecture Containers</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../playground/x-arch.html#emulation-environment">Emulation Environment</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../contents.html">NVIDIA Cloud Native Technologies</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../contents.html" class="icon icon-home"></a> &raquo;</li>
      <li>Install NVIDIA GPU Operator</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="install-nvidia-gpu-operator">
<span id="install-gpu-operator-1-11-1"></span><h1>Install NVIDIA GPU Operator<a class="headerlink" href="#install-nvidia-gpu-operator" title="Permalink to this heading"></a></h1>
<section id="install-helm">
<h2>Install Helm<a class="headerlink" href="#install-helm" title="Permalink to this heading"></a></h2>
<p>The preferred method to deploy the GPU Operator is using <code class="docutils literal notranslate"><span class="pre">helm</span></code>.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>curl<span class="w"> </span>-fsSL<span class="w"> </span>-o<span class="w"> </span>get_helm.sh<span class="w"> </span>https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3<span class="w"> </span><span class="se">\</span>
<span class="w">   </span><span class="o">&amp;&amp;</span><span class="w"> </span>chmod<span class="w"> </span><span class="m">700</span><span class="w"> </span>get_helm.sh<span class="w"> </span><span class="se">\</span>
<span class="w">   </span><span class="o">&amp;&amp;</span><span class="w"> </span>./get_helm.sh
</pre></div>
</div>
<p>Now, add the NVIDIA Helm repository:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>helm<span class="w"> </span>repo<span class="w"> </span>add<span class="w"> </span>nvidia<span class="w"> </span>https://helm.ngc.nvidia.com/nvidia<span class="w"> </span><span class="se">\</span>
<span class="w">   </span><span class="o">&amp;&amp;</span><span class="w"> </span>helm<span class="w"> </span>repo<span class="w"> </span>update
</pre></div>
</div>
</section>
<section id="install-the-gpu-operator">
<h2>Install the GPU Operator<a class="headerlink" href="#install-the-gpu-operator" title="Permalink to this heading"></a></h2>
<p>The GPU Operator Helm chart offers a number of customizable options that can be configured depending on your environment.</p>
<div class="align-default"><img height="120" src="../../../_images/blockdiag-9ab121b0af6e54db8e70aef1d4d49cd964af7cd7.png" width="640" /></div>
<section id="chart-customization-options">
<span id="gpu-operator-helm-chart-options-1-11-1"></span><h3>Chart Customization Options<a class="headerlink" href="#chart-customization-options" title="Permalink to this heading"></a></h3>
<p>The following options are available when using the Helm chart. These options can be used with <code class="docutils literal notranslate"><span class="pre">--set</span></code> when installing via Helm.</p>
<table class="colwidths-auto docutils align-center">
<thead>
<tr class="row-odd"><th class="head"><p>Parameter</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Default</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">nfd.enabled</span></code></p></td>
<td><p>Deploys Node Feature Discovery plugin as a daemonset.
Set this variable to <code class="docutils literal notranslate"><span class="pre">false</span></code> if NFD is already running in the cluster.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">true</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">operator.defaultRuntime</span></code></p></td>
<td><p><strong>DEPRECATED as of v1.9</strong></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">docker</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">mig.strategy</span></code></p></td>
<td><p>Controls the strategy to be used with MIG on supported NVIDIA GPUs. Options
are either <code class="docutils literal notranslate"><span class="pre">mixed</span></code> or <code class="docutils literal notranslate"><span class="pre">single</span></code>.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">single</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">psp.enabled</span></code></p></td>
<td><p>The GPU operator deploys <code class="docutils literal notranslate"><span class="pre">PodSecurityPolicies</span></code> if enabled.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">false</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">driver.enabled</span></code></p></td>
<td><p>By default, the Operator deploys NVIDIA drivers as a container on the system.
Set this value to <code class="docutils literal notranslate"><span class="pre">false</span></code> when using the Operator on systems with pre-installed drivers.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">true</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">driver.repository</span></code></p></td>
<td><p>The images are downloaded from NGC. Specify another image repository when using
custom driver images.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nvcr.io/nvidia</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">driver.version</span></code></p></td>
<td><p>Version of the NVIDIA datacenter driver supported by the Operator.</p></td>
<td><p>Depends on the version of the Operator. See the Component Matrix
for more information on supported drivers.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">driver.rdma.enabled</span></code></p></td>
<td><p>Controls whether the driver daemonset should build and load the <code class="docutils literal notranslate"><span class="pre">nvidia-peermem</span></code> kernel module.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">false</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">driver.rdma.useHostMofed</span></code></p></td>
<td><p>Indicate if MOFED is directly pre-installed on the host. This is used to build and load <code class="docutils literal notranslate"><span class="pre">nvidia-peermem</span></code> kernel module.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">false</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">toolkit.enabled</span></code></p></td>
<td><p>By default, the Operator deploys the NVIDIA Container Toolkit (<code class="docutils literal notranslate"><span class="pre">nvidia-docker2</span></code> stack)
as a container on the system. Set this value to <code class="docutils literal notranslate"><span class="pre">false</span></code> when using the Operator on systems
with pre-installed NVIDIA runtimes.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">true</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">migManager.enabled</span></code></p></td>
<td><p>The MIG manager watches for changes to the MIG geometry and applies reconfiguration as needed. By
default, the MIG manager only runs on nodes with GPUs that support MIG (for e.g. A100).</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">true</span></code></p></td>
</tr>
</tbody>
</table>
</section>
<section id="namespace">
<h3>Namespace<a class="headerlink" href="#namespace" title="Permalink to this heading"></a></h3>
<p>Prior to GPU Operator v1.9, the operator was installed in the <code class="docutils literal notranslate"><span class="pre">default</span></code> namespace while all operands were
installed in the <code class="docutils literal notranslate"><span class="pre">gpu-operator-resources</span></code> namespace.</p>
<p>Starting with GPU Operator v1.9, both the operator and operands get installed in the same namespace.
The namespace is configurable and is determined during installation. For example, to install the GPU Operator
in the <code class="docutils literal notranslate"><span class="pre">gpu-operator</span></code> namespace:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>helm<span class="w"> </span>install<span class="w"> </span>--wait<span class="w"> </span>--generate-name<span class="w"> </span><span class="se">\</span>
<span class="w">     </span>-n<span class="w"> </span>gpu-operator<span class="w"> </span>--create-namespace<span class="w"> </span><span class="se">\</span>
<span class="w">     </span>nvidia/gpu-operator
</pre></div>
</div>
<p>If a namespace is not specified during installation, all GPU Operator components will be installed in the
<code class="docutils literal notranslate"><span class="pre">default</span></code> namespace.</p>
</section>
<section id="operands">
<h3>Operands<a class="headerlink" href="#operands" title="Permalink to this heading"></a></h3>
<p>By default, the GPU Operator operands are deployed on all GPU worker nodes in the cluster.
GPU worker nodes are identified by the presence of the label <code class="docutils literal notranslate"><span class="pre">feature.node.kubernetes.io/pci-10de.present=true</span></code>,
where <code class="docutils literal notranslate"><span class="pre">0x10de</span></code> is the PCI vendor ID assigned to NVIDIA.</p>
<p>To disable operands from getting deployed on a GPU worker node, label the node with <code class="docutils literal notranslate"><span class="pre">nvidia.com/gpu.deploy.operands=false</span></code>.
This can be useful when dedicating a GPU worker node for non-container workloads (i.e. KubeVirt VMs).</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl<span class="w"> </span>label<span class="w"> </span>nodes<span class="w"> </span><span class="nv">$NODE</span><span class="w"> </span>nvidia.com/gpu.deploy.operands<span class="o">=</span><span class="nb">false</span>
</pre></div>
</div>
</section>
<section id="common-deployment-scenarios">
<h3>Common Deployment Scenarios<a class="headerlink" href="#common-deployment-scenarios" title="Permalink to this heading"></a></h3>
<p>In this section, we present some common deployment recipes when using the Helm chart to install the GPU Operator.</p>
<section id="bare-metal-passthrough-with-default-configurations-on-ubuntu">
<h4>Bare-metal/Passthrough with default configurations on Ubuntu<a class="headerlink" href="#bare-metal-passthrough-with-default-configurations-on-ubuntu" title="Permalink to this heading"></a></h4>
<p>In this scenario, the default configuration options are used:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>helm<span class="w"> </span>install<span class="w"> </span>--wait<span class="w"> </span>--generate-name<span class="w"> </span><span class="se">\</span>
<span class="w">     </span>-n<span class="w"> </span>gpu-operator<span class="w"> </span>--create-namespace<span class="w"> </span><span class="se">\</span>
<span class="w">     </span>nvidia/gpu-operator
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>For installing on Secure Boot systems or using Precompiled modules refer to <a class="reference internal" href="install-precompiled-signed-drivers.html#install-precompiled-signed-drivers-1-11-1"><span class="std std-ref">Installing Precompiled and Canonical Signed Drivers on Ubuntu20.04</span></a>.</p></li>
</ul>
</div>
</section>
<section id="bare-metal-passthrough-with-default-configurations-on-centos">
<h4>Bare-metal/Passthrough with default configurations on CentOS<a class="headerlink" href="#bare-metal-passthrough-with-default-configurations-on-centos" title="Permalink to this heading"></a></h4>
<p>In this scenario, the CentOS toolkit image is used:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>helm<span class="w"> </span>install<span class="w"> </span>--wait<span class="w"> </span>--generate-name<span class="w"> </span><span class="se">\</span>
<span class="w">     </span>-n<span class="w"> </span>gpu-operator<span class="w"> </span>--create-namespace<span class="w"> </span><span class="se">\</span>
<span class="w">     </span>nvidia/gpu-operator<span class="w"> </span><span class="se">\</span>
<span class="w">     </span>--set<span class="w"> </span>toolkit.version<span class="o">=</span><span class="m">1</span>.7.1-centos7
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>For CentOS 8 systems, use <cite>toolkit.version=1.7.1-centos8</cite>.</p></li>
<li><p>Replace <cite>1.7.1</cite> toolkit version used here with the latest one available <a class="reference external" href="https://ngc.nvidia.com/catalog/containers/nvidia:k8s:container-toolkit/tags">here</a>.</p></li>
</ul>
</div>
</section>
<hr class="docutils" />
<section id="nvidia-vgpu">
<h4>NVIDIA vGPU<a class="headerlink" href="#nvidia-vgpu" title="Permalink to this heading"></a></h4>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The GPU Operator with NVIDIA vGPUs requires additional steps to build a private driver image prior to install.
Refer to the document <a class="reference internal" href="install-gpu-operator-vgpu.html#install-gpu-operator-1-11-1-vgpu"><span class="std std-ref">NVIDIA vGPU</span></a> for detailed instructions on the workflow and required values of
the variables used in this command.</p>
</div>
<p>The command below will install the GPU Operator with its default configuration for vGPU:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>helm<span class="w"> </span>install<span class="w"> </span>--wait<span class="w"> </span>--generate-name<span class="w"> </span><span class="se">\</span>
<span class="w">     </span>-n<span class="w"> </span>gpu-operator<span class="w"> </span>--create-namespace<span class="w"> </span><span class="se">\</span>
<span class="w">     </span>nvidia/gpu-operator<span class="w"> </span><span class="se">\</span>
<span class="w">     </span>--set<span class="w"> </span>driver.repository<span class="o">=</span><span class="nv">$PRIVATE_REGISTRY</span><span class="w"> </span><span class="se">\</span>
<span class="w">     </span>--set<span class="w"> </span>driver.version<span class="o">=</span><span class="nv">$VERSION</span><span class="w"> </span><span class="se">\</span>
<span class="w">     </span>--set<span class="w"> </span>driver.imagePullSecrets<span class="o">={</span><span class="nv">$REGISTRY_SECRET_NAME</span><span class="o">}</span><span class="w"> </span><span class="se">\</span>
<span class="w">     </span>--set<span class="w"> </span>driver.licensingConfig.configMapName<span class="o">=</span>licensing-config
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="nvidia-ai-enterprise">
<h4>NVIDIA AI Enterprise<a class="headerlink" href="#nvidia-ai-enterprise" title="Permalink to this heading"></a></h4>
<p>Refer to <a class="reference internal" href="install-gpu-operator-nvaie-ocp.html#install-gpu-operator-1-11-1-nvaie"><span class="std std-ref">GPU Operator with NVIDIA AI Enterprise</span></a>.</p>
</section>
<hr class="docutils" />
<section id="bare-metal-passthrough-with-pre-installed-nvidia-drivers">
<h4>Bare-metal/Passthrough with pre-installed NVIDIA drivers<a class="headerlink" href="#bare-metal-passthrough-with-pre-installed-nvidia-drivers" title="Permalink to this heading"></a></h4>
<p>In this example, the user has already pre-installed NVIDIA drivers as part of the system image:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>helm<span class="w"> </span>install<span class="w"> </span>--wait<span class="w"> </span>--generate-name<span class="w"> </span><span class="se">\</span>
<span class="w">     </span>-n<span class="w"> </span>gpu-operator<span class="w"> </span>--create-namespace<span class="w"> </span><span class="se">\</span>
<span class="w">     </span>nvidia/gpu-operator<span class="w"> </span><span class="se">\</span>
<span class="w">     </span>--set<span class="w"> </span>driver.enabled<span class="o">=</span><span class="nb">false</span>
</pre></div>
</div>
<hr class="docutils" />
</section>
<section id="bare-metal-passthrough-with-pre-installed-drivers-and-nvidia-container-toolkit">
<span id="preinstalled-drivers-and-toolkit-1-11-1"></span><h4>Bare-metal/Passthrough with pre-installed drivers and NVIDIA Container Toolkit<a class="headerlink" href="#bare-metal-passthrough-with-pre-installed-drivers-and-nvidia-container-toolkit" title="Permalink to this heading"></a></h4>
<p>In this example, the user has already pre-installed the NVIDIA drivers and NVIDIA Container Toolkit (<code class="docutils literal notranslate"><span class="pre">nvidia-docker2</span></code>)
as part of the system image.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>These steps should be followed when using the GPU Operator v1.9+ on DGX A100 systems with DGX OS 5.1+.</p>
</div>
<p>Before installing the operator, ensure that the following configurations are modified depending on the container runtime configured in your cluster.</p>
<p>Docker:</p>
<blockquote>
<div><ul>
<li><p>Update the Docker configuration to add <code class="docutils literal notranslate"><span class="pre">nvidia</span></code> as the default runtime. The <code class="docutils literal notranslate"><span class="pre">nvidia</span></code> runtime should
be setup as the default container runtime for Docker on GPU nodes. This can be done by adding the
<code class="docutils literal notranslate"><span class="pre">default-runtime</span></code> line into the Docker daemon config file, which is usually located on the system
at <code class="docutils literal notranslate"><span class="pre">/etc/docker/daemon.json</span></code>:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">{</span>
<span class="go">    &quot;default-runtime&quot;: &quot;nvidia&quot;,</span>
<span class="go">    &quot;runtimes&quot;: {</span>
<span class="go">        &quot;nvidia&quot;: {</span>
<span class="go">            &quot;path&quot;: &quot;/usr/bin/nvidia-container-runtime&quot;,</span>
<span class="go">            &quot;runtimeArgs&quot;: []</span>
<span class="go">      }</span>
<span class="go">    }</span>
<span class="go">}</span>
</pre></div>
</div>
<p>Restart the Docker daemon to complete the installation after setting the default runtime:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>sudo<span class="w"> </span>systemctl<span class="w"> </span>restart<span class="w"> </span>docker
</pre></div>
</div>
</li>
</ul>
</div></blockquote>
<p>Containerd:</p>
<blockquote>
<div><ul>
<li><p>Update <code class="docutils literal notranslate"><span class="pre">containerd</span></code> to use <code class="docutils literal notranslate"><span class="pre">nvidia</span></code> as the default runtime and add <code class="docutils literal notranslate"><span class="pre">nvidia</span></code> runtime configuration.
This can be done by adding below config to <code class="docutils literal notranslate"><span class="pre">/etc/containerd/config.toml</span></code> and restarting <code class="docutils literal notranslate"><span class="pre">containerd</span></code> service.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">version = 2</span>
<span class="go">[plugins]</span>
<span class="go">  [plugins.&quot;io.containerd.grpc.v1.cri&quot;]</span>
<span class="go">    [plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd]</span>
<span class="go">      default_runtime_name = &quot;nvidia&quot;</span>

<span class="go">      [plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.runtimes]</span>
<span class="go">        [plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.runtimes.nvidia]</span>
<span class="go">          privileged_without_host_devices = false</span>
<span class="go">          runtime_engine = &quot;&quot;</span>
<span class="go">          runtime_root = &quot;&quot;</span>
<span class="go">          runtime_type = &quot;io.containerd.runc.v2&quot;</span>
<span class="go">          [plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.runtimes.nvidia.options]</span>
<span class="go">            BinaryName = &quot;/usr/bin/nvidia-container-runtime&quot;</span>
</pre></div>
</div>
<p>Restart the Containerd daemon to complete the installation after setting the default runtime:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>sudo<span class="w"> </span>systemctl<span class="w"> </span>restart<span class="w"> </span>containerd
</pre></div>
</div>
</li>
</ul>
</div></blockquote>
<p>Install the GPU operator with the following options:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>helm<span class="w"> </span>install<span class="w"> </span>--wait<span class="w"> </span>--generate-name<span class="w"> </span><span class="se">\</span>
<span class="w">     </span>-n<span class="w"> </span>gpu-operator<span class="w"> </span>--create-namespace<span class="w"> </span><span class="se">\</span>
<span class="w">      </span>nvidia/gpu-operator<span class="w"> </span><span class="se">\</span>
<span class="w">      </span>--set<span class="w"> </span>driver.enabled<span class="o">=</span><span class="nb">false</span><span class="w"> </span><span class="se">\</span>
<span class="w">      </span>--set<span class="w"> </span>toolkit.enabled<span class="o">=</span><span class="nb">false</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="bare-metal-passthrough-with-pre-installed-nvidia-container-toolkit-but-no-drivers">
<h4>Bare-metal/Passthrough with pre-installed NVIDIA Container Toolkit (but no drivers)<a class="headerlink" href="#bare-metal-passthrough-with-pre-installed-nvidia-container-toolkit-but-no-drivers" title="Permalink to this heading"></a></h4>
<p>In this example, the user has already pre-installed the NVIDIA Container Toolkit (<code class="docutils literal notranslate"><span class="pre">nvidia-docker2</span></code>) as part of the system image.</p>
<p>Before installing the operator, ensure that the following configurations are modified depending on the container runtime configured in your cluster.</p>
<p>Docker:</p>
<blockquote>
<div><ul>
<li><p>Update the Docker configuration to add <code class="docutils literal notranslate"><span class="pre">nvidia</span></code> as the default runtime. The <code class="docutils literal notranslate"><span class="pre">nvidia</span></code> runtime should
be setup as the default container runtime for Docker on GPU nodes. This can be done by adding the
<code class="docutils literal notranslate"><span class="pre">default-runtime</span></code> line into the Docker daemon config file, which is usually located on the system
at <code class="docutils literal notranslate"><span class="pre">/etc/docker/daemon.json</span></code>:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">{</span>
<span class="go">    &quot;default-runtime&quot;: &quot;nvidia&quot;,</span>
<span class="go">    &quot;runtimes&quot;: {</span>
<span class="go">        &quot;nvidia&quot;: {</span>
<span class="go">            &quot;path&quot;: &quot;/usr/bin/nvidia-container-runtime&quot;,</span>
<span class="go">            &quot;runtimeArgs&quot;: []</span>
<span class="go">      }</span>
<span class="go">    }</span>
<span class="go">}</span>
</pre></div>
</div>
<p>Restart the Docker daemon to complete the installation after setting the default runtime:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>sudo<span class="w"> </span>systemctl<span class="w"> </span>restart<span class="w"> </span>docker
</pre></div>
</div>
</li>
</ul>
</div></blockquote>
<p>Containerd:</p>
<blockquote>
<div><ul>
<li><p>Update <code class="docutils literal notranslate"><span class="pre">containerd</span></code> to use <code class="docutils literal notranslate"><span class="pre">nvidia</span></code> as the default runtime and add <code class="docutils literal notranslate"><span class="pre">nvidia</span></code> runtime configuration.
This can be done by adding below config to <code class="docutils literal notranslate"><span class="pre">/etc/containerd/config.toml</span></code> and restarting <code class="docutils literal notranslate"><span class="pre">containerd</span></code> service.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">version = 2</span>
<span class="go">[plugins]</span>
<span class="go">  [plugins.&quot;io.containerd.grpc.v1.cri&quot;]</span>
<span class="go">    [plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd]</span>
<span class="go">      default_runtime_name = &quot;nvidia&quot;</span>

<span class="go">      [plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.runtimes]</span>
<span class="go">        [plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.runtimes.nvidia]</span>
<span class="go">          privileged_without_host_devices = false</span>
<span class="go">          runtime_engine = &quot;&quot;</span>
<span class="go">          runtime_root = &quot;&quot;</span>
<span class="go">          runtime_type = &quot;io.containerd.runc.v2&quot;</span>
<span class="go">          [plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.runtimes.nvidia.options]</span>
<span class="go">            BinaryName = &quot;/usr/bin/nvidia-container-runtime&quot;</span>
</pre></div>
</div>
<p>Restart the Containerd daemon to complete the installation after setting the default runtime:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>sudo<span class="w"> </span>systemctl<span class="w"> </span>restart<span class="w"> </span>containerd
</pre></div>
</div>
</li>
</ul>
</div></blockquote>
<p>Configure toolkit to use the <code class="docutils literal notranslate"><span class="pre">root</span></code> directory of the driver installation as <code class="docutils literal notranslate"><span class="pre">/run/nvidia/driver</span></code>, which is the path mounted by driver container.</p>
<blockquote>
<div><div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>sudo<span class="w"> </span>sed<span class="w"> </span>-i<span class="w"> </span><span class="s1">&#39;s/^#root/root/&#39;</span><span class="w"> </span>/etc/nvidia-container-runtime/config.toml
</pre></div>
</div>
</div></blockquote>
<p>Once these steps are complete, now install the GPU operator with the following options (which will provision a driver):</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>helm<span class="w"> </span>install<span class="w"> </span>--wait<span class="w"> </span>--generate-name<span class="w"> </span><span class="se">\</span>
<span class="w">     </span>-n<span class="w"> </span>gpu-operator<span class="w"> </span>--create-namespace<span class="w"> </span><span class="se">\</span>
<span class="w">     </span>nvidia/gpu-operator<span class="w"> </span><span class="se">\</span>
<span class="w">     </span>--set<span class="w"> </span>toolkit.enabled<span class="o">=</span><span class="nb">false</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="custom-driver-image-based-off-a-specific-driver-version">
<h4>Custom driver image (based off a specific driver version)<a class="headerlink" href="#custom-driver-image-based-off-a-specific-driver-version" title="Permalink to this heading"></a></h4>
<p>If you want to use custom driver container images (for e.g. using 465.27), then
you would need to build a new driver container image. Follow these steps:</p>
<ul>
<li><p>Rebuild the driver container by specifying the <code class="docutils literal notranslate"><span class="pre">$DRIVER_VERSION</span></code> argument when building the Docker image. For
reference, the driver container Dockerfiles are available on the Git repo <a class="reference external" href="https://gitlab.com/nvidia/container-images/driver">here</a></p></li>
<li><p>Build the container using the appropriate Dockerfile. For example:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>docker<span class="w"> </span>build<span class="w"> </span>--pull<span class="w"> </span>-t<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--build-arg<span class="w"> </span><span class="nv">DRIVER_VERSION</span><span class="o">=</span><span class="m">455</span>.28<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>nvidia/driver:455.28-ubuntu20.04<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--file<span class="w"> </span>Dockerfile<span class="w"> </span>.
</pre></div>
</div>
<p>Ensure that the driver container is tagged as shown in the example by using the <code class="docutils literal notranslate"><span class="pre">driver:&lt;version&gt;-&lt;os&gt;</span></code> schema.</p>
</li>
<li><p>Specify the new driver image and repository by overriding the defaults in
the Helm install command. For example:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>helm<span class="w"> </span>install<span class="w"> </span>--wait<span class="w"> </span>--generate-name<span class="w"> </span><span class="se">\</span>
<span class="w">     </span>-n<span class="w"> </span>gpu-operator<span class="w"> </span>--create-namespace<span class="w"> </span><span class="se">\</span>
<span class="w">     </span>nvidia/gpu-operator<span class="w"> </span><span class="se">\</span>
<span class="w">     </span>--set<span class="w"> </span>driver.repository<span class="o">=</span>docker.io/nvidia<span class="w"> </span><span class="se">\</span>
<span class="w">     </span>--set<span class="w"> </span>driver.version<span class="o">=</span><span class="s2">&quot;465.27&quot;</span>
</pre></div>
</div>
</li>
</ul>
<p>Note that these instructions are provided for reference and evaluation purposes.
Not using the standard releases of the GPU Operator from NVIDIA would mean limited
support for such custom configurations.</p>
</section>
<hr class="docutils" />
<section id="custom-configuration-for-runtime-containerd">
<h4>Custom configuration for runtime <code class="docutils literal notranslate"><span class="pre">containerd</span></code><a class="headerlink" href="#custom-configuration-for-runtime-containerd" title="Permalink to this heading"></a></h4>
<p>When <cite>containerd</cite> is the container runtime used, the following configuration
options are also respected:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">toolkit</span><span class="p">:</span>
<span class="w">   </span><span class="nt">env</span><span class="p">:</span>
<span class="w">   </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">CONTAINERD_CONFIG</span>
<span class="w">     </span><span class="nt">value</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">/etc/containerd/config.toml</span>
<span class="w">   </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">CONTAINERD_SOCKET</span>
<span class="w">     </span><span class="nt">value</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">/run/containerd/containerd.sock</span>
<span class="w">   </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">CONTAINERD_RUNTIME_CLASS</span>
<span class="w">     </span><span class="nt">value</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">nvidia</span>
<span class="w">   </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">CONTAINERD_SET_AS_DEFAULT</span>
<span class="w">     </span><span class="nt">value</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
</pre></div>
</div>
<p>These options are defined as follows:</p>
<blockquote>
<div><ul>
<li><dl>
<dt><strong>CONTAINERD_CONFIG</strong><span class="classifier">The path on the host to the <code class="docutils literal notranslate"><span class="pre">containerd</span></code> config</span></dt><dd><p>you would like to have updated with support for the <code class="docutils literal notranslate"><span class="pre">nvidia-container-runtime</span></code>.
By default this will point to <code class="docutils literal notranslate"><span class="pre">/etc/containerd/config.toml</span></code> (the default
location for <code class="docutils literal notranslate"><span class="pre">containerd</span></code>). It should be customized if your <code class="docutils literal notranslate"><span class="pre">containerd</span></code>
installation is not in the default location.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>CONTAINERD_SOCKET</strong><span class="classifier">The path on the host to the socket file used to</span></dt><dd><p>communicate with <code class="docutils literal notranslate"><span class="pre">containerd</span></code>. The operator will use this to send a
<code class="docutils literal notranslate"><span class="pre">SIGHUP</span></code> signal to the <code class="docutils literal notranslate"><span class="pre">containerd</span></code> daemon to reload its config. By
default this will point to <code class="docutils literal notranslate"><span class="pre">/run/containerd/containerd.sock</span></code>
(the default location for <code class="docutils literal notranslate"><span class="pre">containerd</span></code>). It should be customized if
your <code class="docutils literal notranslate"><span class="pre">containerd</span></code> installation is not in the default location.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>CONTAINERD_RUNTIME_CLASS</strong><span class="classifier">The name of the</span></dt><dd><p><a class="reference external" href="https://kubernetes.io/docs/concepts/containers/runtime-class">Runtime Class</a>
you would like to associate with the <code class="docutils literal notranslate"><span class="pre">nvidia-container-runtime</span></code>.
Pods launched with a <code class="docutils literal notranslate"><span class="pre">runtimeClassName</span></code> equal to CONTAINERD_RUNTIME_CLASS
will always run with the <code class="docutils literal notranslate"><span class="pre">nvidia-container-runtime</span></code>. The default
CONTAINERD_RUNTIME_CLASS is <code class="docutils literal notranslate"><span class="pre">nvidia</span></code>.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>CONTAINERD_SET_AS_DEFAULT</strong><span class="classifier">A flag indicating whether you want to set</span></dt><dd><p><code class="docutils literal notranslate"><span class="pre">nvidia-container-runtime</span></code> as the default runtime used to launch all
containers. When set to false, only containers in pods with a <code class="docutils literal notranslate"><span class="pre">runtimeClassName</span></code>
equal to CONTAINERD_RUNTIME_CLASS will be run with the <code class="docutils literal notranslate"><span class="pre">nvidia-container-runtime</span></code>.
The default value is <code class="docutils literal notranslate"><span class="pre">true</span></code>.</p>
</dd>
</dl>
</li>
</ul>
</div></blockquote>
</section>
<hr class="docutils" />
<section id="proxy-environments">
<h4>Proxy Environments<a class="headerlink" href="#proxy-environments" title="Permalink to this heading"></a></h4>
<p>Refer to the section <a class="reference internal" href="install-gpu-operator-proxy.html#install-gpu-operator-1-11-1-proxy"><span class="std std-ref">Install GPU Operator in Proxy Environments</span></a> for more information on how to install the Operator on clusters
behind a HTTP proxy.</p>
</section>
<hr class="docutils" />
<section id="air-gapped-environments">
<h4>Air-gapped Environments<a class="headerlink" href="#air-gapped-environments" title="Permalink to this heading"></a></h4>
<p>Refer to the section <a class="reference internal" href="install-gpu-operator-air-gapped.html#install-gpu-operator-1-11-1-air-gapped"><span class="std std-ref">Install GPU Operator in Air-gapped Environments</span></a> for more information on how to install the Operator
in air-gapped environments.</p>
</section>
<hr class="docutils" />
<section id="multi-instance-gpu-mig">
<h4>Multi-Instance GPU (MIG)<a class="headerlink" href="#multi-instance-gpu-mig" title="Permalink to this heading"></a></h4>
<p>Refer to the document <a class="reference internal" href="gpu-operator-mig.html#install-gpu-operator-1-11-1-mig"><span class="std std-ref">GPU Operator with MIG</span></a> for more information on how use the Operator with Multi-Instance GPU (MIG)
on NVIDIA Ampere products. For guidance on configuring MIG support for the <strong>NVIDIA GPU Operator</strong> in an OpenShift Container Platform cluster, see the <a class="reference external" href="https://docs.nvidia.com/datacenter/cloud-native/openshift/mig-ocp.html">user guide</a>.</p>
</section>
<hr class="docutils" />
<section id="outdated-kernels">
<h4>Outdated Kernels<a class="headerlink" href="#outdated-kernels" title="Permalink to this heading"></a></h4>
<p>Refer to the section <a class="reference internal" href="install-gpu-operator-outdated-kernels.html#install-gpu-operator-1-11-1-outdated-kernels"><span class="std std-ref">Considerations when Installing with Outdated Kernels in Cluster</span></a> for more information on how to install the Operator successfully
when nodes in the cluster are not running the latest kernel</p>
</section>
</section>
<hr class="docutils" />
<section id="verify-gpu-operator-install">
<h3>Verify GPU Operator Install<a class="headerlink" href="#verify-gpu-operator-install" title="Permalink to this heading"></a></h3>
<p>Once the Helm chart is installed, check the status of the pods to ensure all the containers are running and the validation is complete:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl<span class="w"> </span>get<span class="w"> </span>pods<span class="w"> </span>-n<span class="w"> </span>gpu-operator
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">NAME                                                          READY   STATUS      RESTARTS   AGE</span>
<span class="go">gpu-feature-discovery-crrsq                                   1/1     Running     0          60s</span>
<span class="go">gpu-operator-7fb75556c7-x8spj                                 1/1     Running     0          5m13s</span>
<span class="go">gpu-operator-node-feature-discovery-master-58d884d5cc-w7q7b   1/1     Running     0          5m13s</span>
<span class="go">gpu-operator-node-feature-discovery-worker-6rht2              1/1     Running     0          5m13s</span>
<span class="go">gpu-operator-node-feature-discovery-worker-9r8js              1/1     Running     0          5m13s</span>
<span class="go">nvidia-container-toolkit-daemonset-lhgqf                      1/1     Running     0          4m53s</span>
<span class="go">nvidia-cuda-validator-rhvbb                                   0/1     Completed   0          54s</span>
<span class="go">nvidia-dcgm-5jqzg                                             1/1     Running     0          60s</span>
<span class="go">nvidia-dcgm-exporter-h964h                                    1/1     Running     0          60s</span>
<span class="go">nvidia-device-plugin-daemonset-d9ntc                          1/1     Running     0          60s</span>
<span class="go">nvidia-device-plugin-validator-cm2fd                          0/1     Completed   0          48s</span>
<span class="go">nvidia-driver-daemonset-5xj6g                                 1/1     Running     0          4m53s</span>
<span class="go">nvidia-mig-manager-89z9b                                      1/1     Running     0          4m53s</span>
<span class="go">nvidia-operator-validator-bwx99                               1/1     Running     0          58s</span>
</pre></div>
</div>
<p>We can now proceed to running some sample GPU workloads to verify that the Operator (and its components) are working correctly.</p>
</section>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2018-2023, NVIDIA Corporation.
      <span class="lastupdated">Last updated on 2023-03-14.
      </span></p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>  

  <style>
  a:link, a:visited {
    color: #76b900;
  }

  a:hover {
    color: #8c0;
  }

  .rst-content dl:not(.docutils) dt {
    background: rgba(118, 185, 0, 0.1);
    color: rgba(59,93,0,1);
    border-top: solid 3px rgba(59,93,0,1);
  }
  </style>
  

</body>
</html>