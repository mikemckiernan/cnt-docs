<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>DCGM-Exporter &mdash; NVIDIA Cloud Native Technologies  documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="../_static/tabs.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />
    <link rel="shortcut icon" href="../_static/nvidia.ico"/>
    <link rel="canonical" href="https://docs.nvidia.com/datacenter/cloud-native/gpu-telemetry/dcgm-exporter.html"/>
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/sphinx_highlight.js"></script>
        <script src="../_static/clipboard.min.js"></script>
        <script src="../_static/copybutton.js"></script>
        <script src="../_static/js/google-analytics/google-analytics-tracker.js"></script>
        <script src="../_static/js/google-analytics/google-analytics-write.js"></script>
        <script src="//assets.adobedtm.com/b92787824f2e0e9b68dc2e993f9bd995339fe417/satelliteLib-7ba51e58dc61bcb0e9311aadd02a0108ab24cc6c.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" > 
            <a href="../contents.html">
            <img src="../_static/NVLogo_H_B&W.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

  <style>
    /* Sidebar header (and topbar for mobile) */
    .wy-side-nav-search, .wy-nav-top {
      background: #76b900;
    }

    .wy-side-nav-search a:link, .wy-nav-top a:link {
      color: #fff;
    }
    .wy-side-nav-search a:visited, .wy-nav-top a:visited {
      color: #fff;
    }
    .wy-side-nav-search a:hover, .wy-nav-top a:hover {
      color: #fff;
    }

    .wy-menu-vertical a:link, .wy-menu-vertical a:visited {
      color: #d9d9d9
    }

    .wy-menu-vertical a:active {
      background-color: #76b900
    }

    .wy-side-nav-search>div.version {
      color: rgba(0, 0, 0, 0.3)
    }

    .wy-nav-content {
      max-width: 1000px;
    }
  </style>
  
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">GPU Operator</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/about.html">About the Operator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/platform-support.html">Platform Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/release-notes.html">Release Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/getting-started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/getting-started.html#install-nvidia-gpu-operator">Install NVIDIA GPU Operator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/gpu-driver-upgrades.html">GPU Driver Upgrades</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/advanced-configurations.html">Advanced Configurations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/openshift/contents.html">Red Hat OpenShift</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/appendix.html">Appendix</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/license.html">Licenses and Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/archive.html">Archive</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../contents.html">NVIDIA Cloud Native Technologies</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../contents.html" class="icon icon-home"></a> &raquo;</li>
      <li>DCGM-Exporter</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="dcgm-exporter">
<span id="id1"></span><h1>DCGM-Exporter<a class="headerlink" href="#dcgm-exporter" title="Permalink to this heading"></a></h1>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this heading"></a></h2>
<p><a class="reference external" href="https://github.com/NVIDIA/dcgm-exporter">DCGM-Exporter</a> is a tool based on the
Go APIs to <a class="reference external" href="https://developer.nvidia.com/dcgm">NVIDIA DCGM</a> that allows users to gather
GPU metrics and understand workload behavior or monitor GPUs in clusters. <cite>dcgm-exporter</cite> is
written in Go and exposes GPU metrics at an HTTP endpoint (<code class="docutils literal notranslate"><span class="pre">/metrics</span></code>) for monitoring solutions
such as Prometheus.</p>
<p>For information on the profiling metrics available from DCGM, refer to
<a class="reference external" href="https://docs.nvidia.com/datacenter/dcgm/latest/dcgm-api/dcgm-api-profiling.html#profiling" title="(in NVIDIA DCGM Documentation vVersion: 3.1 (Latest))"><span>Profiling</span></a> in the DCGM documentation.</p>
</section>
<section id="getting-started">
<h2>Getting Started<a class="headerlink" href="#getting-started" title="Permalink to this heading"></a></h2>
<p><cite>dcgm-exporter</cite> can be run as a standalone container or deployed as a
daemonset on GPU nodes in a Kubernetes cluster.</p>
<p>Since <cite>dcgm-exporter</cite> starts <cite>nv-hostengine</cite> as an embedded process (for collecting metrics),
appropriate configuration options should be used if <cite>dcgm-exporter</cite> is run on systems (such as
NVIDIA DGX) that have DCGM (or rather <cite>nv-hostengine</cite>) running.</p>
<section id="running-dcgm-exporter">
<h3>Running <cite>dcgm-exporter</cite><a class="headerlink" href="#running-dcgm-exporter" title="Permalink to this heading"></a></h3>
<p>The <cite>dcgm-exporter</cite> container can be run using a container engine such as Docker. In this mode, <cite>dcgm-exporter</cite>
starts <cite>nv-hostengine</cite> as an embedded process and starts publishing metrics:</p>
<a class="reference internal image-reference" href="../_images/dcgm-exporter_embedded.png"><img alt="../_images/dcgm-exporter_embedded.png" src="../_images/dcgm-exporter_embedded.png" style="width: 800px;" /></a>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span><span class="nv">DCGM_EXPORTER_VERSION</span><span class="o">=</span><span class="m">2</span>.1.4-2.3.1<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="se">\</span>
docker<span class="w"> </span>run<span class="w"> </span>-d<span class="w"> </span>--rm<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--gpus<span class="w"> </span>all<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--net<span class="w"> </span>host<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--cap-add<span class="w"> </span>SYS_ADMIN<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>nvcr.io/nvidia/k8s/dcgm-exporter:<span class="si">${</span><span class="nv">DCGM_EXPORTER_VERSION</span><span class="si">}</span>-ubuntu20.04<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>-f<span class="w"> </span>/etc/dcgm-exporter/dcp-metrics-included.csv
</pre></div>
</div>
<p>Retrieve the metrics:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>curl<span class="w"> </span>localhost:9400/metrics
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp"># </span>HELP<span class="w"> </span>DCGM_FI_DEV_SM_CLOCK<span class="w"> </span>SM<span class="w"> </span>clock<span class="w"> </span>frequency<span class="w"> </span><span class="o">(</span><span class="k">in</span><span class="w"> </span>MHz<span class="o">)</span>.
<span class="gp"># </span>TYPE<span class="w"> </span>DCGM_FI_DEV_SM_CLOCK<span class="w"> </span>gauge
<span class="gp"># </span>HELP<span class="w"> </span>DCGM_FI_DEV_MEM_CLOCK<span class="w"> </span>Memory<span class="w"> </span>clock<span class="w"> </span>frequency<span class="w"> </span><span class="o">(</span><span class="k">in</span><span class="w"> </span>MHz<span class="o">)</span>.
<span class="gp"># </span>TYPE<span class="w"> </span>DCGM_FI_DEV_MEM_CLOCK<span class="w"> </span>gauge
<span class="gp"># </span>HELP<span class="w"> </span>DCGM_FI_DEV_MEMORY_TEMP<span class="w"> </span>Memory<span class="w"> </span>temperature<span class="w"> </span><span class="o">(</span><span class="k">in</span><span class="w"> </span>C<span class="o">)</span>.
<span class="gp"># </span>TYPE<span class="w"> </span>DCGM_FI_DEV_MEMORY_TEMP<span class="w"> </span>gauge
<span class="go">...</span>
<span class="go">DCGM_FI_DEV_SM_CLOCK{gpu=&quot;0&quot;, UUID=&quot;GPU-604ac76c-d9cf-fef3-62e9-d92044ab6e52&quot;} 139</span>
<span class="go">DCGM_FI_DEV_MEM_CLOCK{gpu=&quot;0&quot;, UUID=&quot;GPU-604ac76c-d9cf-fef3-62e9-d92044ab6e52&quot;} 405</span>
<span class="go">DCGM_FI_DEV_MEMORY_TEMP{gpu=&quot;0&quot;, UUID=&quot;GPU-604ac76c-d9cf-fef3-62e9-d92044ab6e52&quot;} 9223372036854775794</span>
<span class="go">...</span>
</pre></div>
</div>
</section>
<section id="dcgm-exporter-customization">
<h3>DCGM-Exporter Customization<a class="headerlink" href="#dcgm-exporter-customization" title="Permalink to this heading"></a></h3>
<p>DCGM-Exporter has various options for adjusting its default behavior. Each option supports both a command-line flag and environment variable.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 35%" />
<col style="width: 20%" />
<col style="width: 45%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Environment Variable</p></th>
<th class="head"><p>Command-Line Flag</p></th>
<th class="head"><p>Value</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">$DCGM_EXPORTER_COLLECTORS</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">-f</span></code></p></td>
<td><p>File Path</p></td>
</tr>
<tr class="row-odd"><td colspan="3"><p>Path to file containing DCGM fields to collect. Default: “/etc/dcgm-exporter/default-counters.csv”</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">$DCGM_EXPORTER_LISTEN</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">-a</span></code></p></td>
<td><p>Address</p></td>
</tr>
<tr class="row-odd"><td colspan="3"><p>Address of listening http server. Default: “:9400”</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">$DCGM_EXPORTER_INTERVAL</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">-c</span></code></p></td>
<td><p>Interval</p></td>
</tr>
<tr class="row-odd"><td colspan="3"><p>Interval of time at which point metrics are collected. Unit is milliseconds. Default:30000</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">$DCGM_EXPORTER_KUBERNETES</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">-k</span></code></p></td>
<td><p>Boolean</p></td>
</tr>
<tr class="row-odd"><td colspan="3"><p>Enable kubernetes mapping metrics to kubernetes pods. Default: false</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">$DCGM_EXPORTER_CONFIGMAP_DATA</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">-m</span></code></p></td>
<td><p>Namespace:Name</p></td>
</tr>
<tr class="row-odd"><td colspan="3"><p>ConfigMap namespace and name containing DCGM fields to collect. Default: “none”</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">$DCGM_REMOTE_HOSTENGINE_INFO</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">-r</span></code></p></td>
<td><p>Host:Port</p></td>
</tr>
<tr class="row-odd"><td colspan="3"><p>Connect to remote hostengine at Host:Port. Default: NA (dcgm-exporter will started  in embedded mode)</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">$DCGM_EXPORTER_DEVICES_STR</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">-d</span></code></p></td>
<td><p>Device String (see following note)</p></td>
</tr>
<tr class="row-odd"><td colspan="3"><p>Specify which devices to monitor. Default: all GPU instances in MIG mode, all GPUs if MIG disabled.</p></td>
</tr>
<tr class="row-even"><td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Device String Syntax: <code class="docutils literal notranslate"><span class="pre">[f]</span> <span class="pre">|</span> <span class="pre">[g[:id1[,-id2]]]</span> <span class="pre">|</span> <span class="pre">[i[:id1[,-id2]]]</span></code></p>
<p>If an id list is used, then devices with matching IDs must exist on the system. For example:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">f</span></code> = Monitor all GPUs if MIG is disabled, or all GPU instances if MIG is enabled</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">g</span></code> = Monitor all GPUs</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">i</span></code> = Monitor all GPU instances</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">g:0,1</span></code> = monitor GPUs 0 and 1</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">i:0,2-4</span></code> = monitor GPU instances 0, 2, 3, and 4.</p></li>
</ul>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">-i</span></code> cannot be specified unless MIG mode is enabled.</p></li>
<li><p>Any time indices are specified, those indices must exist on the system.</p></li>
<li><p>In MIG mode, only <code class="docutils literal notranslate"><span class="pre">f</span></code> or <code class="docutils literal notranslate"><span class="pre">i</span></code> with a range can be specified. GPUs are not assigned to pods and therefore reporting must occur at the GPU instance level. (default: <code class="docutils literal notranslate"><span class="pre">f</span></code>)</p></li>
</ol>
</div>
<section id="connecting-to-an-existing-dcgm-agent">
<h4>Connecting to an existing DCGM agent<a class="headerlink" href="#connecting-to-an-existing-dcgm-agent" title="Permalink to this heading"></a></h4>
<p>In this scenario, system images include DCGM and have <cite>nv-hostengine</cite> running already. Examples include
the DGX systems that bundles drivers, DCGM, etc. in the system image. To avoid any compatibility issues,
it is recommended to have <cite>dcgm-exporter</cite> connect to the existing <cite>nv-hostengine</cite> daemon to gather/publish
GPU telemetry data.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>The <cite>dcgm-exporter</cite> container image includes a DCGM client library (<code class="docutils literal notranslate"><span class="pre">libdcgm.so</span></code>) to communicate with
<cite>nv-hostengine</cite>. In this deployment scenario we have <cite>dcgm-exporter</cite> (or rather <code class="docutils literal notranslate"><span class="pre">libdcgm.so</span></code>) connect
to an existing <cite>nv-hostengine</cite> running on the host. The DCGM client library uses an internal protocol to exchange
information with <cite>nv-hostengine</cite>. To avoid any potential incompatibilities between the container image’s DCGM client library
and the host’s <cite>nv-hostengine</cite>, it is strongly recommended to use a version of DCGM on which <cite>dcgm-exporter</cite> is based is
greater than or equal to (but not less than) the version of DCGM running on the host. This can be easily determined by
comparing the version tags of the <cite>dcgm-exporter</cite> image and by running <code class="docutils literal notranslate"><span class="pre">nv-hostengine</span> <span class="pre">--version</span></code> on the host.</p>
</div>
<p>In this scenario, we use the <code class="docutils literal notranslate"><span class="pre">-r</span></code> option to connect to an existing <cite>nv-hostengine</cite> process:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span><span class="nv">DCGM_EXPORTER_VERSION</span><span class="o">=</span><span class="m">2</span>.1.4-2.3.1<span class="w"> </span><span class="o">&amp;&amp;</span>
<span class="go">docker run -d --rm \</span>
<span class="go">   --gpus all \</span>
<span class="go">   --net host \</span>
<span class="go">   --cap-add SYS_ADMIN \</span>
<span class="go">   nvcr.io/nvidia/k8s/dcgm-exporter:${DCGM_EXPORTER_VERSION}-ubuntu20.04 \</span>
<span class="go">   -r localhost:5555 -f /etc/dcgm-exporter/dcp-metrics-included.csv</span>
</pre></div>
</div>
</section>
<section id="connecting-to-a-dcgm-standalone-container">
<h4>Connecting to a DCGM standalone container<a class="headerlink" href="#connecting-to-a-dcgm-standalone-container" title="Permalink to this heading"></a></h4>
<p>In this scenario the DCGM <cite>nv-hostengine</cite> runs in a separate container on the same host making its client port available to
DCGM-Exporter as well as dcgmi client commands.</p>
<a class="reference internal image-reference" href="../_images/dcgm_and_dcgm-exporter.png"><img alt="../_images/dcgm_and_dcgm-exporter.png" src="../_images/dcgm_and_dcgm-exporter.png" style="width: 800px;" /></a>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Similar to the warning when connecting to an existing DCGM agent, the <cite>dcgm-exporter</cite> container image includes a
DCGM client library (<code class="docutils literal notranslate"><span class="pre">libdcgm.so</span></code>) to communicate with <cite>nv-hostengine</cite> running in a separate container.
The DCGM client library in use by DCGM-Exporter uses an internal protocol to exchange information with <cite>nv-hostengine</cite>.
To avoid any potential incompatibilities between the container image’s DCGM client library
and the standalone DCGM container’s <cite>nv-hostengine</cite>, it is strongly recommended to ensure the version of DCGM on which
<cite>dcgm-exporter</cite> is based is greater than or equal to (but not less than) the version of DCGM running in the standalone
container. This can be easily determined by comparing the version tags of the <cite>dcgm-exporter</cite> and <cite>dcgm</cite> standalone image.</p>
</div>
<p>First, start the standalone DCGM container with the <cite>nv-hostengine</cite> port available to external applications:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$</span><span class="nv">DCGM_VERSION</span><span class="o">=</span><span class="m">2</span>.2.9<span class="w"> </span><span class="o">&amp;&amp;</span>
<span class="go">docker run -d --rm \</span>
<span class="go">   --gpus all \</span>
<span class="go">   --cap-add SYS_ADMIN \</span>
<span class="go">   -p 5555:5555 \</span>
<span class="go">   nvidia/dcgm:${DCGM_VERSION}-ubuntu20.04</span>
</pre></div>
</div>
<p>Second, start the dcgm-exporter container with <code class="docutils literal notranslate"><span class="pre">r</span></code> option to connect to an existing <cite>nv-hostengine</cite> port:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$</span><span class="nv">DCGM_EXPORTER_VERSION</span><span class="o">=</span><span class="m">2</span>.2.9-2.5.0<span class="w"> </span><span class="o">&amp;&amp;</span>
<span class="go">docker run -d --rm \</span>
<span class="go">   --gpus all \</span>
<span class="go">   --net host \</span>
<span class="go">   --cap-add SYS_ADMIN \</span>
<span class="go">   nvcr.io/nvidia/k8s/dcgm-exporter:${DCGM_EXPORTER_VERSION}-ubuntu20.04 \</span>
<span class="go">   -r localhost:5555 -f /etc/dcgm-exporter/dcp-metrics-included.csv</span>
</pre></div>
</div>
<p>In this scenario <cite>dcgmi</cite> commands run on the host will also connect to the <cite>nv-hostengine</cite> running in the standalone
DCGM container:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">dcgmi discovery -l</span>
<span class="go">1 GPU found.</span>
<span class="go">+--------+----------------------------------------------------------------------+</span>
<span class="go">| GPU ID | Device Information                                                   |</span>
<span class="go">+--------+----------------------------------------------------------------------+</span>
<span class="go">| 0      | Name: Quadro RTX 6000                                                |</span>
<span class="go">|        | PCI Bus ID: 00000000:65:00.0                                         |</span>
<span class="go">|        | Device UUID: GPU-2f6576bf-3c29-1fbb-068d-e74c4a97f0c5                |</span>
<span class="go">+--------+----------------------------------------------------------------------+</span>
</pre></div>
</div>
</section>
</section>
</section>
<section id="multi-instance-gpu-mig-support">
<h2>Multi-Instance GPU (MIG) Support<a class="headerlink" href="#multi-instance-gpu-mig-support" title="Permalink to this heading"></a></h2>
<p>The new Multi-Instance GPU (MIG) feature allows the GPUs based on the NVIDIA Ampere architecture to be
securely partitioned into up to seven separate GPU Instances for CUDA applications, providing multiple users
with separate GPU resources for optimal GPU utilization.</p>
<p>For more information on MIG, refer to the MIG <a class="reference external" href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html">User Guide</a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Support for MIG in <cite>dcgm-exporter</cite> was added starting with <code class="docutils literal notranslate"><span class="pre">2.4.0-rc.2</span></code>. Replace the container image with this tag in the
command line examples above: <code class="docutils literal notranslate"><span class="pre">2.1.8-2.4.0-rc.2-ubuntu20.04</span></code>. If you are connecting to an existing DCGM on the host system,
ensure that you upgrade to at least 2.1.8 on the host system.</p>
</div>
<p><cite>dcgm-exporter</cite> publishes metrics for both the entire GPU as well as individual MIG devices (or GPU instances)
as can be seen in the output below:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">DCGM_FI_DEV_SM_CLOCK{gpu=&quot;0&quot;,UUID=&quot;GPU-34319582-d595-d1c7-d1d2-179bcfa61660&quot;,device=&quot;nvidia0&quot;,Hostname=&quot;ub20-a100-k8s&quot;} 1215</span>
<span class="go">DCGM_FI_DEV_MEM_CLOCK{gpu=&quot;0&quot;,UUID=&quot;GPU-34319582-d595-d1c7-d1d2-179bcfa61660&quot;,device=&quot;nvidia0&quot;,Hostname=&quot;ub20-a100-k8s&quot;} 1215</span>
<span class="go">DCGM_FI_DEV_MEMORY_TEMP{gpu=&quot;0&quot;,UUID=&quot;GPU-34319582-d595-d1c7-d1d2-179bcfa61660&quot;,device=&quot;nvidia0&quot;,Hostname=&quot;ub20-a100-k8s&quot;} 69</span>
<span class="go">DCGM_FI_DEV_GPU_TEMP{gpu=&quot;0&quot;,UUID=&quot;GPU-34319582-d595-d1c7-d1d2-179bcfa61660&quot;,device=&quot;nvidia0&quot;,Hostname=&quot;ub20-a100-k8s&quot;} 61</span>
<span class="go">DCGM_FI_DEV_POWER_USAGE{gpu=&quot;0&quot;,UUID=&quot;GPU-34319582-d595-d1c7-d1d2-179bcfa61660&quot;,device=&quot;nvidia0&quot;,Hostname=&quot;ub20-a100-k8s&quot;} 409.692000</span>
<span class="go">DCGM_FI_DEV_TOTAL_ENERGY_CONSUMPTION{gpu=&quot;0&quot;,UUID=&quot;GPU-34319582-d595-d1c7-d1d2-179bcfa61660&quot;,device=&quot;nvidia0&quot;,Hostname=&quot;ub20-a100-k8s&quot;} 319159391</span>
<span class="go">DCGM_FI_DEV_PCIE_REPLAY_COUNTER{gpu=&quot;0&quot;,UUID=&quot;GPU-34319582-d595-d1c7-d1d2-179bcfa61660&quot;,device=&quot;nvidia0&quot;,Hostname=&quot;ub20-a100-k8s&quot;} 0</span>
<span class="go">DCGM_FI_DEV_XID_ERRORS{gpu=&quot;0&quot;,UUID=&quot;GPU-34319582-d595-d1c7-d1d2-179bcfa61660&quot;,device=&quot;nvidia0&quot;,Hostname=&quot;ub20-a100-k8s&quot;} 0</span>
<span class="go">DCGM_FI_DEV_FB_FREE{gpu=&quot;0&quot;,UUID=&quot;GPU-34319582-d595-d1c7-d1d2-179bcfa61660&quot;,device=&quot;nvidia0&quot;,Hostname=&quot;ub20-a100-k8s&quot;} 35690</span>
<span class="go">DCGM_FI_DEV_FB_USED{gpu=&quot;0&quot;,UUID=&quot;GPU-34319582-d595-d1c7-d1d2-179bcfa61660&quot;,device=&quot;nvidia0&quot;,Hostname=&quot;ub20-a100-k8s&quot;} 4845</span>
<span class="go">DCGM_FI_DEV_NVLINK_BANDWIDTH_TOTAL{gpu=&quot;0&quot;,UUID=&quot;GPU-34319582-d595-d1c7-d1d2-179bcfa61660&quot;,device=&quot;nvidia0&quot;,Hostname=&quot;ub20-a100-k8s&quot;} 0</span>
<span class="go">DCGM_FI_DEV_VGPU_LICENSE_STATUS{gpu=&quot;0&quot;,UUID=&quot;GPU-34319582-d595-d1c7-d1d2-179bcfa61660&quot;,device=&quot;nvidia0&quot;,Hostname=&quot;ub20-a100-k8s&quot;} 0</span>
<span class="go">DCGM_FI_PROF_GR_ENGINE_ACTIVE{gpu=&quot;0&quot;,UUID=&quot;GPU-34319582-d595-d1c7-d1d2-179bcfa61660&quot;,device=&quot;nvidia0&quot;,Hostname=&quot;ub20-a100-k8s&quot;} 0.995630</span>
<span class="go">DCGM_FI_PROF_PIPE_TENSOR_ACTIVE{gpu=&quot;0&quot;,UUID=&quot;GPU-34319582-d595-d1c7-d1d2-179bcfa61660&quot;,device=&quot;nvidia0&quot;,Hostname=&quot;ub20-a100-k8s&quot;} 0.929260</span>
<span class="go">DCGM_FI_PROF_DRAM_ACTIVE{gpu=&quot;0&quot;,UUID=&quot;GPU-34319582-d595-d1c7-d1d2-179bcfa61660&quot;,device=&quot;nvidia0&quot;,Hostname=&quot;ub20-a100-k8s&quot;} 0.690789</span>
<span class="go">DCGM_FI_PROF_PCIE_TX_BYTES{gpu=&quot;0&quot;,UUID=&quot;GPU-34319582-d595-d1c7-d1d2-179bcfa61660&quot;,device=&quot;nvidia0&quot;,Hostname=&quot;ub20-a100-k8s&quot;} 33011804</span>
<span class="go">DCGM_FI_PROF_PCIE_RX_BYTES{gpu=&quot;0&quot;,UUID=&quot;GPU-34319582-d595-d1c7-d1d2-179bcfa61660&quot;,device=&quot;nvidia0&quot;,Hostname=&quot;ub20-a100-k8s&quot;} 97863601</span>

<span class="go">DCGM_FI_DEV_XID_ERRORS{gpu=&quot;0&quot;,UUID=&quot;GPU-34319582-d595-d1c7-d1d2-179bcfa61660&quot;,device=&quot;nvidia0&quot;,GPU_I_PROFILE=&quot;1g.5gb&quot;,GPU_I_ID=&quot;13&quot;,Hostname=&quot;ub20-a100-k8s&quot;} 0</span>
<span class="go">DCGM_FI_PROF_GR_ENGINE_ACTIVE{gpu=&quot;0&quot;,UUID=&quot;GPU-34319582-d595-d1c7-d1d2-179bcfa61660&quot;,device=&quot;nvidia0&quot;,GPU_I_PROFILE=&quot;1g.5gb&quot;,GPU_I_ID=&quot;13&quot;,Hostname=&quot;ub20-a100-k8s&quot;} 0.995687</span>
<span class="go">DCGM_FI_PROF_PIPE_TENSOR_ACTIVE{gpu=&quot;0&quot;,UUID=&quot;GPU-34319582-d595-d1c7-d1d2-179bcfa61660&quot;,device=&quot;nvidia0&quot;,GPU_I_PROFILE=&quot;1g.5gb&quot;,GPU_I_ID=&quot;13&quot;,Hostname=&quot;ub20-a100-k8s&quot;} 0.930433</span>
<span class="go">DCGM_FI_PROF_DRAM_ACTIVE{gpu=&quot;0&quot;,UUID=&quot;GPU-34319582-d595-d1c7-d1d2-179bcfa61660&quot;,device=&quot;nvidia0&quot;,GPU_I_PROFILE=&quot;1g.5gb&quot;,GPU_I_ID=&quot;13&quot;,Hostname=&quot;ub20-a100-k8s&quot;} 0.800339</span>
</pre></div>
</div>
<p>For more information on the profiling metrics and how to interpret the metrics, refer to the <a class="reference external" href="https://docs.nvidia.com/datacenter/dcgm/latest/dcgm-user-guide/feature-overview.html#profiling">profiling metrics</a>
section of the DCGM user guide.</p>
</section>
</section>
<section id="integrating-gpu-telemetry-into-kubernetes">
<h1>Integrating GPU Telemetry into Kubernetes<a class="headerlink" href="#integrating-gpu-telemetry-into-kubernetes" title="Permalink to this heading"></a></h1>
<p>Understanding GPU usage provides important insights for IT administrators managing a data center.
Trends in GPU metrics correlate with workload behavior and make it possible to optimize resource allocation,
diagnose anomalies, and increase overall data center efficiency. As GPUs become more mainstream in
Kubernetes environments, users would like to get access to GPU metrics to monitor GPU resources, just
like they do today for CPUs.</p>
<p>The purpose of this document is to enumerate an end-to-end (e2e) workflow
for setting up and using <a class="reference external" href="https://developer.nvidia.com/dcgm">DCGM</a> within a Kubernetes environment.</p>
<p>For simplicity, the base environment being used in this guide is Ubuntu 18.04 LTS and
a native installation of the NVIDIA drivers on the GPU enabled nodes (i.e. neither
the <a class="reference external" href="https://github.com/NVIDIA/gpu-operator">NVIDIA GPU Operator</a> nor containerized drivers are used
in this document).</p>
<section id="nvidia-drivers">
<h2>NVIDIA Drivers<a class="headerlink" href="#nvidia-drivers" title="Permalink to this heading"></a></h2>
<p>This section provides a summary of the steps for installing the driver using the <code class="docutils literal notranslate"><span class="pre">apt</span></code> package manager on Ubuntu LTS.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For complete instructions on setting up NVIDIA drivers, visit the quickstart guide at <a class="reference external" href="https://docs.nvidia.com/datacenter/tesla/tesla-installation-notes/index.html">https://docs.nvidia.com/datacenter/tesla/tesla-installation-notes/index.html</a>.
The guide covers a number of pre-installation requirements and steps on supported Linux distributions for a successful install of the driver.</p>
</div>
<p>Install the kernel headers and development packages for the currently running kernel:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>sudo<span class="w"> </span>apt-get<span class="w"> </span>install<span class="w"> </span>linux-headers-<span class="k">$(</span>uname<span class="w"> </span>-r<span class="k">)</span>
</pre></div>
</div>
<p>Setup the CUDA network repository and ensure packages on the CUDA network repository have priority over the Canonical repository:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span><span class="nv">distribution</span><span class="o">=</span><span class="k">$(</span>.<span class="w"> </span>/etc/os-release<span class="p">;</span><span class="nb">echo</span><span class="w"> </span><span class="nv">$ID$VERSION_ID</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>sed<span class="w"> </span>-e<span class="w"> </span><span class="s1">&#39;s/\.//g&#39;</span><span class="k">)</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span><span class="o">&amp;&amp;</span><span class="w"> </span>wget<span class="w"> </span>https://developer.download.nvidia.com/compute/cuda/repos/<span class="nv">$distribution</span>/x86_64/cuda-<span class="nv">$distribution</span>.pin<span class="w"> </span><span class="se">\</span>
<span class="w">   </span><span class="o">&amp;&amp;</span><span class="w"> </span>sudo<span class="w"> </span>mv<span class="w"> </span>cuda-<span class="nv">$distribution</span>.pin<span class="w"> </span>/etc/apt/preferences.d/cuda-repository-pin-600
</pre></div>
</div>
<p>Install the CUDA repository GPG key:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>sudo<span class="w"> </span>apt-key<span class="w"> </span>adv<span class="w"> </span>--fetch-keys<span class="w"> </span>https://developer.download.nvidia.com/compute/cuda/repos/<span class="nv">$distribution</span>/x86_64/7fa2af80.pub<span class="w"> </span><span class="se">\</span>
<span class="w">   </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;deb http://developer.download.nvidia.com/compute/cuda/repos/</span><span class="nv">$distribution</span><span class="s2">/x86_64 /&quot;</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>sudo<span class="w"> </span>tee<span class="w"> </span>/etc/apt/sources.list.d/cuda.list
</pre></div>
</div>
<p>Update the <code class="docutils literal notranslate"><span class="pre">apt</span></code> repository cache and install the driver using the <code class="docutils literal notranslate"><span class="pre">cuda-drivers</span></code> meta-package. Use the <code class="docutils literal notranslate"><span class="pre">--no-install-recommends</span></code> option for a lean driver install
without any dependencies on X packages. This is particularly useful for headless installations on cloud instances:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>sudo<span class="w"> </span>apt-get<span class="w"> </span>update<span class="w"> </span><span class="se">\</span>
<span class="w">   </span><span class="o">&amp;&amp;</span><span class="w"> </span>sudo<span class="w"> </span>apt-get<span class="w"> </span>-y<span class="w"> </span>install<span class="w"> </span>cuda-drivers
</pre></div>
</div>
</section>
<section id="install-docker">
<h2>Install Docker<a class="headerlink" href="#install-docker" title="Permalink to this heading"></a></h2>
<p>Use the official Docker script to install the latest release of Docker:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>curl<span class="w"> </span>https://get.docker.com<span class="w"> </span><span class="p">|</span><span class="w"> </span>sh
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>sudo<span class="w"> </span>systemctl<span class="w"> </span>--now<span class="w"> </span><span class="nb">enable</span><span class="w"> </span>docker
</pre></div>
</div>
</section>
<section id="install-nvidia-container-toolkit-previously-nvidia-docker2">
<h2>Install NVIDIA Container Toolkit (previously <code class="docutils literal notranslate"><span class="pre">nvidia-docker2</span></code>)<a class="headerlink" href="#install-nvidia-container-toolkit-previously-nvidia-docker2" title="Permalink to this heading"></a></h2>
<p>To run GPU accelerated containers in Docker, NVIDIA Container Toolkit for Docker is required.</p>
<p>Setup the <code class="docutils literal notranslate"><span class="pre">stable</span></code> repository and the GPG key:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span><span class="nv">distribution</span><span class="o">=</span><span class="k">$(</span>.<span class="w"> </span>/etc/os-release<span class="p">;</span><span class="nb">echo</span><span class="w"> </span><span class="nv">$ID$VERSION_ID</span><span class="k">)</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span><span class="o">&amp;&amp;</span><span class="w"> </span>curl<span class="w"> </span>-s<span class="w"> </span>-L<span class="w"> </span>https://nvidia.github.io/nvidia-docker/gpgkey<span class="w"> </span><span class="p">|</span><span class="w"> </span>sudo<span class="w"> </span>apt-key<span class="w"> </span>add<span class="w"> </span>-<span class="w"> </span><span class="se">\</span>
<span class="w">   </span><span class="o">&amp;&amp;</span><span class="w"> </span>curl<span class="w"> </span>-s<span class="w"> </span>-L<span class="w"> </span>https://nvidia.github.io/nvidia-docker/<span class="nv">$distribution</span>/nvidia-docker.list<span class="w"> </span><span class="p">|</span><span class="w"> </span>sudo<span class="w"> </span>tee<span class="w"> </span>/etc/apt/sources.list.d/nvidia-docker.list
</pre></div>
</div>
<p>Install the NVIDIA runtime packages (and their dependencies) after updating the package listing:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>sudo<span class="w"> </span>apt-get<span class="w"> </span>update<span class="w"> </span><span class="se">\</span>
<span class="w">   </span><span class="o">&amp;&amp;</span><span class="w"> </span>sudo<span class="w"> </span>apt-get<span class="w"> </span>install<span class="w"> </span>-y<span class="w"> </span>nvidia-docker2
</pre></div>
</div>
<p>Since Kubernetes does not support the <code class="docutils literal notranslate"><span class="pre">--gpus</span></code> option with Docker yet, the <code class="docutils literal notranslate"><span class="pre">nvidia</span></code> runtime should be setup as the
default container runtime for Docker on the GPU node. This can be done by adding the <code class="docutils literal notranslate"><span class="pre">default-runtime</span></code> line into the Docker daemon
config file, which is usually located on the system at <code class="docutils literal notranslate"><span class="pre">/etc/docker/daemon.json</span></code>:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">{</span>
<span class="go">   &quot;default-runtime&quot;: &quot;nvidia&quot;,</span>
<span class="go">   &quot;runtimes&quot;: {</span>
<span class="go">        &quot;nvidia&quot;: {</span>
<span class="go">            &quot;path&quot;: &quot;/usr/bin/nvidia-container-runtime&quot;,</span>
<span class="go">            &quot;runtimeArgs&quot;: []</span>
<span class="go">      }</span>
<span class="go">   }</span>
<span class="go">}</span>
</pre></div>
</div>
<p>Restart the Docker daemon to complete the installation after setting the default runtime:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>sudo<span class="w"> </span>systemctl<span class="w"> </span>restart<span class="w"> </span>docker
</pre></div>
</div>
<p>At this point, a working setup can be tested by running a base CUDA container:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>sudo<span class="w"> </span>docker<span class="w"> </span>run<span class="w"> </span>--rm<span class="w"> </span>--gpus<span class="w"> </span>all<span class="w"> </span>nvidia/cuda:11.0-base<span class="w"> </span>nvidia-smi
</pre></div>
</div>
<p>You should observe an output as shown below:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">+-----------------------------------------------------------------------------+</span>
<span class="go">| NVIDIA-SMI 450.51.06    Driver Version: 450.51.06    CUDA Version: 11.0     |</span>
<span class="go">|-------------------------------+----------------------+----------------------+</span>
<span class="go">| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |</span>
<span class="go">| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |</span>
<span class="go">|                               |                      |               MIG M. |</span>
<span class="go">|===============================+======================+======================|</span>
<span class="go">|   0  Tesla T4            On   | 00000000:00:1E.0 Off |                    0 |</span>
<span class="go">| N/A   34C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |</span>
<span class="go">|                               |                      |                  N/A |</span>
<span class="go">+-------------------------------+----------------------+----------------------+</span>

<span class="go">+-----------------------------------------------------------------------------+</span>
<span class="go">| Processes:                                                                  |</span>
<span class="go">|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |</span>
<span class="go">|        ID   ID                                                   Usage      |</span>
<span class="go">|=============================================================================|</span>
<span class="go">|  No running processes found                                                 |</span>
<span class="go">+-----------------------------------------------------------------------------+</span>
</pre></div>
</div>
</section>
<section id="install-kubernetes">
<h2>Install Kubernetes<a class="headerlink" href="#install-kubernetes" title="Permalink to this heading"></a></h2>
<p>Refer to <a class="reference internal" href="../kubernetes/install-k8s.html#install-k8s"><span class="std std-ref">Install Kubernetes</span></a> for getting started with setting up a Kubernetes cluster.</p>
</section>
<section id="install-nvidia-device-plugin">
<h2>Install NVIDIA Device Plugin<a class="headerlink" href="#install-nvidia-device-plugin" title="Permalink to this heading"></a></h2>
<p>To use GPUs in Kubernetes, the <a class="reference external" href="https://github.com/NVIDIA/k8s-device-plugin/">NVIDIA Device Plugin</a> is required.
The NVIDIA Device Plugin is a daemonset that automatically enumerates the number of GPUs on each node of the cluster
and allows pods to be run on GPUs.</p>
<p>The preferred method to deploy the device plugin is as a daemonset using <code class="docutils literal notranslate"><span class="pre">helm</span></code>. First, install Helm:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>curl<span class="w"> </span>-fsSL<span class="w"> </span>-o<span class="w"> </span>get_helm.sh<span class="w"> </span>https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3<span class="w"> </span><span class="se">\</span>
<span class="w">   </span><span class="o">&amp;&amp;</span><span class="w"> </span>chmod<span class="w"> </span><span class="m">700</span><span class="w"> </span>get_helm.sh<span class="w"> </span><span class="se">\</span>
<span class="w">   </span><span class="o">&amp;&amp;</span><span class="w"> </span>./get_helm.sh
</pre></div>
</div>
<p>Add the <code class="docutils literal notranslate"><span class="pre">nvidia-device-plugin</span></code> <code class="docutils literal notranslate"><span class="pre">helm</span></code> repository:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>helm<span class="w"> </span>repo<span class="w"> </span>add<span class="w"> </span>nvdp<span class="w"> </span>https://nvidia.github.io/k8s-device-plugin<span class="w"> </span><span class="se">\</span>
<span class="w">   </span><span class="o">&amp;&amp;</span><span class="w"> </span>helm<span class="w"> </span>repo<span class="w"> </span>update
</pre></div>
</div>
<p>Deploy the device plugin:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>helm<span class="w"> </span>install<span class="w"> </span>--generate-name<span class="w"> </span>nvdp/nvidia-device-plugin
</pre></div>
</div>
<p>For more user configurable options while deploying the daemonset, refer to the <a class="reference external" href="https://github.com/NVIDIA/k8s-device-plugin/#deployment-via-helm">documentation</a></p>
<p>At this point, all the pods should be deployed:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl<span class="w"> </span>get<span class="w"> </span>pods<span class="w"> </span>-A
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">NAMESPACE     NAME                                       READY   STATUS      RESTARTS   AGE</span>
<span class="go">kube-system   calico-kube-controllers-5fbfc9dfb6-2ttkk   1/1     Running     3          9d</span>
<span class="go">kube-system   calico-node-5vfcb                          1/1     Running     3          9d</span>
<span class="go">kube-system   coredns-66bff467f8-jzblc                   1/1     Running     4          9d</span>
<span class="go">kube-system   coredns-66bff467f8-l85sz                   1/1     Running     3          9d</span>
<span class="go">kube-system   etcd-ip-172-31-81-185                      1/1     Running     4          9d</span>
<span class="go">kube-system   kube-apiserver-ip-172-31-81-185            1/1     Running     3          9d</span>
<span class="go">kube-system   kube-controller-manager-ip-172-31-81-185   1/1     Running     3          9d</span>
<span class="go">kube-system   kube-proxy-86vlr                           1/1     Running     3          9d</span>
<span class="go">kube-system   kube-scheduler-ip-172-31-81-185            1/1     Running     4          9d</span>
<span class="go">kube-system   nvidia-device-plugin-1595448322-42vgf      1/1     Running     2          9d</span>
</pre></div>
</div>
<p>To test whether CUDA jobs can be deployed, run a sample CUDA <code class="docutils literal notranslate"><span class="pre">vectorAdd</span></code> application:</p>
<p>The pod spec is shown for reference below, which requests 1 GPU:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">apiVersion: v1</span>
<span class="go">kind: Pod</span>
<span class="go">metadata:</span>
<span class="go">  name: gpu-operator-test</span>
<span class="go">spec:</span>
<span class="go">  restartPolicy: OnFailure</span>
<span class="go">  containers:</span>
<span class="go">  - name: cuda-vector-add</span>
<span class="go">    image: &quot;nvidia/samples:vectoradd-cuda10.2&quot;</span>
<span class="go">    resources:</span>
<span class="go">      limits:</span>
<span class="go">         nvidia.com/gpu: 1</span>
</pre></div>
</div>
<p>Save this podspec as <code class="docutils literal notranslate"><span class="pre">gpu-pod.yaml</span></code>. Now, deploy the application:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl<span class="w"> </span>apply<span class="w"> </span>-f<span class="w"> </span>gpu-pod.yaml
</pre></div>
</div>
<p>Check the logs to ensure the app completed successfully:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl<span class="w"> </span>get<span class="w"> </span>pods<span class="w"> </span>gpu-operator-test
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">NAME                READY   STATUS      RESTARTS   AGE</span>
<span class="go">gpu-operator-test   0/1     Completed   0          9d</span>
</pre></div>
</div>
<p>And check the logs of the <code class="docutils literal notranslate"><span class="pre">gpu-operator-test</span></code> pod:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl<span class="w"> </span>logs<span class="w"> </span>gpu-operator-test
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">[Vector addition of 50000 elements]</span>
<span class="go">Copy input data from the host memory to the CUDA device</span>
<span class="go">CUDA kernel launch with 196 blocks of 256 threads</span>
<span class="go">Copy output data from the CUDA device to the host memory</span>
<span class="go">Test PASSED</span>
<span class="go">Done</span>
</pre></div>
</div>
</section>
<section id="gpu-telemetry">
<h2>GPU Telemetry<a class="headerlink" href="#gpu-telemetry" title="Permalink to this heading"></a></h2>
<p>Monitoring stacks usually consist of a collector, a time-series database to store metrics and a visualization layer.
A popular open-source stack is <a class="reference external" href="https://prometheus.io/">Prometheus</a> used along with <a class="reference external" href="https://grafana.com/">Grafana</a> as
the visualization tool to create rich dashboards. Prometheus also includes an <a class="reference external" href="https://github.com/prometheus/alertmanager">Alertmanager</a>,
to create and manage alerts. Prometheus is deployed along with <a class="reference external" href="https://github.com/kubernetes/kube-state-metrics">kube-state-metrics</a> and
<a class="reference external" href="https://github.com/prometheus/node_exporter">node_exporter</a> to expose cluster-level metrics for Kubernetes API objects and node-level
metrics such as CPU utilization.</p>
<p>An architecture of Prometheus is shown in the figure below:</p>
<a class="reference internal image-reference" href="https://boxboat.com/2019/08/08/monitoring-kubernetes-with-prometheus/prometheus-architecture.png"><img alt="https://boxboat.com/2019/08/08/monitoring-kubernetes-with-prometheus/prometheus-architecture.png" src="https://boxboat.com/2019/08/08/monitoring-kubernetes-with-prometheus/prometheus-architecture.png" style="width: 800px;" /></a>
<p>To gather GPU telemetry in Kubernetes, its recommended to use <code class="docutils literal notranslate"><span class="pre">dcgm-exporter</span></code>. <code class="docutils literal notranslate"><span class="pre">dcgm-exporter</span></code>, based on <a class="reference external" href="https://developer.nvidia.com/dcgm">DCGM</a> exposes
GPU metrics for Prometheus and can be visualized using Grafana. <code class="docutils literal notranslate"><span class="pre">dcgm-exporter</span></code> is architected to take advantage of
<code class="docutils literal notranslate"><span class="pre">KubeletPodResources</span></code> <a class="reference external" href="https://kubernetes.io/docs/reference/command-line-tools-reference/feature-gates/">API</a> and exposes GPU metrics in a format that can be
scraped by Prometheus. A <code class="docutils literal notranslate"><span class="pre">ServiceMonitor</span></code> is also included to expose endpoints.</p>
<p>The rest of this section walks through setting up Prometheus, <code class="docutils literal notranslate"><span class="pre">dcgm-exporter</span></code>, and grafana.</p>
<section id="setting-up-prometheus">
<h3>Setting up Prometheus<a class="headerlink" href="#setting-up-prometheus" title="Permalink to this heading"></a></h3>
<p>Implementing a Prometheus stack can be complicated but can be managed by taking advantage of the <code class="docutils literal notranslate"><span class="pre">Helm</span></code> package manager and
the <a class="reference external" href="https://github.com/coreos/prometheus-operator">Prometheus Operator</a> and <a class="reference external" href="https://github.com/coreos/kube-prometheus">kube-prometheus</a> projects.
The Operator uses standard configurations and dashboards for Prometheus and Grafana and the Helm <a class="reference external" href="https://github.com/helm/charts/tree/master/stable/prometheus-operator">prometheus-operator</a>
chart allows you to get a full cluster monitoring solution up and running by installing Prometheus Operator and the rest of the components listed above.</p>
<p>First, add the <code class="docutils literal notranslate"><span class="pre">helm</span></code> repo:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>helm<span class="w"> </span>repo<span class="w"> </span>add<span class="w"> </span>prometheus-community<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>https://prometheus-community.github.io/helm-charts
</pre></div>
</div>
<p>Now, search for the available <code class="docutils literal notranslate"><span class="pre">prometheus</span></code> charts:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>helm<span class="w"> </span>search<span class="w"> </span>repo<span class="w"> </span>kube-prometheus
</pre></div>
</div>
<p>Once you’ve located which the version of the chart to use, inspect the chart so we can modify the settings:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>helm<span class="w"> </span>inspect<span class="w"> </span>values<span class="w"> </span>prometheus-community/kube-prometheus-stack<span class="w"> </span>&gt;<span class="w"> </span>/tmp/kube-prometheus-stack.values
</pre></div>
</div>
<p>Next, we’ll need to edit the values file to change the port at which the Prometheus server service is available. In the <code class="docutils literal notranslate"><span class="pre">prometheus</span></code> instance
section of the chart, change the service type from <code class="docutils literal notranslate"><span class="pre">ClusterIP</span></code> to <code class="docutils literal notranslate"><span class="pre">NodePort</span></code>. This will allow the Prometheus server to be accessible at your
machine ip address at port 30090 as <code class="docutils literal notranslate"><span class="pre">http://&lt;machine-ip&gt;:30090/</span></code></p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">From:</span>
<span class="gp"> #</span><span class="c1"># Port to expose on each node</span>
<span class="gp"> #</span><span class="c1"># Only used if service.type is &#39;NodePort&#39;</span>
<span class="gp"> #</span><span class="c1">#</span>
<span class="go"> nodePort: 30090</span>

<span class="gp"> #</span><span class="c1"># Loadbalancer IP</span>
<span class="gp"> #</span><span class="c1"># Only use if service.type is &quot;loadbalancer&quot;</span>
<span class="go"> loadBalancerIP: &quot;&quot;</span>
<span class="go"> loadBalancerSourceRanges: []</span>
<span class="gp"> #</span><span class="c1"># Service type</span>
<span class="gp"> #</span><span class="c1">#</span>
<span class="go"> type: ClusterIP</span>

<span class="go">To:</span>
<span class="gp"> #</span><span class="c1"># Port to expose on each node</span>
<span class="gp"> #</span><span class="c1"># Only used if service.type is &#39;NodePort&#39;</span>
<span class="gp"> #</span><span class="c1">#</span>
<span class="go"> nodePort: 30090</span>

<span class="gp"> #</span><span class="c1"># Loadbalancer IP</span>
<span class="gp"> #</span><span class="c1"># Only use if service.type is &quot;loadbalancer&quot;</span>
<span class="go"> loadBalancerIP: &quot;&quot;</span>
<span class="go"> loadBalancerSourceRanges: []</span>
<span class="gp"> #</span><span class="c1"># Service type</span>
<span class="gp"> #</span><span class="c1">#</span>
<span class="go"> type: NodePort</span>
</pre></div>
</div>
<p>Also, modify the <code class="docutils literal notranslate"><span class="pre">prometheusSpec.serviceMonitorSelectorNilUsesHelmValues</span></code> settings to <code class="docutils literal notranslate"><span class="pre">false</span></code> below:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">#</span><span class="c1"># If true, a nil or {} value for prometheus.prometheusSpec.serviceMonitorSelector will cause the</span>
<span class="gp">#</span><span class="c1"># prometheus resource to be created with selectors based on values in the helm deployment,</span>
<span class="gp">#</span><span class="c1"># which will also match the servicemonitors created</span>
<span class="gp">#</span><span class="c1">#</span>
<span class="go">serviceMonitorSelectorNilUsesHelmValues: false</span>
</pre></div>
</div>
<p>Add the following <code class="docutils literal notranslate"><span class="pre">configMap</span></code> to the section on <code class="docutils literal notranslate"><span class="pre">additionalScrapeConfigs</span></code> in the Helm chart.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">#</span><span class="c1"># AdditionalScrapeConfigs allows specifying additional Prometheus scrape configurations. Scrape configurations</span>
<span class="gp">#</span><span class="c1"># are appended to the configurations generated by the Prometheus Operator. Job configurations must have the form</span>
<span class="gp">#</span><span class="c1"># as specified in the official Prometheus documentation:</span>
<span class="gp">#</span><span class="c1"># https://prometheus.io/docs/prometheus/latest/configuration/configuration/#scrape_config. As scrape configs are</span>
<span class="gp">#</span><span class="c1"># appended, the user is responsible to make sure it is valid. Note that using this feature may expose the possibility</span>
<span class="gp">#</span><span class="c1"># to break upgrades of Prometheus. It is advised to review Prometheus release notes to ensure that no incompatible</span>
<span class="gp">#</span><span class="c1"># scrape configs are going to break Prometheus after the upgrade.</span>
<span class="gp">#</span><span class="c1">#</span>
<span class="gp">#</span><span class="c1"># The scrape configuration example below will find master nodes, provided they have the name .*mst.*, relabel the</span>
<span class="gp">#</span><span class="c1"># port to 2379 and allow etcd scraping provided it is running on all Kubernetes master nodes</span>
<span class="gp">#</span><span class="c1">#</span>
<span class="go">additionalScrapeConfigs:</span>
<span class="go">- job_name: gpu-metrics</span>
<span class="go">  scrape_interval: 1s</span>
<span class="go">  metrics_path: /metrics</span>
<span class="go">  scheme: http</span>
<span class="go">  kubernetes_sd_configs:</span>
<span class="go">  - role: endpoints</span>
<span class="go">    namespaces:</span>
<span class="go">      names:</span>
<span class="go">      - gpu-operator</span>
<span class="go">  relabel_configs:</span>
<span class="go">  - source_labels: [__meta_kubernetes_pod_node_name]</span>
<span class="go">    action: replace</span>
<span class="go">    target_label: kubernetes_node</span>
</pre></div>
</div>
<p>Finally, we can deploy the Prometheus and Grafana pods using the <code class="docutils literal notranslate"><span class="pre">kube-prometheus-stack</span></code> via Helm:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>helm<span class="w"> </span>install<span class="w"> </span>prometheus-community/kube-prometheus-stack<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--create-namespace<span class="w"> </span>--namespace<span class="w"> </span>prometheus<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--generate-name<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--values<span class="w"> </span>/tmp/kube-prometheus-stack.values
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>You can also override values in the Prometheus chart directly on the Helm command line:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>helm<span class="w"> </span>install<span class="w"> </span>prometheus-community/kube-prometheus-stack<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--create-namespace<span class="w"> </span>--namespace<span class="w"> </span>prometheus<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--generate-name<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--set<span class="w"> </span>prometheus.service.type<span class="o">=</span>NodePort<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--set<span class="w"> </span>prometheus.prometheusSpec.serviceMonitorSelectorNilUsesHelmValues<span class="o">=</span><span class="nb">false</span>
</pre></div>
</div>
</div>
<p>You should see a console output as below:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">NAME: kube-prometheus-stack-1637791640</span>
<span class="go">LAST DEPLOYED: Wed Nov 24 22:07:22 2021</span>
<span class="go">NAMESPACE: prometheus</span>
<span class="go">STATUS: deployed</span>
<span class="go">REVISION: 1</span>
<span class="go">NOTES:</span>
<span class="go">kube-prometheus-stack has been installed. Check its status by running:</span>
<span class="go">  kubectl --namespace prometheus get pods -l &quot;release=kube-prometheus-stack-1637791640&quot;</span>

<span class="go">Visit https://github.com/prometheus-operator/kube-prometheus for instructions on how to create &amp; configure Alertmanager and Prometheus instances using the Operator.</span>
</pre></div>
</div>
<p>Now you can see the Prometheus and Grafana pods:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl<span class="w"> </span>get<span class="w"> </span>pods<span class="w"> </span>-A
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">NAMESPACE     NAME                                                              READY   STATUS      RESTARTS   AGE</span>
<span class="go">kube-system   calico-kube-controllers-8f59968d4-g28x8                           1/1     Running     1          23m</span>
<span class="go">kube-system   calico-node-zfnfk                                                 1/1     Running     1          23m</span>
<span class="go">kube-system   coredns-f9fd979d6-p7djj                                           1/1     Running     1          23m</span>
<span class="go">kube-system   coredns-f9fd979d6-qhhgq                                           1/1     Running     1          23m</span>
<span class="go">kube-system   etcd-ip-172-31-92-253                                             1/1     Running     1          23m</span>
<span class="go">kube-system   kube-apiserver-ip-172-31-92-253                                   1/1     Running     2          23m</span>
<span class="go">kube-system   kube-controller-manager-ip-172-31-92-253                          1/1     Running     1          23m</span>
<span class="go">kube-system   kube-proxy-mh528                                                  1/1     Running     1          23m</span>
<span class="go">kube-system   kube-scheduler-ip-172-31-92-253                                   1/1     Running     1          23m</span>
<span class="go">kube-system   nvidia-device-plugin-1603211071-7hlk6                             1/1     Running     0          15m</span>
<span class="go">prometheus    alertmanager-kube-prometheus-stack-1603-alertmanager-0            2/2     Running     0          13m</span>
<span class="go">prometheus    kube-prometheus-stack-1603-operator-6b95bcdc79-wmbkn              2/2     Running     0          13m</span>
<span class="go">prometheus    kube-prometheus-stack-1603211794-grafana-67ff56c449-tlmxc         2/2     Running     0          13m</span>
<span class="go">prometheus    kube-prometheus-stack-1603211794-kube-state-metrics-877df67c49f   1/1     Running     0          13m</span>
<span class="go">prometheus    kube-prometheus-stack-1603211794-prometheus-node-exporter-b5fl9   1/1     Running     0          13m</span>
<span class="go">prometheus    prometheus-kube-prometheus-stack-1603-prometheus-0                3/3     Running     1          13m</span>
</pre></div>
</div>
<section id="setting-up-dcgm">
<h4>Setting up DCGM<a class="headerlink" href="#setting-up-dcgm" title="Permalink to this heading"></a></h4>
<p>Now, we will deploy <code class="docutils literal notranslate"><span class="pre">dcgm-exporter</span></code> to gather GPU telemetry. First, lets setup the Helm repo:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>helm<span class="w"> </span>repo<span class="w"> </span>add<span class="w"> </span>gpu-helm-charts<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>https://nvidia.github.io/dcgm-exporter/helm-charts
</pre></div>
</div>
<p>And then update the Helm repo:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>helm<span class="w"> </span>repo<span class="w"> </span>update
</pre></div>
</div>
<p><strong>DCGM-Exporter Helm Chart Customization</strong></p>
<p>The DCGM-Exporter helm package includes several customization options for various use cases.</p>
<dl>
<dt>arguments</dt><dd><p>Customize the command-line parameters passed to dcgm-exporter on startup.</p>
<p><em>Example: Set the metric collection interval to 1000 milliseconds.</em></p>
</dd>
</dl>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">arguments</span><span class="p">[</span><span class="s2">&quot;-c&quot;</span><span class="p">,</span> <span class="s2">&quot;1000&quot;</span><span class="p">]</span>
</pre></div>
</div>
<dl>
<dt>extraConfigMapVolumes</dt><dd><p>Attach ConfigMap volume containing the metrics to the be watched.</p>
<p><em>Example: Attach the ‘exporter-metrics-config-map’ volume to the pod.</em></p>
</dd>
</dl>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">extraConfigMapVolumes</span><span class="p">:</span>
<span class="o">-</span> <span class="n">name</span><span class="p">:</span> <span class="n">exporter</span><span class="o">-</span><span class="n">metrics</span><span class="o">-</span><span class="n">volume</span>
  <span class="n">configMap</span><span class="p">:</span>
    <span class="n">name</span><span class="p">:</span> <span class="n">exporter</span><span class="o">-</span><span class="n">metrics</span><span class="o">-</span><span class="n">config</span><span class="o">-</span><span class="nb">map</span>
</pre></div>
</div>
<dl>
<dt>extraEnv</dt><dd><p>Customize environment variables, including and especially the DCGM-Exporter variables.</p>
<p><em>Example: Collect the metrics specified in the ConfigMap `exporter-metrics-volume`.</em></p>
</dd>
</dl>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">extraEnv</span><span class="p">:</span>
<span class="o">-</span> <span class="n">name</span><span class="p">:</span> <span class="n">DCGM_EXPORTER_CONFIGMAP_DATA</span>
  <span class="n">value</span><span class="p">:</span> <span class="s2">&quot;default:exporter-metrics-volume&quot;</span>
</pre></div>
</div>
<p>Install the <code class="docutils literal notranslate"><span class="pre">dcgm-exporter</span></code> chart:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>helm<span class="w"> </span>install<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--generate-name<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>gpu-helm-charts/dcgm-exporter
</pre></div>
</div>
<p>Now, you can observe the <code class="docutils literal notranslate"><span class="pre">dcgm-exporter</span></code> pod:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl<span class="w"> </span>get<span class="w"> </span>pods<span class="w"> </span>-A
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">NAMESPACE     NAME                                                              READY   STATUS      RESTARTS   AGE</span>
<span class="go">default       dcgm-exporter-2-1603213075-w27mx                                  1/1     Running     0          2m18s</span>
<span class="go">kube-system   calico-kube-controllers-8f59968d4-g28x8                           1/1     Running     1          43m</span>
<span class="go">kube-system   calico-node-zfnfk                                                 1/1     Running     1          43m</span>
<span class="go">kube-system   coredns-f9fd979d6-p7djj                                           1/1     Running     1          43m</span>
<span class="go">kube-system   coredns-f9fd979d6-qhhgq                                           1/1     Running     1          43m</span>
<span class="go">kube-system   etcd-ip-172-31-92-253                                             1/1     Running     1          43m</span>
<span class="go">kube-system   kube-apiserver-ip-172-31-92-253                                   1/1     Running     2          43m</span>
<span class="go">kube-system   kube-controller-manager-ip-172-31-92-253                          1/1     Running     1          43m</span>
<span class="go">kube-system   kube-proxy-mh528                                                  1/1     Running     1          43m</span>
<span class="go">kube-system   kube-scheduler-ip-172-31-92-253                                   1/1     Running     1          43m</span>
<span class="go">kube-system   nvidia-device-plugin-1603211071-7hlk6                             1/1     Running     0          35m</span>
<span class="go">prometheus    alertmanager-kube-prometheus-stack-1603-alertmanager-0            2/2     Running     0          33m</span>
<span class="go">prometheus    kube-prometheus-stack-1603-operator-6b95bcdc79-wmbkn              2/2     Running     0          33m</span>
<span class="go">prometheus    kube-prometheus-stack-1603211794-grafana-67ff56c449-tlmxc         2/2     Running     0          33m</span>
<span class="go">prometheus    kube-prometheus-stack-1603211794-kube-state-metrics-877df67c49f   1/1     Running     0          33m</span>
<span class="go">prometheus    kube-prometheus-stack-1603211794-prometheus-node-exporter-b5fl9   1/1     Running     0          33m</span>
<span class="go">prometheus    prometheus-kube-prometheus-stack-1603-prometheus-0                3/3     Running     1          33m</span>
</pre></div>
</div>
<p>You can view the services setup as part of the operator and <code class="docutils literal notranslate"><span class="pre">dcgm-exporter</span></code>:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl<span class="w"> </span>get<span class="w"> </span>svc<span class="w"> </span>-A
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">NAMESPACE     NAME                                                        TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                        AGE</span>
<span class="go">default       dcgm-exporter-2-1603213075                                  ClusterIP   10.104.40.255   &lt;none&gt;        9400/TCP                       7m44s</span>
<span class="go">default       kubernetes                                                  ClusterIP   10.96.0.1       &lt;none&gt;        443/TCP                        49m</span>
<span class="go">kube-system   kube-dns                                                    ClusterIP   10.96.0.10      &lt;none&gt;        53/UDP,53/TCP,9153/TCP         48m</span>
<span class="go">kube-system   kube-prometheus-stack-1603-coredns                          ClusterIP   None            &lt;none&gt;        9153/TCP                       28m</span>
<span class="go">kube-system   kube-prometheus-stack-1603-kube-controller-manager          ClusterIP   None            &lt;none&gt;        10252/TCP                      28m</span>
<span class="go">kube-system   kube-prometheus-stack-1603-kube-etcd                        ClusterIP   None            &lt;none&gt;        2379/TCP                       28m</span>
<span class="go">kube-system   kube-prometheus-stack-1603-kube-proxy                       ClusterIP   None            &lt;none&gt;        10249/TCP                      28m</span>
<span class="go">kube-system   kube-prometheus-stack-1603-kube-scheduler                   ClusterIP   None            &lt;none&gt;        10251/TCP                      28m</span>
<span class="go">kube-system   kube-prometheus-stack-1603-kubelet                          ClusterIP   None            &lt;none&gt;        10250/TCP,10255/TCP,4194/TCP   28m</span>
<span class="go">prometheus    alertmanager-operated                                       ClusterIP   None            &lt;none&gt;        9093/TCP,9094/TCP,9094/UDP     28m</span>
<span class="go">prometheus    kube-prometheus-stack-1603-alertmanager                     ClusterIP   10.100.20.237   &lt;none&gt;        9093/TCP                       28m</span>
<span class="go">prometheus    kube-prometheus-stack-1603-operator                         ClusterIP   10.111.1.27     &lt;none&gt;        8080/TCP,443/TCP               28m</span>
<span class="go">prometheus    kube-prometheus-stack-1603-prometheus                       NodePort    10.99.188.46    &lt;none&gt;        9090:30090/TCP                 28m</span>
<span class="go">prometheus    kube-prometheus-stack-1603211794-grafana                    ClusterIP   10.109.219.60   &lt;none&gt;        80/TCP                         28m</span>
<span class="go">prometheus    kube-prometheus-stack-1603211794-kube-state-metrics         ClusterIP   10.103.250.41   &lt;none&gt;        8080/TCP                       28m</span>
<span class="go">prometheus    kube-prometheus-stack-1603211794-prometheus-node-exporter   ClusterIP   10.108.225.36   &lt;none&gt;        9100/TCP                       28m</span>
<span class="go">prometheus    prometheus-operated                                         ClusterIP   None            &lt;none&gt;        9090/TCP                       28m</span>
</pre></div>
</div>
<p>You can observe that the Prometheus server is available at port 30090 on the node’s IP address. Open your browser to <code class="docutils literal notranslate"><span class="pre">http://&lt;machine-ip-address&gt;:30090</span></code>.
It may take a few minutes for DCGM to start publishing the metrics to Prometheus. The metrics availability can be verified by typing <code class="docutils literal notranslate"><span class="pre">DCGM_FI_DEV_GPU_UTIL</span></code>
in the event bar to determine if the GPU metrics are visible:</p>
<a class="reference internal image-reference" href="../_images/001-dcgm-e2e-prom-screenshot1.png"><img alt="../_images/001-dcgm-e2e-prom-screenshot1.png" src="../_images/001-dcgm-e2e-prom-screenshot1.png" style="width: 800px;" /></a>
</section>
</section>
<section id="using-grafana">
<h3>Using Grafana<a class="headerlink" href="#using-grafana" title="Permalink to this heading"></a></h3>
<p>You can also launch the Grafana tools for visualizing the GPU metrics.</p>
<p>There are two mechanisms for dealing with the ports on which Grafana is available - the service can be patched or port-forwarding can be used to reach the home page.
Either option can be chosen based on preference.</p>
<p><strong>Patching the Grafana Service</strong></p>
<p>By default, Grafana uses a <code class="docutils literal notranslate"><span class="pre">ClusterIP</span></code> to expose the ports on which the service is accessible. This can be changed to a <code class="docutils literal notranslate"><span class="pre">NodePort</span></code> instead, so the page is accessible
from the browser, similar to the Prometheus dashboard.</p>
<p>You can use <a class="reference external" href="https://kubernetes.io/docs/tasks/manage-kubernetes-objects/update-api-object-kubectl-patch/">kubectl patch</a> to update the service API
object to expose a <code class="docutils literal notranslate"><span class="pre">NodePort</span></code> instead.</p>
<p>First, modify the spec to change the service type:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>cat<span class="w"> </span>&lt;&lt;<span class="w"> </span>EOF<span class="w"> </span><span class="p">|</span><span class="w"> </span>tee<span class="w"> </span>grafana-patch.yaml
<span class="go">spec:</span>
<span class="go">  type: NodePort</span>
<span class="go">  nodePort: 32322</span>
<span class="go">EOF</span>
</pre></div>
</div>
<p>And now use <code class="docutils literal notranslate"><span class="pre">kubectl</span> <span class="pre">patch</span></code>:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl<span class="w"> </span>patch<span class="w"> </span>svc<span class="w"> </span>kube-prometheus-stack-1603211794-grafana<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>-n<span class="w"> </span>prometheus<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--patch<span class="w"> </span><span class="s2">&quot;</span><span class="k">$(</span>cat<span class="w"> </span>grafana-patch.yaml<span class="k">)</span><span class="s2">&quot;</span>
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">service/kube-prometheus-stack-1603211794-grafana patched</span>
</pre></div>
</div>
<p>You can verify that the service is now exposed at an externally accessible port:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl<span class="w"> </span>get<span class="w"> </span>svc<span class="w"> </span>-A
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">NAMESPACE     NAME                                                        TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                        AGE</span>
<span class="go">&lt;snip&gt;</span>
<span class="go">prometheus    kube-prometheus-stack-1603211794-grafana                    NodePort    10.109.219.60   &lt;none&gt;        80:30759/TCP                   32m</span>
</pre></div>
</div>
<p>Open your browser to <code class="docutils literal notranslate"><span class="pre">http://&lt;machine-ip-address&gt;:30759</span></code> and view the Grafana login page. Access Grafana home using the <code class="docutils literal notranslate"><span class="pre">admin</span></code> username.
The password credentials for the login are available in the <code class="docutils literal notranslate"><span class="pre">prometheus.values</span></code> file we edited in the earlier section of the doc:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">#</span><span class="c1"># Deploy default dashboards.</span>
<span class="gp">#</span><span class="c1">#</span>
<span class="go">defaultDashboardsEnabled: true</span>

<span class="go">adminPassword: prom-operator</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="../_images/002-dcgm-e2e-grafana-screenshot1.png"><img alt="../_images/002-dcgm-e2e-grafana-screenshot1.png" src="../_images/002-dcgm-e2e-grafana-screenshot1.png" style="width: 800px;" /></a>
<p><strong>Port Forwarding</strong></p>
<p>Another method to access the Grafana page would be to use port forwarding.</p>
<p>First, it can be observed that the Grafana service is available at port 80. We will need to port-forward the service from an abitrary port - in this example,
we will forward from port 32322 on our local machine to port 80 on the service (which in turn will forward to port 3000 that the Grafana pod is listening at, as
shown below):</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl<span class="w"> </span>port-forward<span class="w"> </span>svc/kube-prometheus-stack-1603211794-grafana<span class="w"> </span>-n<span class="w"> </span>prometheus<span class="w"> </span><span class="m">32322</span>:80
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">Forwarding from 127.0.0.1:32322 -&gt; 3000</span>
<span class="go">Forwarding from [::1]:32322 -&gt; 3000</span>
<span class="go">Handling connection for 32322</span>
</pre></div>
</div>
<p>If your cluster is setup on a cloud instance e.g. AWS EC2, you may have to setup an SSH tunnel between your local workstation and the instance using
port forwarding to view the Grafana tool in your local workstation’s browser. For example, on Windows you can use PuTTY to open an SSH tunnel and specify the
source port as 32322 and destination as <code class="docutils literal notranslate"><span class="pre">localhost:32322</span></code> under the <code class="docutils literal notranslate"><span class="pre">Tunnels</span></code> sub-menu in the SSH menu.</p>
<p>Open your browser and point to <code class="docutils literal notranslate"><span class="pre">http://localhost:32322/</span></code> to view the Grafana login page using the same credentials in the previous section.</p>
</section>
<section id="dcgm-dashboard-in-grafana">
<h3>DCGM Dashboard in Grafana<a class="headerlink" href="#dcgm-dashboard-in-grafana" title="Permalink to this heading"></a></h3>
<p>To add a dashboard for DCGM, you can use a standard dashboard that NVIDIA has made available, which can also be customized.</p>
<a class="reference internal image-reference" href="../_images/003-dcgm-e2e-grafana-home-screenshot.png"><img alt="../_images/003-dcgm-e2e-grafana-home-screenshot.png" src="../_images/003-dcgm-e2e-grafana-home-screenshot.png" style="width: 800px;" /></a>
<p>To access the dashboard, navigate from the Grafana home page to Dashboards -&gt; Manage -&gt; Import:</p>
<a class="reference internal image-reference" href="../_images/004-dcgm-e2e-grafana-manage-screenshot.png"><img alt="../_images/004-dcgm-e2e-grafana-manage-screenshot.png" src="../_images/004-dcgm-e2e-grafana-manage-screenshot.png" style="width: 800px;" /></a>
<a class="reference internal image-reference" href="../_images/005-dcgm-e2e-grafana-import-screenshot.png"><img alt="../_images/005-dcgm-e2e-grafana-import-screenshot.png" src="../_images/005-dcgm-e2e-grafana-import-screenshot.png" style="width: 800px;" /></a>
<p>Import the NVIDIA dashboard from <code class="docutils literal notranslate"><span class="pre">https://grafana.com/grafana/dashboards/12239</span></code>
and choose <em>Prometheus</em> as the data source in the drop down:</p>
<a class="reference internal image-reference" href="../_images/006-dcgm-e2e-grafana-import-screenshot.png"><img alt="../_images/006-dcgm-e2e-grafana-import-screenshot.png" src="../_images/006-dcgm-e2e-grafana-import-screenshot.png" style="width: 800px;" /></a>
<a class="reference internal image-reference" href="../_images/007-dcgm-e2e-grafana-import-screenshot.png"><img alt="../_images/007-dcgm-e2e-grafana-import-screenshot.png" src="../_images/007-dcgm-e2e-grafana-import-screenshot.png" style="width: 800px;" /></a>
<p>The GPU dashboard will now be available on Grafana for visualizing metrics:</p>
<a class="reference internal image-reference" href="../_images/008-dcgm-e2e-grafana-dashboard-screenshot.png"><img alt="../_images/008-dcgm-e2e-grafana-dashboard-screenshot.png" src="../_images/008-dcgm-e2e-grafana-dashboard-screenshot.png" style="width: 800px;" /></a>
</section>
<section id="viewing-metrics-for-running-applications">
<h3>Viewing Metrics for Running Applications<a class="headerlink" href="#viewing-metrics-for-running-applications" title="Permalink to this heading"></a></h3>
<p>In this section, let’s run a more complicated application and view the GPU metrics on the NVIDIA dashboard.</p>
<p>We can use the standard <em>DeepStream Intelligent Video Analytics</em> <a class="reference external" href="https://ngc.nvidia.com/catalog/helm-charts/nvidia:video-analytics-demo">Demo</a> available on the NGC registry.
For our example, let’s use the Helm chart to use the WebUI:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>helm<span class="w"> </span>fetch<span class="w"> </span>https://helm.ngc.nvidia.com/nvidia/charts/video-analytics-demo-0.1.4.tgz<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>helm<span class="w"> </span>install<span class="w"> </span>video-analytics-demo-0.1.4.tgz<span class="w"> </span>--generate-name
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">NAME: video-analytics-demo-0-1596587131</span>
<span class="go">LAST DEPLOYED: Wed Aug  5 00:25:31 2020</span>
<span class="go">NAMESPACE: default</span>
<span class="go">STATUS: deployed</span>
<span class="go">REVISION: 1</span>
<span class="go">NOTES:</span>
<span class="go">1. Get the RTSP URL by running these commands:</span>
<span class="go">export NODE_PORT=$(kubectl get --namespace default -o jsonpath=&quot;{.spec.ports[0].nodePort}&quot; services video-analytics-demo-0-1596587131)</span>
<span class="go">export NODE_IP=$(kubectl get nodes --namespace default -o jsonpath=&quot;{.items[0].status.addresses[0].address}&quot;)</span>
<span class="go">echo rtsp://$NODE_IP:$NODE_PORT/ds-test</span>

<span class="go">2.Get the WebUI URL by running these commands:</span>
<span class="go">export ANT_NODE_PORT=$(kubectl get --namespace default -o jsonpath=&quot;{.spec.ports[0].nodePort}&quot; services video-analytics-demo-0-1596587131-webui)</span>
<span class="go">export NODE_IP=$(kubectl get nodes --namespace default -o jsonpath=&quot;{.items[0].status.addresses[0].address}&quot;)</span>
<span class="go">echo http://$NODE_IP:$ANT_NODE_PORT/WebRTCApp/play.html?name=videoanalytics</span>
<span class="go">Disclaimer:</span>
<span class="go">Note: Due to the output from DeepStream being real-time via RTSP, you may experience occasional hiccups in the video stream depending on network conditions.</span>
</pre></div>
</div>
<p>The demo can be viewed in the browser by pointing to the address following the instructions above.</p>
<p>The GPU metrics are also visible either in the Grafana dashboard or the Prometheus dashboard as can be seen in the following screenshots showing
GPU utilization, memory allocated as the application is running on the GPU:</p>
<a class="reference internal image-reference" href="../_images/010-dcgm-e2e-deepstream-screenshot.png"><img alt="../_images/010-dcgm-e2e-deepstream-screenshot.png" src="../_images/010-dcgm-e2e-deepstream-screenshot.png" style="width: 800px;" /></a>
<a class="reference internal image-reference" href="../_images/011-dcgm-e2e-prom-dashboard-metrics-screenshot.png"><img alt="../_images/011-dcgm-e2e-prom-dashboard-metrics-screenshot.png" src="../_images/011-dcgm-e2e-prom-dashboard-metrics-screenshot.png" style="width: 800px;" /></a>
</section>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2018-2023, NVIDIA Corporation.
      <span class="lastupdated">Last updated on 2023-03-14.
      </span></p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>  

  <style>
  a:link, a:visited {
    color: #76b900;
  }

  a:hover {
    color: #8c0;
  }

  .rst-content dl:not(.docutils) dt {
    background: rgba(118, 185, 0, 0.1);
    color: rgba(59,93,0,1);
    border-top: solid 3px rgba(59,93,0,1);
  }
  </style>
  

</body>
</html>