<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Installing the NVIDIA GPU Operator &mdash; NVIDIA Cloud Native Technologies  documentation</title>
      <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/tabs.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/css/custom.css" type="text/css" />
    <link rel="shortcut icon" href="../../../../_static/nvidia.ico"/>
    <link rel="canonical" href="https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/archive/1.8/openshift/install-gpu-ocp.html"/>
  <!--[if lt IE 9]>
    <script src="../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
        <script src="../../../../_static/jquery.js"></script>
        <script src="../../../../_static/underscore.js"></script>
        <script src="../../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../../../_static/doctools.js"></script>
        <script src="../../../../_static/sphinx_highlight.js"></script>
        <script src="../../../../_static/clipboard.min.js"></script>
        <script src="../../../../_static/copybutton.js"></script>
        <script src="../../../../_static/js/google-analytics/google-analytics-tracker.js"></script>
        <script src="../../../../_static/js/google-analytics/google-analytics-write.js"></script>
        <script src="//assets.adobedtm.com/b92787824f2e0e9b68dc2e993f9bd995339fe417/satelliteLib-7ba51e58dc61bcb0e9311aadd02a0108ab24cc6c.js"></script>
    <script src="../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
    <link rel="next" title="MIG Support in OpenShift Container Platform" href="mig-ocp.html" />
    <link rel="prev" title="Installing the Node Feature Discovery (NFD) Operator" href="install-nfd.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" > 
            <a href="../../../../contents.html">
            <img src="../../../../_static/NVLogo_H_B&W.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

  <style>
    /* Sidebar header (and topbar for mobile) */
    .wy-side-nav-search, .wy-nav-top {
      background: #76b900;
    }

    .wy-side-nav-search a:link, .wy-nav-top a:link {
      color: #fff;
    }
    .wy-side-nav-search a:visited, .wy-nav-top a:visited {
      color: #fff;
    }
    .wy-side-nav-search a:hover, .wy-nav-top a:hover {
      color: #fff;
    }

    .wy-menu-vertical a:link, .wy-menu-vertical a:visited {
      color: #d9d9d9
    }

    .wy-menu-vertical a:active {
      background-color: #76b900
    }

    .wy-side-nav-search>div.version {
      color: rgba(0, 0, 0, 0.3)
    }

    .wy-nav-content {
      max-width: 1000px;
    }
  </style>
  
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">NVIDIA Container Toolkit:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../container-toolkit/overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../container-toolkit/concepts.html">Concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../container-toolkit/arch-overview.html">Architecture Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../container-toolkit/install-guide.html">Installation Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../container-toolkit/troubleshooting.html">Troubleshooting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../container-toolkit/user-guide.html">User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../container-toolkit/release-notes.html">Release Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../container-toolkit/archive.html">Archive</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">NVIDIA GPU Operator:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../../overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../getting-started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../platform-support.html">Platform Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../release-notes.html">Release Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../gpu-driver-upgrades.html">GPU Driver Upgrades</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../install-gpu-operator-vgpu.html">NVIDIA vGPU</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../install-gpu-operator-nvaie.html">NVIDIA AI Enterprise</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../gpu-operator-mig.html">GPU Operator with MIG</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../gpu-sharing.html">Time-Slicing GPUs in Kubernetes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../gpu-operator-rdma.html">GPUDirect RDMA and GPUDirect Storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../gpu-operator-kubevirt.html">GPU Operator with KubeVirt</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../appendix.html">Appendix</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../../../archive.html">Archive</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../../../archive.html#id1">22.9.1</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../archive.html#id2">22.9.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../archive.html#id3">1.11.1</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../archive.html#id4">1.11.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../archive.html#id5">1.10.1</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../archive.html#id6">1.9.1</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../archive.html#id7">1.9.0</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../../../archive.html#id8">1.8</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Kubernetes with GPUs:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../kubernetes/install-k8s.html">Install Kubernetes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../kubernetes/mig-k8s.html">MIG Support in Kubernetes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../kubernetes/anthos-guide.html">NVIDIA GPUs with Google Cloud’s Anthos</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Red Hat OpenShift</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../openshift/contents.html">GPU Operator on OpenShift</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Red Hat Device Edge</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../openshift/nvidia-gpu-with-device-edge.html">Accelerating workloads with NVIDIA GPUs with Red Hat Device Edge</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">GPU Telemetry:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../gpu-telemetry/dcgm-exporter.html">DCGM-Exporter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../gpu-telemetry/dcgm-exporter.html#integrating-gpu-telemetry-into-kubernetes">Integrating GPU Telemetry into Kubernetes</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Multi-Instance GPU:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../mig/mig.html">Multi-Instance GPU</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../mig/mig-k8s.html">MIG Support in Kubernetes</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Driver Containers:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../driver-containers/overview.html">Overview</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Playground:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../playground/dind.html">Docker-in-Docker</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../playground/x-arch.html">Running Cross-Architecture Containers</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../contents.html">NVIDIA Cloud Native Technologies</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../contents.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../../../archive.html">Archive</a> &raquo;</li>
          <li><a href="contents.html">GPU Operator on OpenShift</a> &raquo;</li>
      <li>Installing the NVIDIA GPU Operator</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="installing-the-nvidia-gpu-operator">
<span id="install-nvidiagpu-1-8"></span><h1>Installing the NVIDIA GPU Operator<a class="headerlink" href="#installing-the-nvidia-gpu-operator" title="Permalink to this heading"></a></h1>
<p>With the proper <a class="reference internal" href="cluster-entitlement.html#cluster-entitlement-1-8"><span class="std std-ref">Red Hat entitlement</span></a> in place and the <a class="reference internal" href="install-nfd.html#install-nfd-1-8"><span class="std std-ref">Node Feature Discovery Operator</span></a> installed you can continue with the final step and install the <strong>NVIDIA GPU Operator</strong>.</p>
<ol class="arabic simple">
<li><p>In the OpenShift Container Platform web console from the side menu, select <strong>Operators</strong> &gt; <strong>OperatorHub</strong>, then search for the <strong>NVIDIA GPU Operator</strong>. For additional information see the <a class="reference external" href="https://docs.openshift.com/container-platform/latest/operators/admin/olm-adding-operators-to-cluster.html">Red Hat OpenShift Container Platform documentation</a>.</p></li>
<li><p>Select the <strong>NVIDIA GPU Operator</strong>, click <strong>Install</strong>. In the subsequent screen click <strong>Install</strong>.</p></li>
</ol>
<section id="create-the-cluster-policy-for-the-nvidia-gpu-operator">
<span id="create-cluster-policy-1-8"></span><h2>Create the cluster policy for the NVIDIA GPU Operator<a class="headerlink" href="#create-the-cluster-policy-for-the-nvidia-gpu-operator" title="Permalink to this heading"></a></h2>
<p>When you install the <strong>NVIDIA GPU Operator</strong> in the OpenShift Container Platform, a custom resource definition for a ClusterPolicy is created. The ClusterPolicy configures the GPU stack that will be deployed, configuring the image names and repository, pod restrictions/credentials and so on.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If you create a ClusterPolicy that contains an empty specification, such as <code class="docutils literal notranslate"><span class="pre">spec{}</span></code>, the ClusterPolicy fails to deploy.</p>
</div>
<ol class="arabic">
<li><p>In the OpenShift Container Platform web console, from the side menu, select <strong>Operators</strong> &gt; <strong>Installed Operators</strong>, then click <strong>NVIDIA GPU Operator</strong>.</p></li>
<li><p>Select the <strong>ClusterPolicy</strong> tab, then click <strong>Create ClusterPolicy</strong>. The platform assigns the default name <em>gpu-cluster-policy</em>.</p>
<blockquote>
<div><div class="admonition note">
<p class="admonition-title">Note</p>
<p>You can use this screen to customize the ClusterPolicy however the default are sufficient to get the GPU configured and running.</p>
</div>
</div></blockquote>
</li>
<li><p>Click <strong>Create</strong>.</p>
<p>At this point, the GPU Operator proceeds and installs all the required components to set up the NVIDIA GPUs in the OpenShift 4 cluster. This may take a while so be patient and wait at least 10-20 minutes before digging deeper into any form of troubleshooting.</p>
</li>
<li><p>The status of the newly deployed ClusterPolicy <em>gpu-cluster-policy</em> for the NVIDIA GPU Operator changes to <code class="docutils literal notranslate"><span class="pre">State:ready</span></code> once the installation succeeded.</p></li>
</ol>
<blockquote>
<div><img alt="../../../../_images/cluster_policy_suceed3.png" src="../../../../_images/cluster_policy_suceed3.png" />
</div></blockquote>
</section>
<section id="verify-the-successful-installation-of-the-nvidia-gpu-operator">
<span id="verify-gpu-operator-install-ocp-1-8"></span><h2>Verify the successful installation of the NVIDIA GPU Operator<a class="headerlink" href="#verify-the-successful-installation-of-the-nvidia-gpu-operator" title="Permalink to this heading"></a></h2>
<p>The commands below describe various ways to verify the successful installation of the NVIDIA GPU Operator.</p>
<ol class="arabic">
<li><p>Run the following command to view these new pods and daemonsets:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>oc<span class="w"> </span>get<span class="w"> </span>pods,daemonset<span class="w"> </span>-n<span class="w"> </span>gpu-operator-resources
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">NAME                                           READY   STATUS      RESTARTS   AGE</span>
<span class="go">pod/gpu-feature-discovery-vwhnt                1/1     Running     0          6m32s</span>
<span class="go">pod/nvidia-container-toolkit-daemonset-k8x28   1/1     Running     0          6m33s</span>
<span class="go">pod/nvidia-cuda-validator-xr5sz                0/1     Completed   0          90s</span>
<span class="go">pod/nvidia-dcgm-5grvn                          1/1     Running     0          6m32s</span>
<span class="go">pod/nvidia-dcgm-exporter-cp8ml                 1/1     Running     0          6m32s</span>
<span class="go">pod/nvidia-device-plugin-daemonset-p9dp4       1/1     Running     0          6m32s</span>
<span class="go">pod/nvidia-device-plugin-validator-mrhst       0/1     Completed   0          48s</span>
<span class="go">pod/nvidia-driver-daemonset-pbplc              1/1     Running     0          6m33s</span>
<span class="go">pod/nvidia-node-status-exporter-s2ml2          1/1     Running     0          6m33s</span>
<span class="go">pod/nvidia-operator-validator-44jdf            1/1     Running     0          6m32s</span>

<span class="go">NAME                                                DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR                                      AGE</span>
<span class="go">daemonset.apps/gpu-feature-discovery                1         1         1       1            1           nvidia.com/gpu.deploy.gpu-feature-discovery=true   6m32s</span>
<span class="go">daemonset.apps/nvidia-container-toolkit-daemonset   1         1         1       1            1           nvidia.com/gpu.deploy.container-toolkit=true       6m33s</span>
<span class="go">daemonset.apps/nvidia-dcgm                          1         1         1       1            1           nvidia.com/gpu.deploy.dcgm=true                    6m33s</span>
<span class="go">daemonset.apps/nvidia-dcgm-exporter                 1         1         1       1            1           nvidia.com/gpu.deploy.dcgm-exporter=true           6m33s</span>
<span class="go">daemonset.apps/nvidia-device-plugin-daemonset       1         1         1       1            1           nvidia.com/gpu.deploy.device-plugin=true           6m33s</span>
<span class="go">daemonset.apps/nvidia-driver-daemonset              1         1         1       1            1           nvidia.com/gpu.deploy.driver=true                  6m33s</span>
<span class="go">daemonset.apps/nvidia-mig-manager                   0         0         0       0            0           nvidia.com/gpu.deploy.mig-manager=true             6m32s</span>
<span class="go">daemonset.apps/nvidia-node-status-exporter          1         1         1       1            1           nvidia.com/gpu.deploy.node-status-exporter=true    6m34s</span>
<span class="go">daemonset.apps/nvidia-operator-validator            1         1         1       1            1           nvidia.com/gpu.deploy.operator-validator=true      6m33s</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">nvidia-driver-daemonset</span></code> pod runs on each worker node that contains a supported NVIDIA GPU.</p>
</li>
</ol>
</section>
<section id="running-a-sample-gpu-application">
<span id="running-sample-app-1-8"></span><h2>Running a sample GPU Application<a class="headerlink" href="#running-a-sample-gpu-application" title="Permalink to this heading"></a></h2>
<p>Run a simple CUDA VectorAdd sample, which adds two vectors together to ensure the GPUs have bootstrapped correctly.</p>
<ol class="arabic">
<li><p>Run the following:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>cat<span class="w"> </span>&lt;&lt;<span class="w"> </span>EOF<span class="w"> </span><span class="p">|</span><span class="w"> </span>oc<span class="w"> </span>create<span class="w"> </span>-f<span class="w"> </span>-

<span class="go">apiVersion: v1</span>
<span class="go">kind: Pod</span>
<span class="go">metadata:</span>
<span class="go">  name: cuda-vectoradd</span>
<span class="go">spec:</span>
<span class="go"> restartPolicy: OnFailure</span>
<span class="go"> containers:</span>
<span class="go"> - name: cuda-vectoradd</span>
<span class="go">   image: &quot;nvidia/samples:vectoradd-cuda11.2.1&quot;</span>
<span class="go">   resources:</span>
<span class="go">     limits:</span>
<span class="go">       nvidia.com/gpu: 1</span>
<span class="go">EOF</span>
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">pod/cuda-vectoradd created</span>
</pre></div>
</div>
</li>
<li><p>Check the logs of the container:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>oc<span class="w"> </span>logs<span class="w"> </span>cuda-vectoradd
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">[Vector addition of 50000 elements]</span>
<span class="go">Copy input data from the host memory to the CUDA device</span>
<span class="go">CUDA kernel launch with 196 blocks of 256 threads</span>
<span class="go">Copy output data from the CUDA device to the host memory</span>
<span class="go">Test PASSED</span>
<span class="go">Done</span>
</pre></div>
</div>
</li>
</ol>
</section>
<section id="getting-information-on-the-gpu">
<h2>Getting information on the GPU<a class="headerlink" href="#getting-information-on-the-gpu" title="Permalink to this heading"></a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span></code> shows memory usage, GPU utilization and the temperature of GPU. Test the GPU access by running the popular <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span></code> command within the pod.</p>
<p>To view GPU utilization, run <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span></code> from a pod in the GPU Operator daemonset.</p>
<ol class="arabic">
<li><p>Change to the gpu-operator-resources project:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>oc<span class="w"> </span>project<span class="w"> </span>gpu-operator-resources
</pre></div>
</div>
</li>
<li><p>Run the following command to view these new pods:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>oc<span class="w"> </span>get<span class="w"> </span>pod<span class="w"> </span>-owide<span class="w"> </span>-lapp<span class="o">=</span>nvidia-driver-daemonset
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">NAME                            READY   STATUS    RESTARTS   AGE     IP            NODE                          NOMINATED NODE   READINESS GATES</span>
<span class="go">nvidia-driver-daemonset-pbplc   1/1     Running   0          8m17s   10.130.2.28   ip-10-0-143-64.ec2.internal   &lt;none&gt;           &lt;none&gt;</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The node is shown above, so with the Pod name, you can choose to execute the <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span></code> on the correct node.</p>
</div>
</li>
<li><p>Run the <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span></code> command within the pod:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>oc<span class="w"> </span><span class="nb">exec</span><span class="w"> </span>-it<span class="w"> </span>nvidia-driver-daemonset-pbplc<span class="w"> </span>--<span class="w"> </span>nvidia-smi
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">+-----------------------------------------------------------------------------+</span>
<span class="go">| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |</span>
<span class="go">|-------------------------------+----------------------+----------------------+</span>
<span class="go">| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |</span>
<span class="go">| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |</span>
<span class="go">|                               |                      |               MIG M. |</span>
<span class="go">|===============================+======================+======================|</span>
<span class="go">|   0  Tesla T4            On   | 00000000:00:1E.0 Off |                    0 |</span>
<span class="go">| N/A   40C    P8    16W /  70W |      0MiB / 15109MiB |      0%      Default |</span>
<span class="go">|                               |                      |                  N/A |</span>
<span class="go">+-------------------------------+----------------------+----------------------+</span>
<span class="go">| Processes:                                                                  |</span>
<span class="go">|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |</span>
<span class="go">|        ID   ID                                                   Usage      |</span>
<span class="go">|=============================================================================|</span>
<span class="go">|  No running processes found                                                 |</span>
<span class="go">+-----------------------------------------------------------------------------+</span>
</pre></div>
</div>
</li>
</ol>
<p>Two tables are generated the first reflects the information about all available GPUs (the example shows one GPU). The second table tells you about the processes using the GPUs.</p>
<p>For more information on the contents of the tables please refer to the man page for <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span></code>.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="install-nfd.html" class="btn btn-neutral float-left" title="Installing the Node Feature Discovery (NFD) Operator" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="mig-ocp.html" class="btn btn-neutral float-right" title="MIG Support in OpenShift Container Platform" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2018-2023, NVIDIA Corporation.
      <span class="lastupdated">Last updated on 2023-03-14.
      </span></p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>  

  <style>
  a:link, a:visited {
    color: #76b900;
  }

  a:hover {
    color: #8c0;
  }

  .rst-content dl:not(.docutils) dt {
    background: rgba(118, 185, 0, 0.1);
    color: rgba(59,93,0,1);
    border-top: solid 3px rgba(59,93,0,1);
  }
  </style>
  

</body>
</html>