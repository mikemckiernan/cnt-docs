<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>NVIDIA AI Enterprise &mdash; NVIDIA Cloud Native Technologies  documentation</title>
      <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/tabs.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/custom.css" type="text/css" />
    <link rel="shortcut icon" href="../../../_static/nvidia.ico"/>
    <link rel="canonical" href="https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/archive/22.9.0/install-gpu-operator-nvaie.html"/>
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script src="../../../_static/sphinx_highlight.js"></script>
        <script src="../../../_static/clipboard.min.js"></script>
        <script src="../../../_static/copybutton.js"></script>
        <script src="../../../_static/js/google-analytics/google-analytics-tracker.js"></script>
        <script src="../../../_static/js/google-analytics/google-analytics-write.js"></script>
        <script src="//assets.adobedtm.com/b92787824f2e0e9b68dc2e993f9bd995339fe417/satelliteLib-7ba51e58dc61bcb0e9311aadd02a0108ab24cc6c.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="GPU Operator on OpenShift" href="openshift/contents.html" />
    <link rel="prev" title="NVIDIA vGPU" href="install-gpu-operator-vgpu.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" > 
            <a href="../../../contents.html">
            <img src="../../../_static/NVLogo_H_B&W.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

  <style>
    /* Sidebar header (and topbar for mobile) */
    .wy-side-nav-search, .wy-nav-top {
      background: #76b900;
    }

    .wy-side-nav-search a:link, .wy-nav-top a:link {
      color: #fff;
    }
    .wy-side-nav-search a:visited, .wy-nav-top a:visited {
      color: #fff;
    }
    .wy-side-nav-search a:hover, .wy-nav-top a:hover {
      color: #fff;
    }

    .wy-menu-vertical a:link, .wy-menu-vertical a:visited {
      color: #d9d9d9
    }

    .wy-menu-vertical a:active {
      background-color: #76b900
    }

    .wy-side-nav-search>div.version {
      color: rgba(0, 0, 0, 0.3)
    }

    .wy-nav-content {
      max-width: 1000px;
    }
  </style>
  
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">NVIDIA Container Toolkit:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../container-toolkit/overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../container-toolkit/concepts.html">Concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../container-toolkit/arch-overview.html">Architecture Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../container-toolkit/install-guide.html">Installation Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../container-toolkit/troubleshooting.html">Troubleshooting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../container-toolkit/user-guide.html">User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../container-toolkit/release-notes.html">Release Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../container-toolkit/archive.html">Archive</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">NVIDIA GPU Operator:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting-started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../platform-support.html">Platform Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../release-notes.html">Release Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../gpu-driver-upgrades.html">GPU Driver Upgrades</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../install-gpu-operator-vgpu.html">NVIDIA vGPU</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../install-gpu-operator-nvaie.html">NVIDIA AI Enterprise</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../gpu-operator-mig.html">GPU Operator with MIG</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../gpu-sharing.html">Time-Slicing GPUs in Kubernetes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../gpu-operator-rdma.html">GPUDirect RDMA and GPUDirect Storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../gpu-operator-kubevirt.html">GPU Operator with KubeVirt</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../appendix.html">Appendix</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../../archive.html">Archive</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../../archive.html#id1">22.9.1</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../../archive.html#id2">22.9.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../archive.html#id3">1.11.1</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../archive.html#id4">1.11.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../archive.html#id5">1.10.1</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../archive.html#id6">1.9.1</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../archive.html#id7">1.9.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../archive.html#id8">1.8</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Kubernetes with GPUs:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../kubernetes/install-k8s.html">Install Kubernetes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../kubernetes/mig-k8s.html">MIG Support in Kubernetes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../kubernetes/anthos-guide.html">NVIDIA GPUs with Google Cloud’s Anthos</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">NVIDIA GPUs and Red Hat OpenShift</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../openshift/introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../openshift/prerequisites.html">Prerequisites</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../openshift/steps-overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../openshift/install-nfd.html">Installing the Node Feature Discovery (NFD) Operator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../openshift/install-gpu-ocp.html">Installing the NVIDIA GPU Operator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../openshift/nvaie-with-ocp.html">NVIDIA AI Enterprise with OpenShift</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../openshift/mig-ocp.html">MIG Support in OpenShift Container Platform</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../openshift/clean-up.html">Cleanup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../openshift/mirror-gpu-ocp-disconnected.html">Deploy GPU Operators in a disconnected or airgapped environment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../openshift/enable-gpu-op-dashboard.html">Enable the GPU Operator Dashboard</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../openshift/time-slicing-gpus-in-openshift.html">Time-slicing NVIDIA GPUs in OpenShift</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../openshift/openshift-virtualization.html">NVIDIA GPU Operator with OpenShift Virtualization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../openshift/troubleshooting-gpu-ocp.html">Troubleshooting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../openshift/appendix-ocp.html">Appendix</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">NVIDIA GPUs and Red Hat Device Edge</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../openshift/nvidia-gpu-with-device-edge.html">Accelerating workloads with NVIDIA GPUs</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">GPU Telemetry:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../gpu-telemetry/dcgm-exporter.html">DCGM-Exporter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../gpu-telemetry/dcgm-exporter.html#integrating-gpu-telemetry-into-kubernetes">Integrating GPU Telemetry into Kubernetes</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Multi-Instance GPU:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../mig/mig.html">Multi-Instance GPU</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mig/mig-k8s.html">MIG Support in Kubernetes</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Driver Containers:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../driver-containers/overview.html">Overview</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Playground:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../playground/dind.html">Docker-in-Docker</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../playground/x-arch.html">Running Cross-Architecture Containers</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../contents.html">NVIDIA Cloud Native Technologies</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../contents.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../../archive.html">Archive</a> &raquo;</li>
      <li>NVIDIA AI Enterprise</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="nvidia-ai-enterprise">
<span id="install-gpu-operator-22-9-0-nvaie"></span><h1>NVIDIA AI Enterprise<a class="headerlink" href="#nvidia-ai-enterprise" title="Permalink to this heading"></a></h1>
<p>NVIDIA AI Enterprise is an end-to-end, cloud-native suite of AI and data analytics software, optimized, certified, and supported by NVIDIA with  NVIDIA-Certified  Systems. Additional information can be found at the <a class="reference external" href="https://www.nvidia.com/en-us/data-center/products/ai-enterprise-suite/#benefits">NVIDIA AI Enterprise web page</a>.</p>
<p>NVIDIA AI Enterprise customers have access to a pre-configured GPU Operator within the NVIDIA Enterprise Catalog.
The GPU Operator is pre-configured to simplify the provisioning experience with NVIDIA AI Enterprise deployments.</p>
<p>The pre-configured GPU Operator differs from the GPU Operator in the public NGC catalog. The differences are:</p>
<blockquote>
<div><ul class="simple">
<li><p>It is configured to use a prebuilt vGPU driver image (Only available to NVIDIA AI Enterprise customers)</p></li>
<li><p>It is configured to use the <a class="reference external" href="https://docs.nvidia.com/license-system/latest/">NVIDIA License System (NLS)</a></p></li>
</ul>
</div></blockquote>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For NVIDIA AI Enterprise 2.3, the GPU Operator is configured to deploy the 520.61.05 Data Center GPU Driver by default.
This default driver only works with bare metal and virtual machines with GPU Passthrough.</p>
</div>
<p>This page provides documentation for the following configurations:</p>
<ul class="simple">
<li><p>Kubernetes on bare metal and on vSphere VMs with GPU passthrough and vGPU.</p></li>
<li><p>VMware vSphere with Tanzu.</p></li>
<li><p>Red Hat Openshift on bare metal and on vSphere VMs with GPU passthrough and vGPU.</p></li>
</ul>
<p>The following sections are applicable to the first two configurations and describe how to deploy the GPU Operator using the Helm Chart.
For Red Hat Openshift configurations, please follow this procedure <cite>NVIDIA AI Enterprise with OpenShift &lt;nvaie-ocp&gt;</cite>.</p>
<section id="installing-gpu-operator">
<h2>Installing GPU Operator<a class="headerlink" href="#installing-gpu-operator" title="Permalink to this heading"></a></h2>
<p>To install GPU Operator with NVIDIA AI Enterprise, apply the following steps.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>You can also use the following <a class="reference external" href="https://raw.githubusercontent.com/NVIDIA/gpu-operator/master/scripts/install-gpu-operator-nvaie.sh">script</a>, which automates the below installation instructions.</p>
</div>
<p>Create the <code class="docutils literal notranslate"><span class="pre">gpu-operator</span></code> namespace:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl<span class="w"> </span>create<span class="w"> </span>namespace<span class="w"> </span>gpu-operator
</pre></div>
</div>
<p>Create an empty vGPU license configuration file:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>sudo<span class="w"> </span>touch<span class="w"> </span>gridd.conf
</pre></div>
</div>
<p>Generate and download a NLS client license token. Please refer to Section 4.6 of the <a class="reference external" href="https://docs.nvidia.com/license-system/latest/pdf/nvidia-license-system-user-guide.pdf">NLS User Guide</a> for instructions.</p>
<p>Rename the NLS client license token that you downloaded to <code class="docutils literal notranslate"><span class="pre">client_configuration_token.tok</span></code>.</p>
<p>Create the <code class="docutils literal notranslate"><span class="pre">licensing-config</span></code> ConfigMap object in the <code class="docutils literal notranslate"><span class="pre">gpu-operator</span></code> namespace. Both the vGPU license
configuration file and the NLS client license token will be added to this ConfigMap:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl<span class="w"> </span>create<span class="w"> </span>configmap<span class="w"> </span>licensing-config<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>-n<span class="w"> </span>gpu-operator<span class="w"> </span>--from-file<span class="o">=</span>gridd.conf<span class="w"> </span>--from-file<span class="o">=</span>&lt;path&gt;/client_configuration_token.tok
</pre></div>
</div>
<p>Create an image pull secret in the <code class="docutils literal notranslate"><span class="pre">gpu-operator</span></code> namespace for the private
registry that contains the containerized NVIDIA vGPU software graphics driver for Linux for
use with NVIDIA GPU Operator:</p>
<blockquote>
<div><ul class="simple">
<li><p>Set the registry secret name:</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span><span class="nb">export</span><span class="w"> </span><span class="nv">REGISTRY_SECRET_NAME</span><span class="o">=</span>ngc-secret
</pre></div>
</div>
<ul class="simple">
<li><p>Set the private registry name:</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span><span class="nb">export</span><span class="w"> </span><span class="nv">PRIVATE_REGISTRY</span><span class="o">=</span>nvcr.io/nvaie
</pre></div>
</div>
<ul class="simple">
<li><p>Create an image pull secret in the <code class="docutils literal notranslate"><span class="pre">gpu-operator</span></code> namespace with the registry
secret name and the private registry name that you set. Replace <code class="docutils literal notranslate"><span class="pre">password</span></code>,
and <code class="docutils literal notranslate"><span class="pre">email-address</span></code> with your NGC API key and email address respectively:</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl<span class="w"> </span>create<span class="w"> </span>secret<span class="w"> </span>docker-registry<span class="w"> </span><span class="si">${</span><span class="nv">REGISTRY_SECRET_NAME</span><span class="si">}</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--docker-server<span class="o">=</span><span class="si">${</span><span class="nv">PRIVATE_REGISTRY</span><span class="si">}</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--docker-username<span class="o">=</span><span class="s1">&#39;$oauthtoken&#39;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--docker-password<span class="o">=</span><span class="s1">&#39;&lt;password&gt;&#39;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--docker-email<span class="o">=</span><span class="s1">&#39;&lt;email-address&gt;&#39;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>-n<span class="w"> </span>gpu-operator
</pre></div>
</div>
</div></blockquote>
<p>Add the NVIDIA AI Enterprise Helm repository, where password is the NGC API key for accessing the NVIDIA Enterprise Collection that you generated:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>helm<span class="w"> </span>repo<span class="w"> </span>add<span class="w"> </span>nvaie<span class="w"> </span>https://helm.ngc.nvidia.com/nvaie<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--username<span class="o">=</span><span class="s1">&#39;$oauthtoken&#39;</span><span class="w"> </span>--password<span class="o">=</span><span class="s1">&#39;&lt;password&gt;&#39;</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span><span class="o">&amp;&amp;</span><span class="w"> </span>helm<span class="w"> </span>repo<span class="w"> </span>update
</pre></div>
</div>
<p>Install the NVIDIA GPU Operator:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>helm<span class="w"> </span>install<span class="w"> </span>--wait<span class="w"> </span>gpu-operator<span class="w"> </span>nvaie/gpu-operator-2-1<span class="w"> </span>-n<span class="w"> </span>gpu-operator
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>in case you need to deploy the Helm chart with some customizations, please refer to this link: <a class="reference internal" href="../../../kubernetes/anthos-guide.html#gpu-operator-helm-chart-options"><span class="std std-ref">Chart Customization Options</span></a></p>
</div>
</section>
<section id="installing-gpu-operator-with-the-nvidia-datacenter-driver">
<h2>Installing GPU Operator with the NVIDIA Datacenter Driver<a class="headerlink" href="#installing-gpu-operator-with-the-nvidia-datacenter-driver" title="Permalink to this heading"></a></h2>
<p>To install GPU Operator on baremetal with the NVIDIA Datacenter Driver, apply the following steps.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>You can also use the following <a class="reference external" href="https://raw.githubusercontent.com/NVIDIA/gpu-operator/master/scripts/install-gpu-operator-nvaie.sh">script</a>, which automates the below installation instructions.</p>
</div>
<p>Create the <code class="docutils literal notranslate"><span class="pre">gpu-operator</span></code> namespace:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl<span class="w"> </span>create<span class="w"> </span>namespace<span class="w"> </span>gpu-operator
</pre></div>
</div>
<p>Create an image pull secret in the <code class="docutils literal notranslate"><span class="pre">gpu-operator</span></code> namespace for the private
registry that contains the NVIDIA GPU Operator:</p>
<blockquote>
<div><ul class="simple">
<li><p>Set the registry secret name:</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span><span class="nb">export</span><span class="w"> </span><span class="nv">REGISTRY_SECRET_NAME</span><span class="o">=</span>ngc-secret
</pre></div>
</div>
<ul class="simple">
<li><p>Set the private registry name:</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span><span class="nb">export</span><span class="w"> </span><span class="nv">PRIVATE_REGISTRY</span><span class="o">=</span>nvcr.io/nvaie
</pre></div>
</div>
<ul class="simple">
<li><p>Create an image pull secret in the <code class="docutils literal notranslate"><span class="pre">gpu-operator</span></code> namespace with the registry
secret name and the private registry name that you set. Replace <code class="docutils literal notranslate"><span class="pre">password</span></code>,
and <code class="docutils literal notranslate"><span class="pre">email-address</span></code> with your NGC API key and email address respectively:</p></li>
</ul>
</div></blockquote>
<p>Add the NVIDIA AI Enterprise Helm repository, where password is the NGC API key for accessing the NVIDIA Enterprise Collection that you generated:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>helm<span class="w"> </span>repo<span class="w"> </span>add<span class="w"> </span>nvaie<span class="w"> </span>https://helm.ngc.nvidia.com/nvaie<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--username<span class="o">=</span><span class="s1">&#39;$oauthtoken&#39;</span><span class="w"> </span>--password<span class="o">=</span><span class="s1">&#39;&lt;password&gt;&#39;</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span><span class="o">&amp;&amp;</span><span class="w"> </span>helm<span class="w"> </span>repo<span class="w"> </span>update
</pre></div>
</div>
<p>Install the NVIDIA GPU Operator:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>helm<span class="w"> </span>install<span class="w"> </span>--wait<span class="w"> </span>gpu-operator<span class="w"> </span>nvaie/gpu-operator-2-1<span class="w"> </span>-n<span class="w"> </span>gpu-operator<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--set<span class="w"> </span>driver.repository<span class="o">=</span>nvcr.io/nvidia<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--set<span class="w"> </span>driver.image<span class="o">=</span>driver<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--set<span class="w"> </span>driver.version<span class="o">=</span><span class="m">510</span>.47.03<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--set<span class="w"> </span>driver.licensingConfig.configMapName<span class="o">=</span><span class="s2">&quot;&quot;</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In case you need to deploy the Helm chart with some customizations, please refer to this link: <a class="reference internal" href="../../../kubernetes/anthos-guide.html#gpu-operator-helm-chart-options"><span class="std std-ref">Chart Customization Options</span></a></p>
</div>
</section>
<section id="updating-nls-client-license-token">
<h2>Updating NLS client license token<a class="headerlink" href="#updating-nls-client-license-token" title="Permalink to this heading"></a></h2>
<p>In case the NLS client license token needs to be updated, please use the following procedure:</p>
<p>Create an empty vGPU license configuration file:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>sudo<span class="w"> </span>touch<span class="w"> </span>gridd.conf
</pre></div>
</div>
<p>Generate and download a new NLS client license token. Please refer to Section 4.6 of the <a class="reference external" href="https://docs.nvidia.com/license-system/latest/pdf/nvidia-license-system-user-guide.pdf">NLS User Guide</a> for instructions.</p>
<p>Rename the NLS client license token that you downloaded to <code class="docutils literal notranslate"><span class="pre">client_configuration_token.tok</span></code>.</p>
<p>Create a new <code class="docutils literal notranslate"><span class="pre">licensing-config-new</span></code> ConfigMap object in the <code class="docutils literal notranslate"><span class="pre">gpu-operator</span></code> namespace (make sure the name of the configmap is not already used in the kubernetes cluster). Both the vGPU license configuration file and the NLS client license token will be added to this ConfigMap:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl<span class="w"> </span>create<span class="w"> </span>configmap<span class="w"> </span>licensing-config-new<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>-n<span class="w"> </span>gpu-operator<span class="w"> </span>--from-file<span class="o">=</span>gridd.conf<span class="w"> </span>--from-file<span class="o">=</span>&lt;path&gt;/client_configuration_token.tok
</pre></div>
</div>
<p>Edit the clusterpolicies by using the command:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl<span class="w"> </span>edit<span class="w"> </span>clusterpolicies.nvidia.com
</pre></div>
</div>
<p>Go to the driver section and replace the following argument:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">licensingConfig:</span>
<span class="go">    configMapName: licensing-config</span>
</pre></div>
</div>
<p>with</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">licensingConfig:</span>
<span class="go">    configMapName: licensing-config-new</span>
</pre></div>
</div>
<p>Write and exit from the kubectl edit session (you can use :qw for instance if vi utility is used)</p>
<p>GPU Operator will redeploy sequentially all the driver pods with this new licensing information.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="install-gpu-operator-vgpu.html" class="btn btn-neutral float-left" title="NVIDIA vGPU" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="openshift/contents.html" class="btn btn-neutral float-right" title="GPU Operator on OpenShift" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2018-2023, NVIDIA Corporation.
      <span class="lastupdated">Last updated on 2023-03-14.
      </span></p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>  

  <style>
  a:link, a:visited {
    color: #76b900;
  }

  a:hover {
    color: #8c0;
  }

  .rst-content dl:not(.docutils) dt {
    background: rgba(118, 185, 0, 0.1);
    color: rgba(59,93,0,1);
    border-top: solid 3px rgba(59,93,0,1);
  }
  </style>
  

</body>
</html>