<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Running Sample CUDA Workloads &mdash; NVIDIA Cloud Native Technologies  documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="../_static/tabs.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />
    <link rel="shortcut icon" href="../_static/nvidia.ico"/>
    <link rel="canonical" href="https://docs.nvidia.com/datacenter/cloud-native/mig/mig-examples.html"/>
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/sphinx_highlight.js"></script>
        <script src="../_static/clipboard.min.js"></script>
        <script src="../_static/copybutton.js"></script>
        <script src="../_static/js/google-analytics/google-analytics-tracker.js"></script>
        <script src="../_static/js/google-analytics/google-analytics-write.js"></script>
        <script src="//assets.adobedtm.com/b92787824f2e0e9b68dc2e993f9bd995339fe417/satelliteLib-7ba51e58dc61bcb0e9311aadd02a0108ab24cc6c.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" > 
            <a href="../contents.html">
            <img src="../_static/NVLogo_H_B&W.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

  <style>
    /* Sidebar header (and topbar for mobile) */
    .wy-side-nav-search, .wy-nav-top {
      background: #76b900;
    }

    .wy-side-nav-search a:link, .wy-nav-top a:link {
      color: #fff;
    }
    .wy-side-nav-search a:visited, .wy-nav-top a:visited {
      color: #fff;
    }
    .wy-side-nav-search a:hover, .wy-nav-top a:hover {
      color: #fff;
    }

    .wy-menu-vertical a:link, .wy-menu-vertical a:visited {
      color: #d9d9d9
    }

    .wy-menu-vertical a:active {
      background-color: #76b900
    }

    .wy-side-nav-search>div.version {
      color: rgba(0, 0, 0, 0.3)
    }

    .wy-nav-content {
      max-width: 1000px;
    }
  </style>
  
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">NVIDIA Container Toolkit:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../container-toolkit/overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../container-toolkit/concepts.html">Concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="../container-toolkit/arch-overview.html">Architecture Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../container-toolkit/install-guide.html">Installation Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../container-toolkit/troubleshooting.html">Troubleshooting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../container-toolkit/user-guide.html">User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../container-toolkit/release-notes.html">Release Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../container-toolkit/archive.html">Archive</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">NVIDIA GPU Operator:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/getting-started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/platform-support.html">Platform Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/release-notes.html">Release Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/gpu-driver-upgrades.html">GPU Driver Upgrades</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/install-gpu-operator-vgpu.html">NVIDIA vGPU</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/install-gpu-operator-nvaie.html">NVIDIA AI Enterprise</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/gpu-operator-mig.html">GPU Operator with MIG</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/gpu-sharing.html">Time-Slicing GPUs in Kubernetes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/gpu-operator-rdma.html">GPUDirect RDMA and GPUDirect Storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/gpu-operator-kubevirt.html">GPU Operator with KubeVirt</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/appendix.html">Appendix</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/archive.html">Archive</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Kubernetes with GPUs:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../kubernetes/install-k8s.html">Install Kubernetes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../kubernetes/mig-k8s.html">MIG Support in Kubernetes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../kubernetes/anthos-guide.html">NVIDIA GPUs with Google Cloud’s Anthos</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">NVIDIA GPUs and Red Hat OpenShift</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/openshift/introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/openshift/prerequisites.html">Prerequisites</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/openshift/steps-overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/openshift/install-nfd.html">Installing the Node Feature Discovery (NFD) Operator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/openshift/install-gpu-ocp.html">Installing the NVIDIA GPU Operator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/openshift/nvaie-with-ocp.html">NVIDIA AI Enterprise with OpenShift</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/openshift/mig-ocp.html">MIG Support in OpenShift Container Platform</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/openshift/clean-up.html">Cleanup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/openshift/mirror-gpu-ocp-disconnected.html">Deploy GPU Operators in a disconnected or airgapped environment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/openshift/enable-gpu-op-dashboard.html">Enable the GPU Operator Dashboard</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/openshift/time-slicing-gpus-in-openshift.html">Time-slicing NVIDIA GPUs in OpenShift</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/openshift/openshift-virtualization.html">NVIDIA GPU Operator with OpenShift Virtualization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/openshift/troubleshooting-gpu-ocp.html">Troubleshooting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/openshift/appendix-ocp.html">Appendix</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">NVIDIA GPUs and Red Hat Device Edge</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../gpu-operator/openshift/nvidia-gpu-with-device-edge.html">Accelerating workloads with NVIDIA GPUs</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">GPU Telemetry:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../gpu-telemetry/dcgm-exporter.html">DCGM-Exporter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu-telemetry/dcgm-exporter.html#integrating-gpu-telemetry-into-kubernetes">Integrating GPU Telemetry into Kubernetes</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Multi-Instance GPU:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="mig.html">Multi-Instance GPU</a></li>
<li class="toctree-l1"><a class="reference internal" href="mig-k8s.html">MIG Support in Kubernetes</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Driver Containers:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../driver-containers/overview.html">Overview</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Playground:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../playground/dind.html">Docker-in-Docker</a></li>
<li class="toctree-l1"><a class="reference internal" href="../playground/x-arch.html">Running Cross-Architecture Containers</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../contents.html">NVIDIA Cloud Native Technologies</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../contents.html" class="icon icon-home"></a> &raquo;</li>
      <li>Running Sample CUDA Workloads</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="running-sample-cuda-workloads">
<span id="mig-examples"></span><h1>Running Sample CUDA Workloads<a class="headerlink" href="#running-sample-cuda-workloads" title="Permalink to this heading"></a></h1>
<section id="cuda-vectoradd">
<h2>CUDA VectorAdd<a class="headerlink" href="#cuda-vectoradd" title="Permalink to this heading"></a></h2>
<p>Let’s run a simple CUDA sample, in this case <code class="docutils literal notranslate"><span class="pre">vectorAdd</span></code> by requesting a GPU resource as you would
normally do in Kubernetes. In this case, Kubernetes will schedule the pod on a single MIG device and
we use a <code class="docutils literal notranslate"><span class="pre">nodeSelector</span></code> to direct the pod to be scheduled on the node with the MIG devices.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>cat<span class="w"> </span>&lt;&lt;<span class="w"> </span>EOF<span class="w"> </span><span class="p">|</span><span class="w"> </span>kubectl<span class="w"> </span>create<span class="w"> </span>-f<span class="w"> </span>-
<span class="go">apiVersion: v1</span>
<span class="go">kind: Pod</span>
<span class="go">metadata:</span>
<span class="go">  name: cuda-vectoradd</span>
<span class="go">spec:</span>
<span class="go">  restartPolicy: OnFailure</span>
<span class="go">  containers:</span>
<span class="go">  - name: vectoradd</span>
<span class="go">    image: nvidia/samples:vectoradd-cuda11.2.1</span>
<span class="go">    resources:</span>
<span class="go">      limits:</span>
<span class="go">        nvidia.com/gpu: 1</span>
<span class="go">  nodeSelector:</span>
<span class="go">    nvidia.com/gpu.product: A100-SXM4-40GB-MIG-1g.5gb</span>
<span class="go">EOF</span>
</pre></div>
</div>
</section>
<section id="concurrent-job-launch">
<h2>Concurrent Job Launch<a class="headerlink" href="#concurrent-job-launch" title="Permalink to this heading"></a></h2>
<p>Now, let’s try a more complex example. In this example, we will use Argo Workflows to launch concurrent
jobs on MIG devices. In this example, the A100 has been configured into 2 MIG devices using the: <code class="docutils literal notranslate"><span class="pre">3g.20gb</span></code> profile.</p>
<p>First, <a class="reference external" href="https://argoproj.github.io/argo-workflows/quick-start/#install-argo-workflows">install</a> the Argo Workflows
components into your Kubernetes cluster.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl<span class="w"> </span>create<span class="w"> </span>ns<span class="w"> </span>argo<span class="w"> </span><span class="se">\</span>
<span class="w">    </span><span class="o">&amp;&amp;</span><span class="w"> </span>kubectl<span class="w"> </span>apply<span class="w"> </span>-n<span class="w"> </span>argo<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>-f<span class="w"> </span>https://raw.githubusercontent.com/argoproj/argo-workflows/stable/manifests/quick-start-postgres.yaml
</pre></div>
</div>
<p>Next, download the latest Argo CLI from the <a class="reference external" href="https://github.com/argoproj/argo-workflows/releases">releases page</a> and
follow the instructions to install the binary.</p>
<p>Now, we will craft an Argo example that launches multiple CUDA containers onto the MIG devices on the GPU.
We will reuse the same <code class="docutils literal notranslate"><span class="pre">vectorAdd</span></code> example from before. Here is the job description, saved as <code class="docutils literal notranslate"><span class="pre">vector-add.yaml</span></code>:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">$ cat &lt;&lt; EOF &gt; vector-add.yaml</span>
<span class="l l-Scalar l-Scalar-Plain">apiVersion</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">argoproj.io/v1alpha1</span>
<span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Workflow</span>
<span class="nt">metadata</span><span class="p">:</span>
<span class="nt">generateName</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">argo-mig-example-</span>
<span class="nt">spec</span><span class="p">:</span>
<span class="nt">entrypoint</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">argo-mig-result-example</span>
<span class="nt">templates</span><span class="p">:</span>
<span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">argo-mig-result-example</span>
<span class="w">    </span><span class="l l-Scalar l-Scalar-Plain">steps</span><span class="p p-Indicator">:</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">generate</span>
<span class="w">        </span><span class="nt">template</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">gen-mig-device-list</span>
<span class="w">    </span><span class="c1"># Iterate over the list of numbers generated by the generate step above</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">argo-mig</span>
<span class="w">        </span><span class="nt">template</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">argo-mig</span>
<span class="w">        </span><span class="nt">arguments</span><span class="p">:</span>
<span class="w">        </span><span class="nt">parameters</span><span class="p">:</span>
<span class="w">        </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">argo-mig</span>
<span class="w">            </span><span class="l l-Scalar l-Scalar-Plain">value</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="s">&quot;{{item}}&quot;</span>
<span class="w">        </span><span class="nt">withParam</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;{{steps.generate.outputs.result}}&quot;</span>

<span class="c1"># Generate a list of numbers in JSON format</span>
<span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">gen-mig-device-list</span>
<span class="w">    </span><span class="l l-Scalar l-Scalar-Plain">script</span><span class="p p-Indicator">:</span>
<span class="w">    </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">python:alpine3.6</span>
<span class="w">    </span><span class="nt">command</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">python</span><span class="p p-Indicator">]</span>
<span class="w">    </span><span class="nt">source</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|</span>
<span class="w">        </span><span class="no">import json</span>
<span class="w">        </span><span class="no">import sys</span>
<span class="w">        </span><span class="no">json.dump([i for i in range(0, 2)], sys.stdout)</span>

<span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">argo-mig</span>
<span class="w">    </span><span class="l l-Scalar l-Scalar-Plain">retryStrategy</span><span class="p p-Indicator">:</span>
<span class="w">    </span><span class="nt">limit</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">10</span>
<span class="w">    </span><span class="nt">retryPolicy</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;Always&quot;</span>
<span class="w">    </span><span class="nt">inputs</span><span class="p">:</span>
<span class="w">    </span><span class="nt">parameters</span><span class="p">:</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">argo-mig</span>
<span class="w">    </span><span class="nt">container</span><span class="p">:</span>
<span class="w">    </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">nvidia/samples:vectoradd-cuda11.2.1</span>
<span class="w">    </span><span class="nt">resources</span><span class="p">:</span>
<span class="w">        </span><span class="nt">limits</span><span class="p">:</span>
<span class="w">        </span><span class="nt">nvidia.com/gpu</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">    </span><span class="nt">nodeSelector</span><span class="p">:</span>
<span class="w">    </span><span class="nt">nvidia.com/gpu.product</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">A100-SXM4-40GB-MIG-3g.20gb</span>
<span class="l l-Scalar l-Scalar-Plain">EOF</span>
</pre></div>
</div>
<p>Launch the workflow:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>argo<span class="w"> </span>submit<span class="w"> </span>-n<span class="w"> </span>argo<span class="w"> </span>--watch<span class="w"> </span>vector-add.yaml
</pre></div>
</div>
<p>Argo will print out the pods that have been launched:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">Name:                argo-mig-example-z6mqd</span>
<span class="go">Namespace:           argo</span>
<span class="go">ServiceAccount:      default</span>
<span class="go">Status:              Succeeded</span>
<span class="go">Conditions:</span>
<span class="go">Completed           True</span>
<span class="go">Created:             Wed Mar 24 14:44:51 -0700 (20 seconds ago)</span>
<span class="go">Started:             Wed Mar 24 14:44:51 -0700 (20 seconds ago)</span>
<span class="go">Finished:            Wed Mar 24 14:45:11 -0700 (now)</span>
<span class="go">Duration:            20 seconds</span>
<span class="go">Progress:            3/3</span>
<span class="go">ResourcesDuration:   9s*(1 cpu),9s*(100Mi memory),1s*(1 nvidia.com/gpu)</span>

<span class="go">STEP                       TEMPLATE                 PODNAME                           DURATION  MESSAGE</span>
<span class="go">✔ argo-mig-example-z6mqd  argo-mig-result-example</span>
<span class="go">├───✔ generate            gen-mig-device-list      argo-mig-example-z6mqd-562792713  8s</span>
<span class="go">└─┬─✔ argo-mig(0:0)(0)    argo-mig                 argo-mig-example-z6mqd-845918106  2s</span>
<span class="go">└─✔ argo-mig(1:1)(0)    argo-mig                 argo-mig-example-z6mqd-870679174  2s</span>
</pre></div>
</div>
<p>If you observe the logs, you can see that the <code class="docutils literal notranslate"><span class="pre">vector-add</span></code> sample has completed on both devices:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>argo<span class="w"> </span>logs<span class="w"> </span>-n<span class="w"> </span>argo<span class="w"> </span>@latest
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">argo-mig-example-z6mqd-562792713: [0, 1]</span>
<span class="go">argo-mig-example-z6mqd-870679174: [Vector addition of 50000 elements]</span>
<span class="go">argo-mig-example-z6mqd-870679174: Copy input data from the host memory to the CUDA device</span>
<span class="go">argo-mig-example-z6mqd-870679174: CUDA kernel launch with 196 blocks of 256 threads</span>
<span class="go">argo-mig-example-z6mqd-870679174: Copy output data from the CUDA device to the host memory</span>
<span class="go">argo-mig-example-z6mqd-870679174: Test PASSED</span>
<span class="go">argo-mig-example-z6mqd-870679174: Done</span>
<span class="go">argo-mig-example-z6mqd-845918106: [Vector addition of 50000 elements]</span>
<span class="go">argo-mig-example-z6mqd-845918106: Copy input data from the host memory to the CUDA device</span>
<span class="go">argo-mig-example-z6mqd-845918106: CUDA kernel launch with 196 blocks of 256 threads</span>
<span class="go">argo-mig-example-z6mqd-845918106: Copy output data from the CUDA device to the host memory</span>
<span class="go">argo-mig-example-z6mqd-845918106: Test PASSED</span>
<span class="go">argo-mig-example-z6mqd-845918106: Done</span>
</pre></div>
</div>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2018-2023, NVIDIA Corporation.
      <span class="lastupdated">Last updated on 2023-03-14.
      </span></p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>  

  <style>
  a:link, a:visited {
    color: #76b900;
  }

  a:hover {
    color: #8c0;
  }

  .rst-content dl:not(.docutils) dt {
    background: rgba(118, 185, 0, 0.1);
    color: rgba(59,93,0,1);
    border-top: solid 3px rgba(59,93,0,1);
  }
  </style>
  

</body>
</html>